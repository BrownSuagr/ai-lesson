{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63fb520c2e2eee1",
   "metadata": {},
   "source": [
    "# 金融分控特征工程之特征构造学习目标\n",
    "- 知道未来信息的概念，及处理未来信息的方法\n",
    "- 掌握从原始数据构造出新的特征的方法\n",
    "- 掌握特征变换的方法\n",
    "- 掌握缺失值处理的方法\n",
    "\n",
    "# 1、什么是特征变换？\n",
    "> 特征构造过程中，对特征做分箱处理时必不可少的过程，分箱就是将连续变量离散化，合并成较少的状态\n",
    "\n",
    "# 2、特征分箱的作用是什么？\n",
    "- 离散特征的增加和较少都很容易，易于模型的快速迭代\n",
    "- 稀疏向量內积乘法运算快，计算结果方便存储，易于扩展\n",
    "- 分箱（离散化）后的特征对异常数据有很强的鲁棒性\n",
    "- 单变量分箱（离散化）为N个，每个单变量有独特的权重，相当于为模型引入了非线性，能够提升模型表达能力\n",
    "- 分箱（离散化）后可以进行特征交叉，由M+N个变量变为M*N个变量，进一步引入非线性，提升表达能力\n",
    "- 分箱（离散化）后，模型会更加稳定，对于年龄离散化，20～30为一个区间，不行因为年龄+1就变成一个新特征\n",
    "- 特征离散化可以讲缺失作为独立的一类带入模型\n",
    "- \n",
    "\n",
    "# 3、常见的特征分箱方法有哪些，分别有哪些特点？\n",
    "- 卡方分箱：\n",
    "    - 将数据按照等频和等距分箱后，计算卡方值，将卡放只较小的乡邻的箱体合并，使得不同箱体的好坏样本比例区别放大，容易获得高IV（Information Value）\n",
    "    - 卡方分箱是利用独立性检验来挑选箱划分节点的阈值，卡方分箱过程可以拆氛围初始化和合并两个步骤\n",
    "        - 初始化：根据连续变量值大小进行排序，构建最初的离散化\n",
    "        - 合并：便利相邻两项的卡方值，将卡方数据最小的两组合并，不断的重复直到满足分箱数目要求\n",
    "    - \n",
    "- 决策树分箱：\n",
    "    - 自动适应数据特征：无需预处理：决策树分箱不需要对数据进行预处理和归一化，能够自适应地处理离散和连续变量，并根据数据的实际情况进行分箱。\n",
    "    - 处理高维数据：高维数据支持：决策树分箱能够处理高维数据，并将其离散化为少数几个变量，从而提高模型的效率和稳定性。\n",
    "    - 提高模型可解释性：可视化分箱过程：决策树分箱能够将模型的分箱过程可视化，提高模型的可解释性。通过决策树的规则，可以直观地看到每个分箱的边界和对应的特征值。\n",
    "    - 简化分箱工作量：减少人为干预：使用决策树进行分箱可以大大简化分箱工作量，显著减少人为不确定因素造成的影响。分箱作为一项工程，通过决策树来进行分箱，能够在对数据的熟悉程度尚浅时，通过相关决策算法机制，挖掘出数据中蕴含的关键信息。\n",
    "    - 依赖决策树质量：分箱结果依赖于决策树：决策树分箱的结果依赖于决策树的质量。如果决策树构造不好，分箱结果可能不准确。因此，需要选择合适的决策树参数，如 max_depth、min_samples_leaf 等，以确保分箱结果的准确性和稳定性。\n",
    "    - 箱数选择困难：箱数选择：决策树分箱需要选择合适的箱（叶节点）数，而这个选择比较困难，需要根据具体问题进行判断。通常可以通过调整决策树的参数来控制箱数\n",
    "- 等频分箱：\n",
    "    - 按数据分布，均匀切分，，每个箱体内样本数量一样\n",
    "    - 在样本较少情况下，泛化能力较差\n",
    "    - 在样本不均衡时可能无法分箱\n",
    "    - 特征分析常用等频分箱\n",
    "- 等距分箱：\n",
    "    - 按照数据的特征值的间距均匀切分，每个箱体的数值距离一样\n",
    "    - 一定可以分箱\n",
    "    - 无法保证箱体样本数量均匀\n",
    "    - 信用分统计时常用等距分箱\n",
    "- 聚类分箱\n",
    "- 其他分箱：\n",
    "\n",
    "\n",
    "# 小结\n",
    "- 特征工程准备工作\n",
    "    - ER图\n",
    "    - 样本设计表\n",
    "    - 特征框架表\n",
    "- 特征构造方法\n",
    "    - 用户静态信息特征\n",
    "    - 用户时间截面特征\n",
    "    - 用户时间序列特征\n",
    "    - 用户关联特征\n",
    "- 缺失值处理\n",
    "    - 补零\n",
    "    - 风险趋势\n",
    "    - 增加缺失特征\n",
    "    - 业务默认值\n",
    "- 未来信息处理\n",
    "    - 快照表\n",
    "    - 将数据分却成是否包含未来信息分别处理\n",
    "- 特征构造标准\n",
    "    - 简单\n",
    "    - 归纳 + 演绎\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "f6f52991073d6313",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T07:00:01.812413Z",
     "start_time": "2025-03-09T07:00:00.181911Z"
    }
   },
   "source": [
    "# 导入Pandas包\n",
    "import pandas as pd\n",
    "# 导入numpy包\n",
    "import numpy as np\n",
    "\n",
    "# 加载数据\n",
    "data = pd.read_excel('./file/textdata.xlsx')\n",
    "'''\n",
    "数据信息：\n",
    "    数据条目：5\n",
    "    字段数量：26\n",
    "    为空字段：ft2、ft8、ft9、ft10、ft11、ft12、gt2、gt8、gt9、gt10、gt11、gt12\n",
    "    字段类型：float64(12), int64(14)\n",
    "    占用内存：1.1kB\n",
    "'''\n",
    "data.info()"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ffd6b4ce649997cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T10:22:04.386436Z",
     "start_time": "2025-01-04T10:22:04.382476Z"
    }
   },
   "source": [
    "'''\n",
    "loc[row_label, column_label]\n",
    "row_label：可以是单个行标签、行标签列表、行标签范围等。\n",
    "column_label：可以是单个列标签、列标签列表等。\n",
    "'''\n",
    "\n",
    "\n",
    "def Num(ft, p):\n",
    "    '''\n",
    "    计算最近P个月特征大于0的月份数\n",
    "    :param ft: \n",
    "    :param p: \n",
    "    :return: \n",
    "    '''\n",
    "    df = data.loc[:, ft + '1': ft + str(p)]\n",
    "    auto_value = np.where(df > 0, 1, 0).sum(axis=1)\n",
    "    temp = ft + '_num' + str(p)\n",
    "    return temp, auto_value"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d98ce21c95296ca7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T10:17:18.569431Z",
     "start_time": "2025-01-04T10:17:18.564311Z"
    }
   },
   "source": [
    "#最近p个月，ft=0的月份数\n",
    "def zero_cnt(ft, p):\n",
    "    '''\n",
    "    计算最近P个月特征ft等于0的月份数\n",
    "    :param ft: \n",
    "    :param p: \n",
    "    :return: \n",
    "    '''\n",
    "    df = data.loc[:, ft + '1':ft + str(p)]\n",
    "    auto_value = np.where(df == 0, 1, 0).sum(axis=1)\n",
    "    return ft + '_zero_cnt' + str(p), auto_value"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a15c6d2f7f8b547",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T10:17:37.961551Z",
     "start_time": "2025-01-04T10:17:37.957056Z"
    }
   },
   "source": [
    "def Evr(ft, p):\n",
    "    '''\n",
    "    计算近p个月特征ft大于0的月份数是否大于等于1\n",
    "    :param ft: \n",
    "    :param p: \n",
    "    :return: \n",
    "    '''\n",
    "    df = data.loc[:, ft + '1':ft + str(p)]\n",
    "    arr = np.where(df > 0, 1, 0).sum(axis=1)\n",
    "    auto_value = np.where(arr, 1, 0)\n",
    "    return ft + '_evr' + str(p), auto_value"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bfad9e76803ba9eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T10:17:52.824258Z",
     "start_time": "2025-01-04T10:17:52.820769Z"
    }
   },
   "source": [
    "def Avg(ft, p):\n",
    "    '''\n",
    "    计算最近p个月特征ft的均值\n",
    "    :param ft: \n",
    "    :param p: \n",
    "    :return: \n",
    "    '''\n",
    "    df = data.loc[:, ft + '1':ft + str(p)]\n",
    "    auto_value = np.nanmean(df, axis=1)\n",
    "    return ft + '_avg' + str(p), auto_value"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51c7330969dad472",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T10:18:44.997277Z",
     "start_time": "2025-01-04T10:18:44.988870Z"
    }
   },
   "source": [
    "'''\n",
    "计算最近p个月特征ft的和，最大值，最小值\n",
    "'''\n",
    "\n",
    "\n",
    "def Tot(ft, p):\n",
    "    '''\n",
    "    最近p个月，ft和\n",
    "    :param ft: \n",
    "    :param p: \n",
    "    :return: \n",
    "    '''\n",
    "    df = data.loc[:, ft + '1':ft + str(p)]\n",
    "    auto_value = np.nansum(df, axis=1)\n",
    "    return ft + '_tot' + str(p), auto_value\n",
    "\n",
    "\n",
    "def Tot2T(ft, p):\n",
    "    '''\n",
    "    最近(2,p+1)个月，ft和\n",
    "    :param ft: \n",
    "    :param p: \n",
    "    :return: \n",
    "    '''\n",
    "    df = data.loc[:, ft + '2':ft + str(p + 1)]\n",
    "    auto_value = df.sum(1)\n",
    "    return ft + '_tot2t' + str(p), auto_value\n",
    "\n",
    "\n",
    "def Max(ft, p):\n",
    "    '''\n",
    "    最近p个月，ft最大值\n",
    "    :param ft: \n",
    "    :param p: \n",
    "    :return: \n",
    "    '''\n",
    "    df = data.loc[:, ft + '1':ft + str(p)]\n",
    "    auto_value = np.nanmax(df, axis=1)\n",
    "    return ft + '_max' + str(p), auto_value\n",
    "\n",
    "\n",
    "def Min(ft, p):\n",
    "    '''\n",
    "    最近p个月，ft最小值\n",
    "    :param ft: \n",
    "    :param p: \n",
    "    :return: \n",
    "    '''\n",
    "    df = data.loc[:, ft + '1':ft + str(p)]\n",
    "    auto_value = np.nanmin(df, axis=1)\n",
    "    return ft + '_min' + str(p), auto_value"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2a0c8c0b17431412",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T10:42:57.415426Z",
     "start_time": "2025-01-04T10:42:57.288655Z"
    }
   },
   "source": [
    "'''\n",
    "其余衍生方法\n",
    "'''\n",
    "\n",
    "def Msg(ft,p):\n",
    "    '''\n",
    "    最近p个月，最近一次ft>0到现在的月份数\n",
    "    :param ft: \n",
    "    :param p: \n",
    "    :return: \n",
    "    '''\n",
    "    df=data.loc[:,ft+'1':ft+str(p)]\n",
    "    df_value=np.where(df>0,1,0)\n",
    "    auto_value=[]\n",
    "    for i in range(len(df_value)):\n",
    "        row_value=df_value[i,:]\n",
    "        if row_value.max()<=0:\n",
    "            indexs='0'\n",
    "            auto_value.append(indexs)\n",
    "        else:\n",
    "            indexs=1\n",
    "            for j in row_value:\n",
    "                if j>0:\n",
    "                    break\n",
    "                indexs+=1\n",
    "            auto_value.append(indexs)\n",
    "    return ft+'_msg'+str(p),auto_value\n",
    "\n",
    "\n",
    "def Msz(ft,p):\n",
    "    '''\n",
    "    最近p个月，最近一次ft=0到现在的月份数\n",
    "    :param ft: \n",
    "    :param p: \n",
    "    :return: \n",
    "    '''\n",
    "    df=data.loc[:,ft+'1':ft+str(p)]\n",
    "    df_value=np.where(df==0,1,0)\n",
    "    auto_value=[]\n",
    "    for i in range(len(df_value)):\n",
    "        row_value=df_value[i,:]\n",
    "        if row_value.max()<=0:\n",
    "            indexs='0'\n",
    "            auto_value.append(indexs)\n",
    "        else:\n",
    "            indexs=1\n",
    "            for j in row_value:\n",
    "                if j>0:\n",
    "                    break\n",
    "                indexs+=1\n",
    "            auto_value.append(indexs)\n",
    "    return ft+'_msz'+str(p),auto_value\n",
    "\n",
    "def Cav(ft,p):\n",
    "    '''\n",
    "    当月ft/(最近p个月ft的均值)\n",
    "    :param ft: \n",
    "    :param p: \n",
    "    :return: \n",
    "    '''\n",
    "    df=data.loc[:,ft+'1':ft+str(p)]\n",
    "    auto_value = df[ft+'1']/np.nanmean(df,axis = 1 )\n",
    "    return ft+'_cav'+str(p),auto_value\n",
    "\n",
    "def Cmn(ft,p):\n",
    "    '''\n",
    "    当月ft/(最近p个月ft的最小值)\n",
    "    :param ft: \n",
    "    :param p: \n",
    "    :return: \n",
    "    '''\n",
    "    df=data.loc[:,ft+'1':ft+str(p)]\n",
    "    auto_value = df[ft+'1']/np.nanmin(df,axis = 1 )\n",
    "    return ft+'_cmn'+str(p),auto_value\n",
    "\n",
    "def Mai(ft,p):\n",
    "    '''\n",
    "    最近p个月，每两个月间的ft的增长量的最大值\n",
    "    :param ft: \n",
    "    :param p: \n",
    "    :return: \n",
    "    '''\n",
    "    arr=np.array(data.loc[:,ft+'1':ft+str(p)])\n",
    "    auto_value = []\n",
    "    for i in range(len(arr)):\n",
    "        df_value = arr[i,:]\n",
    "        value_lst = []\n",
    "        for k in range(len(df_value)-1):\n",
    "            minus = df_value[k] - df_value[k+1]\n",
    "            value_lst.append(minus)\n",
    "        auto_value.append(np.nanmax(value_lst))\n",
    "    return ft+'_mai'+str(p),auto_value\n",
    "\n",
    "def Mad(ft,p):\n",
    "    '''\n",
    "    最近p个月，每两个月间的ft的减少量的最大值\n",
    "    :param ft: \n",
    "    :param p: \n",
    "    :return: \n",
    "    '''\n",
    "    arr=np.array(data.loc[:,ft+'1':ft+str(p)])\n",
    "    auto_value = []\n",
    "    for i in range(len(arr)):\n",
    "        df_value = arr[i,:]\n",
    "        value_lst = []\n",
    "        for k in range(len(df_value)-1):\n",
    "            minus = df_value[k+1] - df_value[k]\n",
    "            value_lst.append(minus)\n",
    "        auto_value.append(np.nanmax(value_lst))\n",
    "    return ft+'_mad'+str(p),auto_value\n",
    "\n",
    "def Std(ft,p):\n",
    "    '''\n",
    "    最近p个月，ft的标准差\n",
    "    :param ft: \n",
    "    :param p: \n",
    "    :return: \n",
    "    '''\n",
    "    df=data.loc[:,ft+'1':ft+str(p)]\n",
    "    auto_value=np.nanvar(df,axis = 1)\n",
    "    return ft+'_std'+str(p),auto_value\n",
    "\n",
    "def Cva(ft,p):\n",
    "    '''\n",
    "    最近p个月，ft的变异系数\n",
    "    :param ft: \n",
    "    :param p: \n",
    "    :return: \n",
    "    '''\n",
    "    df=data.loc[:,ft+'1':ft+str(p)]\n",
    "    auto_value=np.nanvar(df,axis = 1)/(np.nanmean(df,axis = 1 )+1e-10)\n",
    "    return ft+'_cva'+str(p),auto_value\n",
    "\n",
    "def Cmm(ft,p):\n",
    "    '''\n",
    "    (当月ft) - (最近p个月ft的均值)\n",
    "    :param ft: \n",
    "    :param p: \n",
    "    :return: \n",
    "    '''\n",
    "    df=data.loc[:,ft+'1':ft+str(p)]\n",
    "    auto_value = df[ft+'1'] - np.nanmean(df,axis = 1 )\n",
    "    return ft+'_cmm'+str(p),auto_value\n",
    "\n",
    "def Cnm(ft,p):\n",
    "    '''\n",
    "    (当月ft) - (最近p个月ft的最小值)\n",
    "    :param ft: \n",
    "    :param p: \n",
    "    :return: \n",
    "    '''\n",
    "    df=data.loc[:,ft+'1':ft+str(p)]\n",
    "    auto_value = df[ft+'1'] - np.nanmin(df,axis = 1 )\n",
    "    return ft+'_cnm'+str(p),auto_value\n",
    "\n",
    "def Cxm(ft,p):\n",
    "    '''\n",
    "    (当月ft) - (最近p个月ft的最大值)\n",
    "    :param ft: \n",
    "    :param p: \n",
    "    :return: \n",
    "    '''\n",
    "    df=data.loc[:,ft+'1':ft+str(p)]\n",
    "    auto_value = df[ft+'1'] - np.nanmax(df,axis = 1 )\n",
    "    return ft+'_cxm'+str(p),auto_value\n",
    "\n",
    "\n",
    "def Cxp(ft,p):\n",
    "    '''\n",
    "    ((当月ft) - (最近p个月ft的最大值) ） / (最近p个月ft的最大值))\n",
    "    :param ft: \n",
    "    :param p: \n",
    "    :return: \n",
    "    '''\n",
    "    df=data.loc[:,ft+'1':ft+str(p)]\n",
    "    temp = np.nanmax(df,axis = 1 )\n",
    "    auto_value = (df[ft+'1'] - temp )/ temp\n",
    "    return ft+'_cxp'+str(p),auto_value\n",
    "\n",
    "def Ran(ft,p):\n",
    "    '''\n",
    "    最近p个月，ft的极差\n",
    "    :param ft: \n",
    "    :param p: \n",
    "    :return: \n",
    "    '''\n",
    "    df=data.loc[:,ft+'1':ft+str(p)]\n",
    "    auto_value = np.nanmax(df,axis = 1 )  -  np.nanmin(df,axis = 1 )\n",
    "    return ft+'_ran'+str(p),auto_value\n",
    "\n",
    "def Nci(ft,p):\n",
    "    '''\n",
    "    最近p个月中，特征ft的值，后一个月相比于前一个月增长了的月份数\n",
    "    :param ft: \n",
    "    :param p: \n",
    "    :return: \n",
    "    '''\n",
    "    arr=np.array(data.loc[:,ft+'1':ft+str(p)])\n",
    "    auto_value = []\n",
    "    for i in range(len(arr)):\n",
    "        df_value = arr[i,:]\n",
    "        value_lst = []\n",
    "        for k in range(len(df_value)-1):\n",
    "            minus = df_value[k] - df_value[k+1]\n",
    "            value_lst.append(minus)\n",
    "        value_ng = np.where(np.array(value_lst)>0,1,0).sum()\n",
    "        auto_value.append(np.nanmax(value_ng))\n",
    "    return ft+'_nci'+str(p),auto_value\n",
    "\n",
    "def Ncd(ft,p):\n",
    "    '''\n",
    "    最近p个月中，特征ft的值，后一个月相比于前一个月减少了的月份数\n",
    "    :param ft: \n",
    "    :param p: \n",
    "    :return: \n",
    "    '''\n",
    "    arr=np.array(data.loc[:,ft+'1':ft+str(p)])\n",
    "    auto_value = []\n",
    "    for i in range(len(arr)):\n",
    "        df_value = arr[i,:]\n",
    "        value_lst = []\n",
    "        for k in range(len(df_value)-1):\n",
    "            minus = df_value[k] - df_value[k+1]\n",
    "            value_lst.append(minus)\n",
    "        value_ng = np.where(np.array(value_lst)<0,1,0).sum()\n",
    "        auto_value.append(np.nanmax(value_ng))\n",
    "    return ft+'_ncd'+str(p),auto_value\n",
    "\n",
    "def Ncn(ft,p):\n",
    "    '''\n",
    "    最近p个月中，相邻月份ft 相等的月份数\n",
    "    :param ft: \n",
    "    :param p: \n",
    "    :return: \n",
    "    '''\n",
    "    arr=np.array(data.loc[:,ft+'1':ft+str(p)])\n",
    "    auto_value = []\n",
    "    for i in range(len(arr)):\n",
    "        df_value = arr[i,:]\n",
    "        value_lst = []\n",
    "        for k in range(len(df_value)-1):\n",
    "            minus = df_value[k] - df_value[k+1]\n",
    "            value_lst.append(minus)\n",
    "        value_ng = np.where(np.array(value_lst)==0,1,0).sum()\n",
    "        auto_value.append(np.nanmax(value_ng))\n",
    "    return ft+'_ncn'+str(p),auto_value\n",
    "\n",
    "def Bup(ft,p):\n",
    "    '''\n",
    "    最近P个月中，特征ft的值是否按月份严格递增，是返回1，否返回0\n",
    "    :param ft: \n",
    "    :param p: \n",
    "    :return: \n",
    "    '''\n",
    "    arr=np.array(data.loc[:,ft+'1':ft+str(p)])\n",
    "    auto_value = []\n",
    "    for i in range(len(arr)):\n",
    "        df_value = arr[i,:]\n",
    "        value_lst = []\n",
    "        index = 0\n",
    "        for k in range(len(df_value)-1):\n",
    "            if df_value[k] > df_value[k+1]:\n",
    "                break\n",
    "            index =+ 1\n",
    "        if index == p:\n",
    "            value= 1\n",
    "        else:\n",
    "            value = 0\n",
    "        auto_value.append(value)\n",
    "    return ft+'_bup'+str(p),auto_value\n",
    "\n",
    "def Pdn(ft,p):\n",
    "    '''\n",
    "    最近P个月中，特征ft的值是否按月份严格递减，是返回1，否返回0\n",
    "    :param ft: \n",
    "    :param p: \n",
    "    :return: \n",
    "    '''\n",
    "    arr=np.array(data.loc[:,ft+'1':ft+str(p)])\n",
    "    auto_value = []\n",
    "    for i in range(len(arr)):\n",
    "        df_value = arr[i,:]\n",
    "        value_lst = []\n",
    "        index = 0\n",
    "        for k in range(len(df_value)-1):\n",
    "            if df_value[k+1] > df_value[k]:\n",
    "                break\n",
    "            index =+ 1\n",
    "        if index == p:\n",
    "            value= 1\n",
    "        else:\n",
    "            value = 0\n",
    "        auto_value.append(value)\n",
    "    return ft+'_pdn'+str(p),auto_value\n",
    "\n",
    "def Trm(ft,p):\n",
    "    '''\n",
    "    最近P个月中，ft的切尾均值，这里去掉了数据中的最大值和最小值\n",
    "    :param ft: \n",
    "    :param p: \n",
    "    :return: \n",
    "    '''\n",
    "    df=data.loc[:,ft+'1':ft+str(p)]\n",
    "    auto_value = []\n",
    "    for i in range(len(df)):\n",
    "        trm_mean = list(df.loc[i,:])\n",
    "        trm_mean.remove(np.nanmax(trm_mean))\n",
    "        trm_mean.remove(np.nanmin(trm_mean))\n",
    "        temp=np.nanmean(trm_mean)\n",
    "        auto_value.append(temp)\n",
    "    return ft+'_trm'+str(p),auto_value\n",
    "\n",
    "def Cmx(ft,p):\n",
    "    '''\n",
    "    当月ft / 最近p个月的ft中的最大值\n",
    "    :param ft: \n",
    "    :param p: \n",
    "    :return: \n",
    "    '''\n",
    "    df=data.loc[:,ft+'1':ft+str(p)]\n",
    "    auto_value = (df[ft+'1'] - np.nanmax(df,axis = 1 )) /np.nanmax(df,axis = 1 )\n",
    "    return ft+'_cmx'+str(p),auto_value\n",
    "\n",
    "def Cmp(ft,p):\n",
    "    '''\n",
    "    ( 当月ft - 最近p个月的ft均值 ) / ft均值\n",
    "    :param ft: \n",
    "    :param p: \n",
    "    :return: \n",
    "    '''\n",
    "    df=data.loc[:,ft+'1':ft+str(p)]\n",
    "    auto_value = (df[ft+'1'] - np.nanmean(df,axis = 1 )) /np.nanmean(df,axis = 1 )\n",
    "    return ft+'_cmp'+str(p),auto_value\n",
    "\n",
    "def Cnp(ft,p):\n",
    "    '''\n",
    "    ( 当月ft - 最近p个月的ft最小值 ) /ft最小值 \n",
    "    :param ft: \n",
    "    :param p: \n",
    "    :return: \n",
    "    '''\n",
    "    df=data.loc[:,ft+'1':ft+str(p)]\n",
    "    auto_value = (df[ft+'1'] - np.nanmin(df,axis = 1 )) /np.nanmin(df,axis = 1 )\n",
    "    return ft+'_cnp'+str(p),auto_value\n",
    "\n",
    "def Msx(ft,p):\n",
    "    '''\n",
    "    最近p个月取最大值的月份距现在的月份数\n",
    "    :param ft: \n",
    "    :param p: \n",
    "    :return: \n",
    "    '''\n",
    "    df=data.loc[:,ft+'1':ft+str(p)]\n",
    "    df['_max'] = np.nanmax(df,axis = 1)\n",
    "    for i in range(1,p+1):\n",
    "        df[ft+str(i)] = list(df[ft+str(i)] == df['_max'])\n",
    "    del df['_max']\n",
    "    df_value = np.where(df==True,1,0)\n",
    "    auto_value=[]\n",
    "    for i in range(len(df_value)):\n",
    "        row_value=df_value[i,:]\n",
    "        indexs=1\n",
    "        for j in row_value:\n",
    "            if j == 1:\n",
    "                break\n",
    "            indexs+=1\n",
    "        auto_value.append(indexs)\n",
    "    return ft+'_msx'+str(p),auto_value\n",
    "\n",
    "\n",
    "def Rpp(ft,p):\n",
    "    '''\n",
    "    最近p个月的均值/((p,2p)个月的ft均值)\n",
    "    :param ft: \n",
    "    :param p: \n",
    "    :return: \n",
    "    '''\n",
    "    df1=data.loc[:,ft+'1':ft+str(p)]\n",
    "    value1=np.nanmean(df1,axis = 1 )\n",
    "    df2=data.loc[:,ft+str(p):ft+str(2*p)]\n",
    "    value2=np.nanmean(df2,axis = 1 )\n",
    "    auto_value = value1/value2\n",
    "    return ft+'_rpp'+str(p),auto_value\n",
    "\n",
    "\n",
    "def Dpp(ft,p):\n",
    "    '''\n",
    "    最近p个月的均值 - ((p,2p)个月的ft均值)\n",
    "    :param ft: \n",
    "    :param p: \n",
    "    :return: \n",
    "    '''\n",
    "    df1=data.loc[:,ft+'1':ft+str(p)]\n",
    "    value1=np.nanmean(df1,axis = 1 )\n",
    "    df2=data.loc[:,ft+str(p):ft+str(2*p)]\n",
    "    value2=np.nanmean(df2,axis = 1 )\n",
    "    auto_value = value1 - value2\n",
    "    return ft+'_dpp'+str(p),auto_value\n",
    "\n",
    "\n",
    "def Mpp(ft,p):\n",
    "    '''\n",
    "    (最近p个月的ft最大值)/ (最近(p,2p)个月的ft最大值)\n",
    "    :param ft: \n",
    "    :param p: \n",
    "    :return: \n",
    "    '''\n",
    "    df1=data.loc[:,ft+'1':ft+str(p)]\n",
    "    value1=np.nanmax(df1,axis = 1 )\n",
    "    df2=data.loc[:,ft+str(p):ft+str(2*p)]\n",
    "    value2=np.nanmax(df2,axis = 1 )\n",
    "    auto_value = value1/value2\n",
    "    return ft+'_mpp'+str(p),auto_value\n",
    "\n",
    "\n",
    "def Npp(ft,p):\n",
    "    '''\n",
    "    (最近p个月的ft最小值)/ (最近(p,2p)个月的ft最小值)\n",
    "    :param ft: \n",
    "    :param p: \n",
    "    :return: \n",
    "    '''\n",
    "    df1=data.loc[:,ft+'1':ft+str(p)]\n",
    "    value1=np.nanmin(df1,axis = 1 )\n",
    "    df2=data.loc[:,ft+str(p):ft+str(2*p)]\n",
    "    value2=np.nanmin(df2,axis = 1 )\n",
    "    auto_value = value1/value2\n",
    "    return ft+'_npp'+str(p),auto_value"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e25c9c1d5e7b5223",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T10:43:47.107807Z",
     "start_time": "2025-01-04T10:43:47.089410Z"
    }
   },
   "source": [
    "#定义批量调用双参数的函数        \n",
    "def auto_var2(feature,p):\n",
    "    #global data_new\n",
    "    try:\n",
    "        columns_name,values=Num(feature,p)\n",
    "        data_new[columns_name]=values\n",
    "    except:\n",
    "        print(\"Num PARSE ERROR\",feature,p)\n",
    "    try:\n",
    "        columns_name,values=Nmz(feature,p)\n",
    "        data_new[columns_name]=values\n",
    "    except:\n",
    "        print(\"Nmz PARSE ERROR\",feature,p)\n",
    "    try:\n",
    "        columns_name,values=Evr(feature,p)\n",
    "        data_new[columns_name]=values\n",
    "    except:\n",
    "        print(\"Evr PARSE ERROR\",feature,p)\n",
    "    try:\n",
    "        columns_name,values=Avg(feature,p)\n",
    "        data_new[columns_name]=values\n",
    "    except:\n",
    "        print(\"Avg PARSE ERROR\",feature,p)\n",
    "    try:\n",
    "        columns_name,values=Tot(feature,p)\n",
    "        data_new[columns_name]=values\n",
    "    except:\n",
    "        print(\"Tot PARSE ERROR\",feature,p)\n",
    "    try:\n",
    "        columns_name,values=Tot2T(feature,p)\n",
    "        data_new[columns_name]=values\n",
    "    except:\n",
    "        print(\"Tot2T PARSE ERROR\",feature,p)\n",
    "    try:\n",
    "        columns_name,values=Max(feature,p)\n",
    "        data_new[columns_name]=values\n",
    "    except:\n",
    "        print(\"Tot PARSE ERROR\",feature,p)\n",
    "    try:\n",
    "        columns_name,values=Max(feature,p)\n",
    "        data_new[columns_name]=values\n",
    "    except:\n",
    "        print(\"Max PARSE ERROR\",feature,p)\n",
    "    try:\n",
    "        columns_name,values=Min(feature,p)\n",
    "        data_new[columns_name]=values\n",
    "    except:\n",
    "        print(\"Min PARSE ERROR\",feature,p)\n",
    "    try:\n",
    "        columns_name,values=Msg(feature,p)\n",
    "        data_new[columns_name]=values\n",
    "    except:\n",
    "        print(\"Msg PARSE ERROR\",feature,p)\n",
    "    try:\n",
    "        columns_name,values=Msz(feature,p)\n",
    "        data_new[columns_name]=values\n",
    "    except:\n",
    "        print(\"Msz PARSE ERROR\",feature,p)\n",
    "    try:\n",
    "        columns_name,values=Cav(feature,p)\n",
    "        data_new[columns_name]=values\n",
    "    except:\n",
    "        print(\"Cav PARSE ERROR\",feature,p)\n",
    "    try:\n",
    "        columns_name,values=Cmn(feature,p)\n",
    "        data_new[columns_name]=values\n",
    "    except:\n",
    "        print(\"Cmn PARSE ERROR\",feature,p)\n",
    "    try:\n",
    "        columns_name,values=Std(feature,p)\n",
    "        data_new[columns_name]=values\n",
    "    except:\n",
    "        print(\"Std PARSE ERROR\",feature,p)\n",
    "    try:\n",
    "        columns_name,values=Cva(feature,p)\n",
    "        data_new[columns_name]=values\n",
    "    except:\n",
    "        print(\"Cva PARSE ERROR\",feature,p)\n",
    "    try:\n",
    "        columns_name,values=Cmm(feature,p)\n",
    "        data_new[columns_name]=values\n",
    "    except:\n",
    "        print(\"Cmm PARSE ERROR\",feature,p)\n",
    "    try:\n",
    "        columns_name,values=Cnm(feature,p)\n",
    "        data_new[columns_name]=values\n",
    "    except:\n",
    "        print(\"Cnm PARSE ERROR\",feature,p)\n",
    "    try:\n",
    "        columns_name,values=Cxm(feature,p)\n",
    "        data_new[columns_name]=values\n",
    "    except:\n",
    "        print(\"Cxm PARSE ERROR\",feature,p)\n",
    "    try:\n",
    "        columns_name,values=Cxp(feature,p)\n",
    "        data_new[columns_name]=values\n",
    "    except:\n",
    "        print(\"Cxp PARSE ERROR\",feature,p)\n",
    "    try:\n",
    "        columns_name,values=Ran(feature,p)\n",
    "        data_new[columns_name]=values\n",
    "    except:\n",
    "        print(\"Ran PARSE ERROR\",feature,p)\n",
    "    try:\n",
    "        columns_name,values=Nci(feature,p)\n",
    "        data_new[columns_name]=values\n",
    "    except:\n",
    "        print(\"Nci PARSE ERROR\",feature,p)\n",
    "    try:\n",
    "        columns_name,values=Ncd(feature,p)\n",
    "        data_new[columns_name]=values\n",
    "    except:\n",
    "        print(\"Ncd PARSE ERROR\",feature,p)\n",
    "    try:\n",
    "        columns_name,values=Ncn(feature,p)\n",
    "        data_new[columns_name]=values\n",
    "    except:\n",
    "        print(\"Ncn PARSE ERROR\",feature,p)\n",
    "    try:\n",
    "        columns_name,values=Pdn(feature,p)\n",
    "        data_new[columns_name]=values\n",
    "    except:\n",
    "        print(\"Pdn PARSE ERROR\",feature,p)\n",
    "    try:\n",
    "        columns_name,values=Cmx(feature,p)\n",
    "        data_new[columns_name]=values\n",
    "    except:\n",
    "        print(\"Cmx PARSE ERROR\",feature,p)\n",
    "    try:\n",
    "        columns_name,values=Cmp(feature,p)\n",
    "        data_new[columns_name]=values\n",
    "    except:\n",
    "        print(\"Cmp PARSE ERROR\",feature,p)\n",
    "    try:\n",
    "        columns_name,values=Cnp(feature,p)\n",
    "        data_new[columns_name]=values\n",
    "    except:\n",
    "        print(\"Cnp PARSE ERROR\",feature,p)\n",
    "    try:\n",
    "        columns_name,values=Msx(feature,p)\n",
    "        data_new[columns_name]=values\n",
    "    except:\n",
    "        print(\"Msx PARSE ERROR\",feature,p)\n",
    "    try:\n",
    "        columns_name,values=Nci(feature,p)\n",
    "        data_new[columns_name]=values\n",
    "    except:\n",
    "        print(\"Nci PARSE ERROR\",feature,p)\n",
    "    try:\n",
    "        columns_name,values=Trm(feature,p)\n",
    "        data_new[columns_name]=values\n",
    "    except:\n",
    "        print(\"Trm PARSE ERROR\",feature,p)\n",
    "    try:\n",
    "        columns_name,values=Bup(feature,p)\n",
    "        data_new[columns_name]=values\n",
    "    except:\n",
    "        print(\"Bup PARSE ERROR\",feature,p)\n",
    "    try:\n",
    "        columns_name,values=Mai(feature,p)\n",
    "        data_new[columns_name]=values\n",
    "    except:\n",
    "        print(\"Mai PARSE ERROR\",feature,p)\n",
    "    try:\n",
    "        columns_name,values=Mad(feature,p)\n",
    "        data_new[columns_name]=values\n",
    "    except:\n",
    "        print(\"Mad PARSE ERROR\",feature,p)\n",
    "    try:\n",
    "        columns_name,values=Rpp(feature,p)\n",
    "        data_new[columns_name]=values\n",
    "    except:\n",
    "        print(\"Rpp PARSE ERROR\",feature,p)\n",
    "    try:\n",
    "        columns_name,values=Dpp(feature,p)\n",
    "        data_new[columns_name]=values\n",
    "    except:\n",
    "        print(\"Dpp PARSE ERROR\",feature,p)\n",
    "    try:\n",
    "        columns_name,values=Mpp(feature,p)\n",
    "        data_new[columns_name]=values\n",
    "    except:\n",
    "        print(\"Mpp PARSE ERROR\",feature,p)\n",
    "    try:\n",
    "        columns_name,values=Npp(feature,p)\n",
    "        data_new[columns_name]=values\n",
    "    except:\n",
    "        print(\"Npp PARSE ERROR\",feature,p)\n",
    "    return data_new.columns.size"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6aac4a24271a1148",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T10:45:20.843535Z",
     "start_time": "2025-01-04T10:45:20.109804Z"
    }
   },
   "source": [
    "data_new = pd.DataFrame()\n",
    "for p in range(1, 12):\n",
    "    for inv in ['ft', 'gt']:\n",
    "        auto_var2(inv, p)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a0a2dcc753d63c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T10:45:28.984707Z",
     "start_time": "2025-01-04T10:45:28.975694Z"
    }
   },
   "source": [
    "data_new.columns.tolist()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "af9aa3023c6fb6d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T11:25:48.156825Z",
     "start_time": "2025-01-05T11:25:48.127860Z"
    }
   },
   "source": [
    "# 导入Pandas包\n",
    "import pandas as pd\n",
    "# 导入numpy包\n",
    "import numpy as np\n",
    "# 导入toad库\n",
    "import toad\n",
    "\n",
    "data = pd.read_csv('./file/germancredit.csv')\n",
    "replace_dict = {\n",
    "    'good': 0,\n",
    "    'bad': 1\n",
    "}\n",
    "data.replace(replace_dict, inplace = True)\n",
    "print(data.shape)\n",
    "'''\n",
    "字段说明：\n",
    "    Status of existing checking account（现有支票帐户的存款状态）\n",
    "    Duration in month（持续月数）\n",
    "    Credit history（信用历史记录）\n",
    "    Purpose（申请目的）\n",
    "    Credit amount（信用保证金额）\n",
    "    Savings account/bonds（储蓄账户/债券金额）\n",
    "    Present employment since（当前就业年限）\n",
    "    Installment rate in percentage of disposable income（可支配收入占比）\n",
    "    Personal status and gender（个人婚姻状态及性别）\n",
    "    Other debtors / guarantors（其他债务人或担保人）\n",
    "    Present residence since（当前居民年限）\n",
    "    Property（财产）\n",
    "    Age in years（年龄）\n",
    "    Other installment plans （其他分期付款计划）\n",
    "    Housing（房屋状况）\n",
    "    Number of existing credits at this bank（在该银行已有的信用卡数）\n",
    "    Job（工作性质）\n",
    "    Number of people being liable to provide maintenance for（可提供维护人数）\n",
    "    Telephone（是否留存电话）\n",
    "    foreign worker（是否外国工人）\n",
    "    creditability 数据标签\n",
    "'''\n",
    "data.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af0455054b831a0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T08:19:48.320750Z",
     "start_time": "2025-01-05T08:19:41.080082Z"
    }
   },
   "source": [
    "!pip install toad"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "53e8a12604c0c5f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T11:25:51.403995Z",
     "start_time": "2025-01-05T11:25:51.302186Z"
    }
   },
   "source": [
    "# 初始化一个combiner类\n",
    "combiner = toad.transform.Combiner()\n",
    "\n",
    "'''\n",
    "训练数据并指定分箱方法，其他参数可以选，\n",
    "min_samples:每箱包含样本数量，可以是数字或者是占比\n",
    "'''\n",
    "combiner.fit(data, y = 'creditability', method = 'chi', min_samples = 0.05)\n",
    "\n",
    "# 以字段形式保存分箱结果\n",
    "bins = combiner.export()\n",
    "\n",
    "# 查看分箱结果\n",
    "print('duration.in.month:', bins['duration.in.month'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "98a8360524ceff37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T11:25:53.435663Z",
     "start_time": "2025-01-05T11:25:52.947838Z"
    }
   },
   "source": [
    "# 导入pyplot包\n",
    "import matplotlib.pyplot as plt\n",
    "# Matplotlib 绘图直接嵌入到 Notebook 的输出单元中\n",
    "%matplotlib inline\n",
    "'''\n",
    "Toad是一个功能强大的Python库，专为数据分析、特征工程和信用评分等任务设计。它提供了一系列便捷的工具，帮助数据科学家和分析师高效地进行数据预处理、探索性数据分析（EDA）、特征选择与转换，以及模型评估等工作。\n",
    "'''\n",
    "from toad.plot import bin_plot\n",
    "c2 = toad.transform.Combiner()\n",
    "temp_data = data[['duration.in.month','creditability']]\n",
    "c2.fit(temp_data, y = 'creditability', method = 'chi', n_bins = 7)\n",
    "transformed = c2.transform(temp_data, labels = True)\n",
    "\n",
    "# 传给bin_plot的数据必须是分箱转化后的\n",
    "bin_plot(transformed, x = 'duration.in.month', target = 'creditability')\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8ef4684676a87eaf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T11:25:55.408406Z",
     "start_time": "2025-01-05T11:25:55.398731Z"
    }
   },
   "source": [
    "'''\n",
    "上图中柱形图标志每一箱的占比，折线图表示每一箱的坏样本率，一般折线图要呈现出单调的趋势\n",
    "可以通过调整箱数实现单调趋势\n",
    "'''\n",
    "c2 = toad.transform.Combiner()\n",
    "\n",
    "temp_data = data[['duration.in.month','creditability']]\n",
    "c2.fit(temp_data, y = 'creditability', method = 'chi', n_bins = 5)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f5c7274c693173c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T11:30:52.559712Z",
     "start_time": "2025-01-05T11:30:50.327519Z"
    }
   },
   "source": [
    "'''\n",
    "其它分箱方法：聚类分箱（k-means), 决策树分箱，等频分箱，等距分箱\n",
    "各种分箱方法对比\n",
    "\n",
    "'chi'：卡方分箱。这种方法通过计算卡方值来确定分箱的边界，使得每个箱内的样本在目标变量上的分布尽可能均匀。\n",
    "'dt'：决策树分箱。这种方法使用决策树算法来确定分箱的边界，通常可以得到更自然的分箱结果。\n",
    "'quantile'：分位数分箱。这种方法将数据按照分位数进行分箱，每个箱内的样本数量大致相等。\n",
    "'step'：等宽分箱。这种方法将数据按照等宽的区间进行分箱，每个箱的宽度相同。\n",
    "'kmeans'：K均值分箱。这种方法使用 K均值聚类算法来确定分箱的边界，可以得到较为均衡的分箱结果。\n",
    "'''\n",
    "for method in ['chi', 'dt', 'quantile', 'step', 'kmeans']:\n",
    "    c2 = toad.transform.Combiner()\n",
    "    temp_data = data[['duration.in.month','creditability']]\n",
    "    c2.fit(temp_data, y = 'creditability', method = method, n_bins = 5)\n",
    "\n",
    "    c2.transform(temp_data, labels = True)\n",
    "    '''\n",
    "    toad.plot.bin_plot(frame, x=None, target='target', iv=True, annotate_format='.2f', return_frame=False, figsize=(12, 6))\n",
    "    frame：分箱后的数据框。\n",
    "    x：用于 x 轴的列名。\n",
    "    target：目标列名，默认为 'target'。\n",
    "    iv：是否显示 IV 值，默认为 True。\n",
    "    annotate_format：用于轴注释的格式字符串，默认为 '.2f'。\n",
    "    return_frame：是否返回分箱数据框，默认为 False。\n",
    "    figsize：图表的大小，默认为 (12, 6)。\n",
    "    \n",
    "    '''\n",
    "    bin_frame = c2.transform(temp_data, labels = True)\n",
    "    bin_plot(bin_frame, x = 'duration.in.month', target = 'creditability')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "58a608672f3f0317",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T11:47:50.357472Z",
     "start_time": "2025-01-05T11:47:49.845123Z"
    }
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "x = data.drop('creditability',axis=1)\n",
    "y = data['creditability']\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(x, y, test_size = 0.25, random_state = 450)\n",
    "data_train = pd.concat([X_train, Y_train], axis = 1)\n",
    "\n",
    "# 增加一列区分训练/测试的特征\n",
    "data_train['type'] = 'train'\n",
    "data_test = pd.concat([X_test,Y_test],axis=1)\n",
    "data_test['type'] = 'test'\n",
    "\n",
    "# 设置分箱边界\n",
    "adj_bin = {'duration.in.month': [9, 12, 18, 33]}\n",
    "\n",
    "c2 = toad.transform.Combiner()\n",
    "c2.set_rules(adj_bin)\n",
    "\n",
    "data_ = pd.concat([data_train, data_test], axis = 0)\n",
    "# 分箱\n",
    "temp_data = c2.transform(data_[['duration.in.month','creditability','type']])\n",
    "\n",
    "# 绘制badrate_plot图\n",
    "from toad.plot import badrate_plot, proportion_plot\n",
    "badrate_plot(temp_data, target = 'creditability', x = 'type', by = 'duration.in.month')\n",
    "\n",
    "# 绘制每一箱占比情况图\n",
    "proportion_plot(temp_data['duration.in.month'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c9c24d56a6d12699",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T11:51:34.131876Z",
     "start_time": "2025-01-05T11:51:33.883347Z"
    }
   },
   "source": [
    "# 上面第一张图中的第一箱和第二箱的bad_rate存在倒挂，说明bad_rate不单调，需要调整。可以将第一箱和第二箱进行合并\n",
    "\n",
    "# 嘉定将第一箱、第二箱合并\n",
    "adj_bin = {'duration.in.month': [9,18,33]}\n",
    "c2.set_rules(adj_bin)\n",
    "\n",
    "temp_data = c2.transform(data_[['duration.in.month','creditability','type']])\n",
    "badrate_plot(temp_data, target = 'creditability', x = 'type', by = 'duration.in.month')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "46825785c3af43f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T11:54:40.249118Z",
     "start_time": "2025-01-05T11:54:39.895283Z"
    }
   },
   "source": [
    "# 将特征值转化为分箱的箱号\n",
    "binned_data = c2.transform(data_train)\n",
    "\n",
    "# 计算WOE\n",
    "transer = toad.transform.WOETransformer()\n",
    "'''\n",
    "\n",
    "WOE理解：当前组中好用户和坏用户的比值与所有样本中这个比值的差异。差异通过对这两个比值取对数来表示\n",
    "WOE越大，差异越大，这个分组里的好用户的可能性就越大\n",
    "WOE越小，差异越小，这个分组里的好用户的可能性也就越小。\n",
    "分箱结果对WOE结果有直接影响，分箱不同，WOE映射值也会有很大的不同\n",
    "箱的总数在5～10箱（可以适当调整，通常不超过10箱）\n",
    "并且将每一箱之间的负样本占比差值尽可能大作为箱合并的基本原则\n",
    "每一箱的样本量不能小于整体样本的5%，原则是每一箱的频数需要具有统计意义\n",
    "三种encoding的利弊\n",
    "\n",
    "'''\n",
    "\n",
    "# 对WOE的值进行转化，映射到元数据集上，对训练集使用fit_transform, 测试集使用transform\n",
    "data_tr_woe = transer.fit_transform(binned_data, binned_data['creditability'], exclude=['creditability','type'])\n",
    "data_tr_woe.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c4d76ac927486e99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T11:33:56.784023Z",
     "start_time": "2025-01-05T11:33:56.762810Z"
    }
   },
   "source": [
    "data.drop('creditability',axis=1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bf426a877c895760",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T11:29:52.813057Z",
     "start_time": "2025-01-05T11:29:52.451908Z"
    }
   },
   "source": [
    "import toad\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# 数据载入\n",
    "iris = load_iris()\n",
    "target = iris['target']\n",
    "iris = pd.DataFrame(iris['data'], columns=iris['feature_names'])\n",
    "iris['target'] = target\n",
    "\n",
    "# 分箱\n",
    "c = toad.transform.Combiner()\n",
    "c.fit(iris, y='target', method='chi', min_samples=0.05)\n",
    "\n",
    "# 画分箱图\n",
    "from toad.plot import bin_plot\n",
    "col = 'sepal length (cm)'\n",
    "bin_plot(c.transform(iris[[col, 'target']], labels=True), x=col, target='target', figsize = [4, 3])"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
