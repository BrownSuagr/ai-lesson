{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 大模型介绍学习目标：\n",
    "- 大模型的基本概念\n",
    "- 什么是语言模型，常见的语言模型有哪些\n",
    "- 大模型有哪些评估指标\n",
    "- LLM主要架构类别有哪些类别，分别介绍\n",
    "\n",
    "\n",
    "# 1、什么是大模型（LLM）？\n",
    "定义：参数量超过百亿的模型，才能被称为大模型\n",
    "\n",
    "# 2、什么是语言模型？\n",
    "- 定义：判断一句话发生的概率（你可以把语言模型想象成一个“猜词游戏”高手）\n",
    "- 标准：假如一个句子为s=[w1, w2, w3, ··· wn]语言模型是计算当前句子发生的概率，即：P(s)=P(w1, w2, w3, ··· wn)如果符合人类日常用语表达，P(s)就更大，否则就是小\n",
    "- 分类：\n",
    "N-gram 是“统计词组”，神经网络模型是“理解词义”，Transformer 是“理解语言与推理”。\n",
    "\n",
    "# 3、大模型评估有哪些指标？（精确率、召回率、F1-Secore）\n",
    "- BLEU指标：评估文本翻译质量（BLEU值范围0～1，值越大翻译质量越好，反之越差）BLUE更关注准确率\n",
    "- ROUGE指标：均可以衡量生成结果和标准结果的匹配度，不同的是ROUGE基于召回率\n",
    "![ppl公式](./img/ppl公式.png)\n",
    "- 困惑度PPL：PPL是用来衡量一个概率分布或者概率模型预测样本的好坏\n",
    "\n",
    "# 4、LLM主要架构有哪些类型？（下面分类都是基于Transformer架构）\n",
    "![transformer架构](./img/transformer架构.png)\n",
    "- Encoder-Only(自编码模型)：对于输入文本进行随机mask，利用上下文来预测mask；代表模型BERT\n",
    "- Decoder-Only（自回归模型）：一般从左到右，有上文生成下文；代表模型GPT\n",
    "- Encoder-Decoder（序列到序列模型）：将所有的NLP任务，转换为统一架构格式（文本生成任务）：text2text；代表模型T5\n",
    "\n",
    "\n"
   ],
   "id": "e97dc0d139679e75"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T07:33:35.656488Z",
     "start_time": "2025-06-02T07:33:35.646746Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 导入torch机器学习模型核心模块\n",
    "import torch\n",
    "# 导入自然语言处理工具包nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "# 导入数学公式包\n",
    "import math\n",
    "\n",
    "def cumulative_bleu(references, candidates):\n",
    "    '''\n",
    "    评估生成文本与参考文本相似性的一种方法\n",
    "    :param references: \n",
    "    :param candidates: \n",
    "    :return: \n",
    "    '''\n",
    "    function = SmoothingFunction()\n",
    "    \n",
    "    bleu_one_gram = sentence_bleu(references, candidates, weights=(1, 0, 0, 0), smoothing_function=function.method1)\n",
    "    bleu_two_gram = sentence_bleu(references, candidates, weights=(0.5, 0.5, 0, 0), smoothing_function=function.method1)\n",
    "    bleu_three_gram = sentence_bleu(references, candidates, weights=(0.33, 0.33, 0.33, 0), smoothing_function=function.method1)\n",
    "    bleu_four_gram = sentence_bleu(references, candidates, weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=function.method1)\n",
    "    \n",
    "    return bleu_one_gram, bleu_two_gram, bleu_three_gram, bleu_four_gram\n",
    "\n",
    "# 1、生成文本\n",
    "candidate_text = [\"This\", \"is\",  \"some\",  \"generated\", \"text\"]\n",
    "\n",
    "# 2、参照文本列表\n",
    "reference_texts =[[\"This\", \"is\",  \"a\",  \"reference\", \"text\"]]\n",
    "\n",
    "# 3、计算出BLEU指标\n",
    "c_bleu = cumulative_bleu(reference_texts, candidate_text)\n",
    "print(f'The bleu score is {c_bleu}')"
   ],
   "id": "570b597f8ec96d05",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bleu score is (0.6, 0.3872983346207417, 0.17404441896107775, 0.12574334296829354)\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T07:45:25.320887Z",
     "start_time": "2025-06-02T07:45:25.314197Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 导入rouge模块\n",
    "from rouge import Rouge\n",
    "\n",
    "# 生成的文本\n",
    "generated_text = \"This is some generated text.\"\n",
    "# 参考文本\n",
    "reference_text = [\"This is another generated reference text.\"]\n",
    "\n",
    "# 计算GOUGE指标\n",
    "rouge = Rouge()\n",
    "scores_arr = rouge.get_scores(generated_text, reference_text[0])\n",
    "print(f'scores:{scores_arr}')\n",
    "\n",
    "# 打印结果\n",
    "rouge_one = scores_arr[0][\"rouge-1\"]\n",
    "# print(f'rouge_one:{rouge_one}')\n",
    "# \n",
    "# print(rouge_one[\"p\"])\n",
    "\n",
    "print(f'ROUGE-1 precision: {rouge_one[\"p\"]}')\n",
    "print(f'ROUGE-1 recall: {rouge_one[\"r\"]}')\n",
    "print(f'ROUGE-1 f1-score: {rouge_one[\"f\"]}')"
   ],
   "id": "5b229dabe5991ccf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores:[{'rouge-1': {'r': 0.6666666666666666, 'p': 0.8, 'f': 0.7272727223140496}, 'rouge-2': {'r': 0.2, 'p': 0.25, 'f': 0.22222221728395072}, 'rouge-l': {'r': 0.6666666666666666, 'p': 0.8, 'f': 0.7272727223140496}}]\n",
      "ROUGE-1 precision: 0.8\n",
      "ROUGE-1 recall: 0.6666666666666666\n",
      "ROUGE-1 f1-score: 0.7272727223140496\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T08:15:01.126100Z",
     "start_time": "2025-06-02T08:15:01.118570Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 导入math库\n",
    "import math\n",
    "# 定义语料库\n",
    "sentences = [\n",
    "    ['I', 'have', 'a', 'pen'],\n",
    "    ['He', 'has', 'a', 'book'],\n",
    "    ['She', 'has', 'a', 'cat']\n",
    "]\n",
    "\n",
    "# 定义语言模型\n",
    "unigram = {\n",
    "    'I': 1/12, \n",
    "    'have': 1/12, \n",
    "    'a': 3/12, \n",
    "    'pen': 1/12,\n",
    "    'He': 1/12, \n",
    "    'has': 2/12,\n",
    "    'book': 1/12,\n",
    "    'She': 1/12, \n",
    "    'cat': 1/12\n",
    "}\n",
    "\n",
    "perplexity = 0\n",
    "for sentence in sentences:\n",
    "    sentence_prob = 1\n",
    "    # print(f'sentence :{sentence}')\n",
    "    for word in sentence:\n",
    "        sentence_prob *= unigram[word]\n",
    "        # print(f'word :{word}')\n",
    "    # 计算 log(sentence_prob)^2\n",
    "    temp = -math.log(sentence_prob, 2)/ len(sentence)\n",
    "    # 计算 perplexity = perplexity + x^temp\n",
    "    perplexity += 2**temp\n",
    "perplexity = perplexity /len(sentences)\n",
    "print(f'困惑度：{perplexity}')\n"
   ],
   "id": "53f897d7bc7db58f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "困惑度：8.150887576576553\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T08:11:59.528299Z",
     "start_time": "2025-06-02T08:11:59.516738Z"
    }
   },
   "cell_type": "code",
   "source": "math.log(1, 2)",
   "id": "5b8c7faa140e3273",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "200ab0a135888bb8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
