{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# PyTorch框架学习目标：\n",
    "- 知道什么是PyTorch框架，相比于TensorFlow有哪些异同点\n",
    "- PyTorch框架有哪些特点\n",
    "- PyTorch发展史有哪些重要节点\n",
    "- 学习张量，知道其基本创建方式、特点，以及基本运算、索引、转换方法\n",
    "- 学习自动微分和梯度基本计算\n",
    "- 使用PyTorch构建基本线性模型\n",
    "\n",
    "\n",
    "# 1、什么是pyTorch框架？\n",
    "概念：PyTorch是基于Python的科学计算包\n",
    "```bash\n",
    "pip install torch -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "```\n",
    "\n",
    "# 2、PyTorch有哪些特点？\n",
    "- 类似于NumPy的张量计算：PyTorch中基本结构是张量（Tensor），它与NumPy中数组类似，但是PyTorch张量具有CPU加速的能力（通过CUDA），这使得深度学习模型能够高效的在GPU中运行\n",
    "- 自动微分系统：\n",
    "    - PyTorch提供了强大的自动微分功能（AutoGrad模块），能够自动计算模型中每个参数梯度，\n",
    "    - 自动唯粉使得梯度计算过程变得简洁高效，并且支持复杂的模型和动态计算图\n",
    "- 深度学习库：\n",
    "    - PyTorch提供了一个名为torch.nn的子模块，用于构建神经网络，它包括了大量的预构建曾层（如全联接层、卷积层、循环神经网络层），损失函数（如交叉熵、均方误差），以及优化算法（SGD、Adam等）\n",
    "    - torch.nn.module是PyTorch中构建神经网络的基础类，用户可以通过继承该类来定义自己的神经网络架构\n",
    "- 动态图计算：\n",
    "    - PyTorch使用动态计算机制，允许在运行时构建和修改模型结构，具有更高的灵活性，适合于研究人员进行实验和模型调试\n",
    "- GPU加速（CUDA支持：CUDA是NVIDIA开发的一种并行计算平台和编程模型，允许利用GPU加速计算密集型任务）：\n",
    "    - PyTorch提供对GPU的良好支持，可以轻松的将模型和数据从CPU转移到GPU或从一个GPU转移到GPU上，PyTorch回自动优化计算过程\n",
    "- 跨平台支持：\n",
    "    - PyTorch支持在多种硬件平台（如：CPU、GPU、TPU）上运行，并且支持不同的操作系统（Linux、Windows、MacOS）以及分布式计算环境（多GPU、分布式训练）\n",
    "\n",
    "# 3、PyTorch发展历史\n",
    "\n",
    "![PyTorch发展史](./file/PyTorch发展史.png)\n",
    "\n",
    "- Torch最早的是Torch框架，由Ronan·Collobert和Clement·Farabet等人开发，是一个科学计算框架，提供了多维张量操作可算计算工具\n",
    "- Torch7是Torch的一个后续版本，引入了Lua编程语言，随着pytorch的普及，Torch便不再维护，Torch7也就成为了Torch的最后一个版本。\n",
    "- Pytorch 0.1.0：是Facebook人工智能研究院（FAIR）于2016年发布了PyTorch的第一个版本，标志着PyTorch的正式诞生。\n",
    "- Pytorch 0.2.0：该版本首次引入了动态图机制，使得用户能够在构建神经网络时更加灵活。作为Pytorch后期制胜tensorflow的关键机制，该版本象征着Pytorch进入了一个新的阶段。\n",
    "- Pytorch 1.0.0：2018年发布了Pytorch的首个稳定版本，引入了Eager模式简化了模型的构建和训练过程。\n",
    "- Pytorch 2.0：Pytorch2.0引入了torch.compile，可以支持对训练过程的加速，同时引入了TorchDynamo，主要替换torch.jit.trace和torch.jit.script。另外在这个版本中编译器性能大幅提升，分布式运行方面也做了一定的优化。\n",
    "\n",
    "# 什么是张量？\n",
    "定义：张量（Tensor）是一种数学对象，也是在物理学和工程学中广泛使用的概念。它是一种多维数组，可以表示为一个n维数组，其中n是张量的阶数。张量在不同的领域有不同的应用和解释。\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "de4078022501cedb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T06:31:44.427407Z",
     "start_time": "2025-03-23T06:31:39.966584Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install torch -i https://pypi.tuna.tsinghua.edu.cn/simple",
   "id": "edacb791ab2b8c9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\r\n",
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.9/site-packages (2.2.2)\r\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.9/site-packages (from torch) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/lib/python3.9/site-packages (from torch) (4.12.2)\r\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.9/site-packages (from torch) (1.13.3)\r\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.9/site-packages (from torch) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.9/site-packages (from torch) (3.1.5)\r\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.9/site-packages (from torch) (2024.12.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.9/site-packages (from jinja2->torch) (3.0.2)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\r\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T06:31:54.240401Z",
     "start_time": "2025-03-23T06:31:54.198901Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch  # 需要安装torch模块\n",
    "import numpy as np\n",
    "\n",
    "# torch.tensor(data=, dtype=) 根据指定数据创建张量\n",
    "# 1.创建张量标量（data=, dtype=）\n",
    "data = torch.tensor(10)\n",
    "print(data)\n",
    "\n",
    "# 2.numpy数组，犹豫data为float64，张量元素类型也是float64\n",
    "data = np.random.randn(2, 3)\n",
    "data = torch.tensor(data)\n",
    "print(data)\n",
    "\n",
    "# 3.列表、浮点数默认都是flaot32\n",
    "data = [[10, 20, 30], [40, 50, 60]]\n",
    "data = torch.tensor(data)\n",
    "print(data)"
   ],
   "id": "c9ccaf69f6596041",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10)\n",
      "tensor([[ 0.7359, -1.0309,  1.4773],\n",
      "        [-0.3313, -1.3127, -0.1331]])\n",
      "tensor([[10, 20, 30],\n",
      "        [40, 50, 60]])\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T06:32:11.100080Z",
     "start_time": "2025-03-23T06:32:11.089073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# torch.Tensor(size=) 根据形状来创建张量\n",
    "# 1、创建一个2行3列的张量，默认dtype为float32\n",
    "data = torch.Tensor(2, 3)\n",
    "print(data)\n",
    "\n",
    "# 2、如果传递列表代表，则包含创建包含指定元素的张量\n",
    "data = torch.Tensor([10])\n",
    "print(data)\n",
    "\n",
    "data = torch.Tensor([10, 20])\n",
    "print(data)"
   ],
   "id": "94ee1badfcd1d5a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([10.])\n",
      "tensor([10., 20.])\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T06:32:23.434940Z",
     "start_time": "2025-03-23T06:32:23.426063Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# torch.IntTensor()/torch.FloatTensor() 创建指定类型的张量\n",
    "\n",
    "# 1、创建2行3列，dtype为int32的张量\n",
    "data = torch.IntTensor(2, 3)\n",
    "print(f'2行3列，dtype为int32的张量：{data}')\n",
    "\n",
    "# 2、如果传入的元素类型不正确，则回进行类型转换\n",
    "#data = torch.IntTensor([2.5, 3.3])\n",
    "#print(f'类型转换张量：{data}')\n",
    "\n",
    "# 3、其他类型\n",
    "data = torch.ShortTensor()  # int16\n",
    "print(f'int16类型张量：{data}')\n",
    "\n",
    "data = torch.LongTensor()  # int64\n",
    "print(f'int64类型张量：{data}')\n",
    "\n",
    "data = torch.FloatTensor()  # float32\n",
    "print(f'float32类型张量：{data}')\n",
    "\n",
    "data = torch.DoubleTensor()  # float64\n",
    "print(f'float64类型张量：{data}')"
   ],
   "id": "ecd7bc3be72c99fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2行3列，dtype为int32的张量：tensor([[0, 0, 0],\n",
      "        [0, 0, 0]], dtype=torch.int32)\n",
      "int16类型张量：tensor([], dtype=torch.int16)\n",
      "int64类型张量：tensor([], dtype=torch.int64)\n",
      "float32类型张量：tensor([])\n",
      "float64类型张量：tensor([], dtype=torch.float64)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T06:32:29.043125Z",
     "start_time": "2025-03-23T06:32:29.026188Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 线性和随机张量\n",
    "\n",
    "# torch.arange(start=, end=, step=)：固定步长线性张量\n",
    "# 1、在指定区间按照补偿生成元素[start, end, steps]左闭右开\n",
    "data = torch.arange(0, 10, 2)\n",
    "print(data)\n",
    "\n",
    "# 2、在指定区间啊找元素个数生成[start, end, steps]左闭右闭\n",
    "# step = (end - start) /( step - 1)\n",
    "# value_i = start + step * i\n",
    "data = torch.linspace(0, 9, 10)\n",
    "print(data)"
   ],
   "id": "d45831a7fe5bb756",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 2, 4, 6, 8])\n",
      "tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T06:32:36.546413Z",
     "start_time": "2025-03-23T06:32:36.528380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# torch.randn/rand(size=) 创建随机浮点数类型张量\n",
    "# torch.randint(low=, high=, size=) 创建随机整数类型张量 左闭右开\n",
    "# torch.initial_seed() 和 torch.manual_seed(seed=) 随机种子设置\n",
    "\n",
    "# 1、创建随机张量\n",
    "data = torch.randn(2, 3)\n",
    "print(data)\n",
    "print(f'查看随机数种子：{torch.initial_seed()}')\n",
    "\n",
    "# 2、随机数种子设置\n",
    "torch.manual_seed(100)\n",
    "data = torch.randn(2, 3)\n",
    "print(data)\n",
    "print(f'随机数种子：{torch.initial_seed()}')\n",
    "\n"
   ],
   "id": "e1ae5bef275d6fc8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4337, -2.1093, -1.0010],\n",
      "        [ 0.4639, -1.2823, -1.4343]])\n",
      "查看随机数种子：4910714865061174651\n",
      "tensor([[ 0.3607, -0.2859, -0.3938],\n",
      "        [ 0.2429, -1.3833, -2.3134]])\n",
      "随机数种子：100\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T06:32:43.748117Z",
     "start_time": "2025-03-23T06:32:43.725278Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 指定值张量\n",
    "\n",
    "# torch.zeros(size=) 和 torch.zeros_like(input=) 创建全0张量\n",
    "# 1、创建指定形状全0张量\n",
    "data = torch.zeros(2, 3)\n",
    "print(f'创建指定形状全零张量:{data}')\n",
    "\n",
    "# 2、根据张量形状创建全0张量\n",
    "data = torch.zeros_like(data)\n",
    "print(f'根据传入张量形状创建全零张量：{data}')\n",
    "\n",
    "# torch.ones(size=) 和 torch.ones_like(input=) 创建全1张量\n",
    "# 3、创建指定形状全1张量\n",
    "data = torch.ones(2, 3)\n",
    "print(f'指定形状全一张量：{data}')\n",
    "\n",
    "data = torch.ones_like(data)\n",
    "print(f'根据输入张量形状创建全一张量：{data}')\n",
    "\n",
    "# torch.full(size=, fill_value=) 和 torch.full_like(input=, fill_value=) 创建全为指定值张量\n",
    "# 4、 创建指定形状指定值的张量\n",
    "data = torch.full([2, 3], 10)\n",
    "print(f'全为指定值张量:{data}')\n",
    "\n",
    "# 5、根据张量形状创建指定值的张量\n",
    "data = torch.full_like(data, 20)\n",
    "print(f'根据张量形状创建指定值的张量:{data}')\n"
   ],
   "id": "f8503d70defd155e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "创建指定形状全零张量:tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "根据传入张量形状创建全零张量：tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "指定形状全一张量：tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "根据输入张量形状创建全一张量：tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "全为指定值张量:tensor([[10, 10, 10],\n",
      "        [10, 10, 10]])\n",
      "根据张量形状创建指定值的张量:tensor([[20, 20, 20],\n",
      "        [20, 20, 20]])\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T06:32:50.693795Z",
     "start_time": "2025-03-23T06:32:50.677115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 指定元素类型张量\n",
    "# data.type(dtype=)\n",
    "data = torch.full([2, 3], 10)\n",
    "print(data.dtype)\n",
    "\n",
    "# 将 data 元素类型转换为 float64 类型\n",
    "data = data.type(torch.DoubleTensor)\n",
    "print(data.dtype)\n",
    "\n",
    "# 转换为其他类型\n",
    "data = data.type(torch.ShortTensor)\n",
    "data = data.type(torch.IntTensor)\n",
    "data = data.type(torch.LongTensor)\n",
    "data = data.type(torch.FloatTensor)\n",
    "data = data.type(dtype=torch.float16)\n",
    "\n",
    "# data.half/float/double/short/int/long()\n",
    "data = torch.full([2, 3], 10)\n",
    "print(data.dtype)\n",
    "# 将 data 元素类型转换为 float64 类型\n",
    "data = data.double()\n",
    "print(data.dtype)\n",
    "# 转换为其他类型\n",
    "# data = data.short()\n",
    "# data = data.int()\n",
    "# data = data.long()\n",
    "# data = data.float()\n"
   ],
   "id": "cbc360241f2b8150",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "torch.float64\n",
      "torch.int64\n",
      "torch.float64\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T06:32:58.865841Z",
     "start_time": "2025-03-23T06:32:57.489355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 张量类型转换\n",
    "\n",
    "# 使用 t.numpy() 函数可以将张量转换为 ndarray 数组，但是共享内存，可以使用copy函数避免共享。\n",
    "\n",
    "# 1、张量转换为NumPy数组\n",
    "data_tensor = torch.tensor([2, 3, 4])\n",
    "# 使用张量对象中的 numpy 函数进行转换\n",
    "data_numpy = data_tensor.numpy()\n",
    "print(type(data_tensor))\n",
    "print(type(data_numpy))\n",
    "# 注意: data_tensor 和 data_numpy 共享内存\n",
    "# 修改其中的一个，另外一个也会发生改变\n",
    "# data_tensor[0] = 100\n",
    "data_numpy[0] = 100\n",
    "print(data_tensor)\n",
    "print(data_numpy)\n",
    "\n",
    "# 2. 对象拷贝避免共享内存\n",
    "data_tensor = torch.tensor([2, 3, 4])\n",
    "# 使用张量对象中的 numpy 函数进行转换，通过copy方法拷贝对象\n",
    "data_numpy = data_tensor.numpy().copy()\n",
    "print(type(data_tensor))\n",
    "print(type(data_numpy))\n",
    "# 注意: data_tensor 和 data_numpy 此时不共享内存\n",
    "# 修改其中的一个，另外一个不会发生改变\n",
    "# data_tensor[0] = 100\n",
    "data_numpy[0] = 100\n",
    "print(data_tensor)\n",
    "print(data_numpy)\n"
   ],
   "id": "f4b56236b83f2901",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 8\u001B[0m\n\u001B[1;32m      6\u001B[0m data_tensor \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor([\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m4\u001B[39m])\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# 使用张量对象中的 numpy 函数进行转换\u001B[39;00m\n\u001B[0;32m----> 8\u001B[0m data_numpy \u001B[38;5;241m=\u001B[39m \u001B[43mdata_tensor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnumpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28mtype\u001B[39m(data_tensor))\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28mtype\u001B[39m(data_numpy))\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Numpy is not available"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T06:33:04.983854Z",
     "start_time": "2025-03-23T06:33:04.977513Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 当张量只包含一个元素时, 可以通过 item() 函数提取出该值\n",
    "data = torch.tensor([30, ])\n",
    "print(data.item())\n",
    "data = torch.tensor(30)\n",
    "print(data.item())"
   ],
   "id": "ce5266e39214d8c4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "30\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T06:33:13.276277Z",
     "start_time": "2025-03-23T06:33:13.248904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = torch.randint(0, 10, [2, 3])\n",
    "print(f'初始化张量:{data}')\n",
    "\n",
    "# 1. 不修改原数据\n",
    "new_data = data.add(10)  # 等价 new_data = data + 10\n",
    "print(f'张量+10:{data}')\n",
    "\n",
    "# 2. 直接修改原数据 注意: 带下划线的函数为修改原数据本身\n",
    "data.add_(10)\n",
    "print(f'张量再+10:{data}')\n",
    "\n",
    "# 3. 其他函数\n",
    "print(f'张量减100:{data.sub(100)}')\n",
    "print(f'张量乘100:{data.mul(100)}')\n",
    "print(f'张量除100:{data.div(100)}')\n",
    "print(f'张量除100:{data.neg()}')"
   ],
   "id": "6cb7bd9ad995b8f5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初始化张量:tensor([[8, 8, 4],\n",
      "        [4, 1, 0]])\n",
      "张量+10:tensor([[8, 8, 4],\n",
      "        [4, 1, 0]])\n",
      "张量再+10:tensor([[18, 18, 14],\n",
      "        [14, 11, 10]])\n",
      "张量减100:tensor([[-82, -82, -86],\n",
      "        [-86, -89, -90]])\n",
      "张量乘100:tensor([[1800, 1800, 1400],\n",
      "        [1400, 1100, 1000]])\n",
      "张量除100:tensor([[0.1800, 0.1800, 0.1400],\n",
      "        [0.1400, 0.1100, 0.1000]])\n",
      "张量除100:tensor([[-18, -18, -14],\n",
      "        [-14, -11, -10]])\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T06:33:20.690413Z",
     "start_time": "2025-03-23T06:33:20.681187Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 点乘运算\n",
    "data1 = torch.tensor([[1, 2], [3, 4]])\n",
    "data2 = torch.tensor([[5, 6], [7, 8]])\n",
    "# 第一种方式\n",
    "data = torch.mul(data1, data2)\n",
    "print(data)\n",
    "# 第二种方式\n",
    "data = data1 * data2\n",
    "print(data)"
   ],
   "id": "f25ffb8a3c84c5d5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5, 12],\n",
      "        [21, 32]])\n",
      "tensor([[ 5, 12],\n",
      "        [21, 32]])\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T06:33:26.227026Z",
     "start_time": "2025-03-23T06:33:26.203973Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 矩阵乘法运算\n",
    "# 点积运算\n",
    "data1 = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
    "data2 = torch.tensor([[5, 6], [7, 8]])\n",
    "# 方式一:\n",
    "data3 = data1 @ data2\n",
    "print(\"data3-->\", data3)\n",
    "# 方式二:\n",
    "data4 = torch.matmul(data1, data2)\n",
    "print(\"data4-->\", data4)"
   ],
   "id": "83c39d09dca574eb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data3--> tensor([[19, 22],\n",
      "        [43, 50],\n",
      "        [67, 78]])\n",
      "data4--> tensor([[19, 22],\n",
      "        [43, 50],\n",
      "        [67, 78]])\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T10:43:35.105099Z",
     "start_time": "2025-03-23T10:43:35.094607Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "张量运算函数\n",
    "tensor.mean(dim=):平均值\n",
    "tensor.sum(dim=):求和\n",
    "tensor.min/max(dim=):最小值/最大值\n",
    "tensor.pow(exponent=):幂次方 $$x^n$$\n",
    "tensor.sqrt(dim=):平方根\n",
    "tensor.exp():指数 $$e^x$$\n",
    "tensor.log(dim=):对数 以e为底\n",
    "dim=0按列计算,dim=1按行计算\n",
    "'''\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "def fundamental_operation():\n",
    "    data = torch.randint(0, 10, [2, 3], dtype=torch.float64)\n",
    "    print(data)\n",
    "    # 1. 计算均值\n",
    "    # 注意: tensor 必须为 Float 或者 Double 类型\n",
    "    print(data.mean())\n",
    "    print(data.mean(dim=0))  # 按列计算均值\n",
    "    print(data.mean(dim=1))  # 按行计算均值\n",
    "    # 2. 计算总和\n",
    "    print(data.sum())\n",
    "    print(data.sum(dim=0))\n",
    "    print(data.sum(dim=1))\n",
    "    # 3. 计算平方\n",
    "    print(torch.pow(data, 2))\n",
    "    # 4. 计算平方根\n",
    "    print(data.sqrt())\n",
    "    # 5. 指数计算, e^n 次方\n",
    "    print(data.exp())\n",
    "    # 6. 对数计算\n",
    "    print(data.log())  # 以 e 为底\n",
    "    print(data.log2())\n",
    "    print(data.log10())\n",
    "\n",
    "\n",
    "fundamental_operation()"
   ],
   "id": "8050034c006a71df",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7., 4., 8.],\n",
      "        [4., 4., 7.]], dtype=torch.float64)\n",
      "tensor(5.6667, dtype=torch.float64)\n",
      "tensor([5.5000, 4.0000, 7.5000], dtype=torch.float64)\n",
      "tensor([6.3333, 5.0000], dtype=torch.float64)\n",
      "tensor(34., dtype=torch.float64)\n",
      "tensor([11.,  8., 15.], dtype=torch.float64)\n",
      "tensor([19., 15.], dtype=torch.float64)\n",
      "tensor([[49., 16., 64.],\n",
      "        [16., 16., 49.]], dtype=torch.float64)\n",
      "tensor([[2.6458, 2.0000, 2.8284],\n",
      "        [2.0000, 2.0000, 2.6458]], dtype=torch.float64)\n",
      "tensor([[1096.6332,   54.5982, 2980.9580],\n",
      "        [  54.5982,   54.5982, 1096.6332]], dtype=torch.float64)\n",
      "tensor([[1.9459, 1.3863, 2.0794],\n",
      "        [1.3863, 1.3863, 1.9459]], dtype=torch.float64)\n",
      "tensor([[2.8074, 2.0000, 3.0000],\n",
      "        [2.0000, 2.0000, 2.8074]], dtype=torch.float64)\n",
      "tensor([[0.8451, 0.6021, 0.9031],\n",
      "        [0.6021, 0.6021, 0.8451]], dtype=torch.float64)\n"
     ]
    }
   ],
   "execution_count": 103
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T10:42:43.765058Z",
     "start_time": "2025-03-23T10:42:43.743601Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "'''\n",
    "张量索引操作\n",
    "我们在操作张量时，经常需要去获取某些元素就进行处理或者修改操作，在这里我们需要了解在torch中的索引操作。\n",
    "'''\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "def tensor_index():\n",
    "    # 随机生成数据 data[开始行(可省略默认：0): 行步长(可省略默认：1): 结束行(可省略默认：shape), 开始列(可省略默认：0): 列步长(可省略默认：1): 结束列(可省略默认：shape)]\n",
    "    data = torch.randint(0, 10, [4, 5])\n",
    "    print(f'随机生成张量：{data}')\n",
    "\n",
    "    # 1、简单行列索引\n",
    "    print(f'行索引：{data[0]}')\n",
    "    print(f'列索引：{data[:, 0]}')\n",
    "\n",
    "    # 2、列表索引\n",
    "    print(f'返回(0, 1)和(1, 2)对应位置数据：{data[[0, 1], [1, 2]]}')\n",
    "    print(f'返回0、1行的1、2列共4个元素：{data[:2, 1:3]}')\n",
    "    print(f'返回0、1行的1、2列共4个元素：{data[[[0], [1]], [1, 2]]}')\n",
    "\n",
    "    # 3、范围索引\n",
    "    print(f'前三行前两列数据：{data[:3, :2]}')\n",
    "    print(f'第二行到最后的前两列数据：{data[2:, :2]}')\n",
    "\n",
    "    # 4、布尔索引\n",
    "    print(f'第三列大于5的行数据:{data[:, :3][data[:, :3] > 5]}')\n",
    "    print(f'第二行大于5的数据：{data[:, [1]][data[:, [1]] > 5]}')\n",
    "    print(f'第二行大于5的数据：{data[:, 1:2][data[:, 1:2] > 5]}')\n",
    "\n",
    "    # 5、多维索引\n",
    "    data = torch.randint(0, 10, [3, 4, 5])\n",
    "    print(f'随机生成三维数据：{data}')\n",
    "    print(f'获取0轴上第一个数据：{data[0, :, :]}')\n",
    "    print(f'获取0轴上第一个数据：{data[[0]]}')\n",
    "\n",
    "    print(f'获取0轴上第一个数据：{data[[1]]}')\n",
    "    print(f'获取1轴上第一个数据：{data[:, 0, :]}')\n",
    "    print(f'获取2轴上第一个数据：{data[:, :, 0]}')\n",
    "\n",
    "\n",
    "tensor_index()"
   ],
   "id": "5f712379eda08afe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "随机生成张量：tensor([[6, 6, 4, 5, 2],\n",
      "        [2, 4, 0, 9, 6],\n",
      "        [5, 8, 2, 8, 2],\n",
      "        [3, 1, 5, 9, 1]])\n",
      "行索引：tensor([6, 6, 4, 5, 2])\n",
      "列索引：tensor([6, 2, 5, 3])\n",
      "返回(0, 1)和(1, 2)对应位置数据：tensor([6, 0])\n",
      "返回0、1行的1、2列共4个元素：tensor([[6, 4],\n",
      "        [4, 0]])\n",
      "返回0、1行的1、2列共4个元素：tensor([[6, 4],\n",
      "        [4, 0]])\n",
      "前三行前两列数据：tensor([[6, 6],\n",
      "        [2, 4],\n",
      "        [5, 8]])\n",
      "第二行到最后的前两列数据：tensor([[5, 8],\n",
      "        [3, 1]])\n",
      "第三列大于5的行数据:tensor([6, 6, 8])\n",
      "第二行大于5的数据：tensor([6, 8])\n",
      "第二行大于5的数据：tensor([6, 8])\n",
      "随机生成三维数据：tensor([[[7, 0, 9, 8, 0],\n",
      "         [7, 9, 7, 9, 7],\n",
      "         [2, 0, 4, 0, 7],\n",
      "         [0, 9, 6, 0, 0]],\n",
      "\n",
      "        [[1, 1, 2, 5, 3],\n",
      "         [7, 1, 3, 1, 5],\n",
      "         [9, 2, 2, 1, 5],\n",
      "         [3, 8, 7, 4, 3]],\n",
      "\n",
      "        [[0, 9, 4, 7, 9],\n",
      "         [6, 4, 6, 3, 2],\n",
      "         [1, 4, 1, 4, 4],\n",
      "         [3, 7, 4, 8, 2]]])\n",
      "获取0轴上第一个数据：tensor([[7, 0, 9, 8, 0],\n",
      "        [7, 9, 7, 9, 7],\n",
      "        [2, 0, 4, 0, 7],\n",
      "        [0, 9, 6, 0, 0]])\n",
      "获取0轴上第一个数据：tensor([[[7, 0, 9, 8, 0],\n",
      "         [7, 9, 7, 9, 7],\n",
      "         [2, 0, 4, 0, 7],\n",
      "         [0, 9, 6, 0, 0]]])\n",
      "获取0轴上第一个数据：tensor([[[1, 1, 2, 5, 3],\n",
      "         [7, 1, 3, 1, 5],\n",
      "         [9, 2, 2, 1, 5],\n",
      "         [3, 8, 7, 4, 3]]])\n",
      "获取1轴上第一个数据：tensor([[7, 0, 9, 8, 0],\n",
      "        [1, 1, 2, 5, 3],\n",
      "        [0, 9, 4, 7, 9]])\n",
      "获取2轴上第一个数据：tensor([[7, 7, 2, 0],\n",
      "        [1, 7, 9, 3],\n",
      "        [0, 6, 1, 3]])\n"
     ]
    }
   ],
   "execution_count": 100
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T10:44:24.217767Z",
     "start_time": "2025-03-23T10:44:24.176012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def reshape():\n",
    "    # 张量形状操作\n",
    "    data = torch.tensor([[10, 20, 30], [40, 50, 60]])\n",
    "    # 1. 使用 shape 属性或者 size 方法都可以获得张量的形状\n",
    "    print(data.shape, data.shape[0], data.shape[1])\n",
    "    print(data.size(), data.size(0), data.size(1))\n",
    "\n",
    "    # 2. 使用 reshape 函数修改张量形状\n",
    "    new_data = data.reshape(1, 6)\n",
    "    print(new_data.shape)\n",
    "\n",
    "    data = torch.randint(0, 10, [3, 4, 5, 6, 7])\n",
    "    print(f'张量：{data}')\n",
    "    print(f'张量形状：{data.shape}')\n",
    "    print(f'张量形状：{data.shape[0]}')\n",
    "    print(f'张量形状：{data.shape[1]}')\n",
    "    print(f'张量形状：{data.shape[2]}')\n",
    "    print(f'张量形状：{data.shape[3]}')\n",
    "\n",
    "    print(f'张量形状：{data.size(0)}')\n",
    "    print(f'张量形状：{data.size(1)}')\n",
    "    print(f'张量形状：{data.size(2)}')\n",
    "    print(f'张量形状：{data.size(3)}')\n",
    "\n",
    "    # 2. 使用 reshape 函数修改张量形状\n",
    "    reshape_data = data.reshape([3, 2, 5, 6, 14])\n",
    "    print(f'张量修改形状(总数不变)：{reshape_data}')\n",
    "    print(reshape_data.shape)\n",
    "\n",
    "    data = torch.tensor([[10, 20, 30], [40, 50, 60]])\n",
    "    # 1. 使用 shape 属性或者 size 方法都可以获得张量的形状\n",
    "    print(data.shape, data.shape[0], data.shape[1])\n",
    "    print(data.size(), data.size(0), data.size(1))\n",
    "\n",
    "    # 2. 使用 reshape 函数修改张量形状\n",
    "    new_data = data.reshape(1, 6)\n",
    "    print(new_data.shape)\n",
    "\n",
    "\n",
    "reshape()"
   ],
   "id": "80a1fb2f6f0348e3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3]) 2 3\n",
      "torch.Size([2, 3]) 2 3\n",
      "torch.Size([1, 6])\n",
      "张量：tensor([[[[[9, 7, 4,  ..., 3, 2, 4],\n",
      "           [6, 1, 0,  ..., 7, 7, 9],\n",
      "           [1, 7, 1,  ..., 9, 4, 9],\n",
      "           [0, 8, 5,  ..., 6, 2, 5],\n",
      "           [3, 4, 6,  ..., 8, 4, 7],\n",
      "           [1, 3, 8,  ..., 1, 3, 4]],\n",
      "\n",
      "          [[5, 5, 3,  ..., 9, 7, 3],\n",
      "           [1, 7, 7,  ..., 3, 6, 1],\n",
      "           [3, 0, 5,  ..., 7, 9, 6],\n",
      "           [3, 7, 1,  ..., 6, 3, 0],\n",
      "           [6, 1, 8,  ..., 8, 1, 6],\n",
      "           [5, 0, 8,  ..., 6, 9, 7]],\n",
      "\n",
      "          [[7, 1, 9,  ..., 7, 4, 9],\n",
      "           [2, 1, 9,  ..., 9, 4, 3],\n",
      "           [6, 5, 9,  ..., 7, 6, 0],\n",
      "           [1, 1, 1,  ..., 4, 6, 2],\n",
      "           [9, 9, 6,  ..., 9, 4, 1],\n",
      "           [2, 4, 7,  ..., 4, 9, 2]],\n",
      "\n",
      "          [[3, 6, 4,  ..., 6, 2, 8],\n",
      "           [9, 8, 1,  ..., 2, 4, 4],\n",
      "           [3, 0, 1,  ..., 6, 5, 5],\n",
      "           [9, 7, 3,  ..., 2, 8, 6],\n",
      "           [5, 0, 4,  ..., 5, 0, 0],\n",
      "           [1, 7, 2,  ..., 5, 0, 5]],\n",
      "\n",
      "          [[0, 6, 3,  ..., 4, 2, 4],\n",
      "           [5, 6, 4,  ..., 8, 9, 7],\n",
      "           [5, 3, 7,  ..., 5, 2, 8],\n",
      "           [4, 8, 2,  ..., 6, 8, 2],\n",
      "           [6, 7, 2,  ..., 3, 9, 4],\n",
      "           [0, 4, 9,  ..., 0, 9, 1]]],\n",
      "\n",
      "\n",
      "         [[[2, 2, 9,  ..., 6, 3, 7],\n",
      "           [0, 3, 1,  ..., 6, 7, 2],\n",
      "           [4, 7, 5,  ..., 6, 5, 0],\n",
      "           [4, 3, 0,  ..., 0, 7, 0],\n",
      "           [0, 7, 1,  ..., 5, 6, 6],\n",
      "           [4, 8, 0,  ..., 4, 0, 2]],\n",
      "\n",
      "          [[8, 0, 9,  ..., 9, 1, 8],\n",
      "           [7, 1, 5,  ..., 4, 9, 6],\n",
      "           [9, 9, 5,  ..., 2, 4, 2],\n",
      "           [4, 6, 4,  ..., 6, 6, 7],\n",
      "           [7, 3, 8,  ..., 7, 3, 0],\n",
      "           [4, 3, 9,  ..., 8, 1, 5]],\n",
      "\n",
      "          [[7, 5, 0,  ..., 1, 0, 4],\n",
      "           [3, 6, 3,  ..., 2, 9, 3],\n",
      "           [5, 8, 0,  ..., 0, 9, 9],\n",
      "           [2, 1, 4,  ..., 1, 4, 8],\n",
      "           [4, 0, 6,  ..., 6, 6, 1],\n",
      "           [5, 6, 3,  ..., 4, 8, 5]],\n",
      "\n",
      "          [[7, 4, 1,  ..., 7, 8, 0],\n",
      "           [7, 2, 3,  ..., 3, 9, 5],\n",
      "           [8, 1, 7,  ..., 6, 2, 9],\n",
      "           [4, 3, 3,  ..., 6, 4, 3],\n",
      "           [1, 2, 2,  ..., 3, 4, 9],\n",
      "           [7, 1, 9,  ..., 5, 5, 2]],\n",
      "\n",
      "          [[5, 9, 8,  ..., 5, 0, 5],\n",
      "           [0, 9, 3,  ..., 3, 3, 9],\n",
      "           [0, 0, 2,  ..., 8, 6, 9],\n",
      "           [1, 1, 5,  ..., 5, 4, 7],\n",
      "           [8, 5, 9,  ..., 2, 8, 5],\n",
      "           [2, 7, 2,  ..., 1, 5, 0]]],\n",
      "\n",
      "\n",
      "         [[[8, 2, 4,  ..., 5, 8, 0],\n",
      "           [6, 2, 6,  ..., 2, 5, 6],\n",
      "           [3, 6, 1,  ..., 4, 1, 3],\n",
      "           [2, 1, 7,  ..., 0, 7, 6],\n",
      "           [5, 8, 9,  ..., 7, 4, 3],\n",
      "           [2, 8, 1,  ..., 6, 8, 3]],\n",
      "\n",
      "          [[4, 6, 6,  ..., 5, 5, 2],\n",
      "           [0, 0, 5,  ..., 6, 1, 0],\n",
      "           [7, 8, 5,  ..., 3, 1, 7],\n",
      "           [3, 3, 9,  ..., 7, 2, 2],\n",
      "           [3, 9, 7,  ..., 6, 9, 0],\n",
      "           [3, 2, 6,  ..., 8, 7, 6]],\n",
      "\n",
      "          [[7, 0, 8,  ..., 1, 7, 8],\n",
      "           [5, 3, 3,  ..., 0, 2, 4],\n",
      "           [9, 6, 0,  ..., 7, 5, 8],\n",
      "           [4, 3, 6,  ..., 5, 3, 3],\n",
      "           [2, 1, 4,  ..., 1, 7, 3],\n",
      "           [5, 7, 7,  ..., 8, 0, 4]],\n",
      "\n",
      "          [[3, 9, 7,  ..., 3, 8, 2],\n",
      "           [5, 2, 3,  ..., 0, 5, 1],\n",
      "           [9, 0, 1,  ..., 1, 5, 1],\n",
      "           [6, 0, 4,  ..., 4, 3, 6],\n",
      "           [5, 8, 6,  ..., 2, 8, 0],\n",
      "           [8, 6, 4,  ..., 0, 4, 1]],\n",
      "\n",
      "          [[8, 7, 6,  ..., 2, 3, 5],\n",
      "           [4, 7, 4,  ..., 7, 6, 1],\n",
      "           [8, 7, 9,  ..., 8, 8, 3],\n",
      "           [5, 2, 4,  ..., 0, 6, 2],\n",
      "           [9, 7, 3,  ..., 0, 9, 2],\n",
      "           [8, 9, 0,  ..., 9, 9, 5]]],\n",
      "\n",
      "\n",
      "         [[[0, 2, 3,  ..., 5, 2, 4],\n",
      "           [0, 6, 0,  ..., 1, 9, 1],\n",
      "           [5, 8, 6,  ..., 8, 0, 5],\n",
      "           [9, 5, 2,  ..., 5, 9, 3],\n",
      "           [2, 0, 1,  ..., 7, 7, 2],\n",
      "           [7, 4, 0,  ..., 1, 3, 7]],\n",
      "\n",
      "          [[5, 4, 4,  ..., 0, 5, 8],\n",
      "           [9, 9, 3,  ..., 8, 8, 2],\n",
      "           [6, 1, 3,  ..., 4, 1, 3],\n",
      "           [8, 4, 0,  ..., 9, 0, 1],\n",
      "           [1, 1, 5,  ..., 4, 2, 4],\n",
      "           [5, 5, 6,  ..., 5, 9, 9]],\n",
      "\n",
      "          [[9, 2, 7,  ..., 1, 9, 7],\n",
      "           [2, 0, 9,  ..., 2, 7, 3],\n",
      "           [7, 4, 7,  ..., 2, 3, 5],\n",
      "           [4, 3, 3,  ..., 6, 2, 0],\n",
      "           [9, 0, 2,  ..., 6, 8, 1],\n",
      "           [4, 4, 1,  ..., 1, 4, 3]],\n",
      "\n",
      "          [[7, 3, 0,  ..., 9, 4, 1],\n",
      "           [2, 2, 7,  ..., 5, 8, 3],\n",
      "           [6, 9, 3,  ..., 4, 1, 2],\n",
      "           [1, 2, 4,  ..., 2, 6, 1],\n",
      "           [6, 3, 1,  ..., 0, 0, 1],\n",
      "           [0, 0, 2,  ..., 2, 0, 6]],\n",
      "\n",
      "          [[7, 3, 6,  ..., 6, 1, 9],\n",
      "           [8, 8, 0,  ..., 6, 7, 6],\n",
      "           [3, 2, 9,  ..., 9, 6, 2],\n",
      "           [3, 4, 3,  ..., 6, 2, 7],\n",
      "           [1, 2, 9,  ..., 4, 6, 2],\n",
      "           [6, 3, 8,  ..., 6, 3, 4]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[2, 5, 1,  ..., 1, 5, 0],\n",
      "           [9, 6, 4,  ..., 6, 6, 2],\n",
      "           [8, 9, 1,  ..., 8, 2, 3],\n",
      "           [0, 3, 1,  ..., 4, 4, 5],\n",
      "           [7, 9, 7,  ..., 1, 4, 7],\n",
      "           [5, 6, 5,  ..., 9, 3, 3]],\n",
      "\n",
      "          [[7, 5, 2,  ..., 7, 7, 1],\n",
      "           [4, 1, 4,  ..., 1, 0, 6],\n",
      "           [2, 0, 0,  ..., 8, 6, 8],\n",
      "           [2, 1, 5,  ..., 8, 8, 5],\n",
      "           [6, 2, 2,  ..., 0, 7, 9],\n",
      "           [8, 8, 3,  ..., 6, 5, 6]],\n",
      "\n",
      "          [[5, 8, 0,  ..., 4, 2, 9],\n",
      "           [6, 1, 0,  ..., 6, 0, 9],\n",
      "           [1, 7, 3,  ..., 6, 2, 8],\n",
      "           [0, 0, 2,  ..., 7, 9, 8],\n",
      "           [7, 5, 5,  ..., 0, 4, 3],\n",
      "           [9, 3, 1,  ..., 0, 7, 5]],\n",
      "\n",
      "          [[3, 6, 3,  ..., 3, 8, 8],\n",
      "           [6, 7, 3,  ..., 1, 5, 8],\n",
      "           [5, 2, 2,  ..., 0, 8, 0],\n",
      "           [2, 9, 6,  ..., 1, 6, 3],\n",
      "           [9, 2, 0,  ..., 1, 4, 0],\n",
      "           [4, 6, 7,  ..., 5, 2, 5]],\n",
      "\n",
      "          [[6, 6, 6,  ..., 1, 0, 9],\n",
      "           [5, 8, 5,  ..., 0, 5, 3],\n",
      "           [3, 4, 7,  ..., 4, 6, 7],\n",
      "           [3, 9, 8,  ..., 2, 9, 3],\n",
      "           [1, 2, 2,  ..., 4, 2, 2],\n",
      "           [6, 9, 1,  ..., 0, 0, 9]]],\n",
      "\n",
      "\n",
      "         [[[3, 6, 4,  ..., 4, 5, 8],\n",
      "           [3, 7, 3,  ..., 5, 5, 2],\n",
      "           [2, 4, 8,  ..., 7, 0, 7],\n",
      "           [0, 7, 6,  ..., 6, 2, 0],\n",
      "           [0, 5, 7,  ..., 7, 2, 3],\n",
      "           [9, 9, 4,  ..., 2, 9, 4]],\n",
      "\n",
      "          [[8, 6, 3,  ..., 3, 9, 5],\n",
      "           [9, 0, 5,  ..., 3, 3, 1],\n",
      "           [3, 7, 4,  ..., 5, 5, 8],\n",
      "           [9, 6, 4,  ..., 1, 6, 0],\n",
      "           [5, 3, 2,  ..., 3, 7, 8],\n",
      "           [0, 4, 6,  ..., 4, 8, 4]],\n",
      "\n",
      "          [[1, 3, 6,  ..., 7, 5, 2],\n",
      "           [5, 8, 3,  ..., 6, 7, 7],\n",
      "           [7, 5, 7,  ..., 0, 0, 3],\n",
      "           [6, 0, 5,  ..., 0, 0, 7],\n",
      "           [9, 7, 0,  ..., 2, 3, 6],\n",
      "           [8, 1, 3,  ..., 6, 4, 0]],\n",
      "\n",
      "          [[1, 2, 1,  ..., 2, 9, 0],\n",
      "           [0, 0, 5,  ..., 7, 8, 0],\n",
      "           [4, 9, 2,  ..., 1, 4, 3],\n",
      "           [1, 2, 3,  ..., 9, 2, 0],\n",
      "           [4, 5, 9,  ..., 6, 3, 5],\n",
      "           [7, 7, 6,  ..., 3, 9, 6]],\n",
      "\n",
      "          [[1, 4, 5,  ..., 5, 2, 2],\n",
      "           [3, 5, 9,  ..., 4, 2, 9],\n",
      "           [3, 2, 2,  ..., 8, 1, 4],\n",
      "           [3, 0, 2,  ..., 0, 7, 8],\n",
      "           [5, 8, 2,  ..., 7, 4, 0],\n",
      "           [1, 3, 5,  ..., 9, 9, 4]]],\n",
      "\n",
      "\n",
      "         [[[4, 8, 7,  ..., 7, 2, 3],\n",
      "           [7, 2, 5,  ..., 8, 1, 8],\n",
      "           [6, 4, 5,  ..., 5, 6, 2],\n",
      "           [8, 1, 1,  ..., 8, 1, 2],\n",
      "           [0, 2, 8,  ..., 4, 6, 6],\n",
      "           [7, 6, 2,  ..., 4, 6, 3]],\n",
      "\n",
      "          [[4, 1, 6,  ..., 0, 3, 5],\n",
      "           [9, 2, 5,  ..., 7, 9, 2],\n",
      "           [9, 4, 4,  ..., 6, 0, 2],\n",
      "           [2, 6, 2,  ..., 7, 5, 4],\n",
      "           [6, 6, 8,  ..., 8, 3, 6],\n",
      "           [9, 0, 6,  ..., 8, 0, 9]],\n",
      "\n",
      "          [[1, 7, 0,  ..., 8, 4, 0],\n",
      "           [2, 4, 5,  ..., 6, 5, 2],\n",
      "           [6, 7, 0,  ..., 8, 7, 9],\n",
      "           [7, 1, 2,  ..., 7, 1, 3],\n",
      "           [1, 8, 1,  ..., 5, 7, 3],\n",
      "           [7, 8, 0,  ..., 9, 1, 9]],\n",
      "\n",
      "          [[8, 5, 2,  ..., 7, 7, 0],\n",
      "           [9, 9, 4,  ..., 9, 5, 0],\n",
      "           [6, 1, 3,  ..., 1, 9, 4],\n",
      "           [1, 4, 3,  ..., 2, 2, 2],\n",
      "           [3, 6, 2,  ..., 1, 3, 8],\n",
      "           [2, 2, 2,  ..., 2, 2, 6]],\n",
      "\n",
      "          [[5, 1, 1,  ..., 8, 3, 3],\n",
      "           [1, 3, 3,  ..., 3, 6, 2],\n",
      "           [4, 8, 1,  ..., 4, 6, 4],\n",
      "           [0, 3, 0,  ..., 4, 3, 6],\n",
      "           [6, 2, 7,  ..., 0, 2, 7],\n",
      "           [0, 3, 9,  ..., 9, 6, 0]]],\n",
      "\n",
      "\n",
      "         [[[9, 2, 4,  ..., 4, 6, 2],\n",
      "           [1, 4, 8,  ..., 9, 8, 9],\n",
      "           [2, 1, 7,  ..., 6, 4, 9],\n",
      "           [2, 5, 9,  ..., 5, 8, 2],\n",
      "           [7, 6, 8,  ..., 4, 8, 3],\n",
      "           [1, 7, 4,  ..., 0, 8, 7]],\n",
      "\n",
      "          [[6, 4, 1,  ..., 0, 2, 1],\n",
      "           [3, 8, 5,  ..., 8, 4, 4],\n",
      "           [2, 6, 9,  ..., 1, 4, 2],\n",
      "           [8, 3, 9,  ..., 6, 8, 6],\n",
      "           [8, 0, 3,  ..., 5, 1, 0],\n",
      "           [0, 7, 6,  ..., 1, 5, 0]],\n",
      "\n",
      "          [[4, 2, 9,  ..., 2, 7, 8],\n",
      "           [6, 2, 2,  ..., 3, 1, 8],\n",
      "           [0, 5, 4,  ..., 0, 7, 4],\n",
      "           [5, 5, 9,  ..., 2, 9, 2],\n",
      "           [0, 4, 1,  ..., 5, 7, 3],\n",
      "           [8, 8, 0,  ..., 5, 2, 2]],\n",
      "\n",
      "          [[5, 9, 2,  ..., 7, 0, 9],\n",
      "           [0, 4, 8,  ..., 3, 9, 2],\n",
      "           [9, 6, 2,  ..., 2, 9, 6],\n",
      "           [7, 5, 4,  ..., 8, 4, 0],\n",
      "           [2, 8, 3,  ..., 8, 9, 7],\n",
      "           [4, 7, 9,  ..., 3, 4, 1]],\n",
      "\n",
      "          [[9, 6, 0,  ..., 8, 3, 3],\n",
      "           [9, 1, 1,  ..., 2, 4, 1],\n",
      "           [6, 4, 7,  ..., 6, 3, 6],\n",
      "           [5, 0, 0,  ..., 5, 8, 2],\n",
      "           [7, 6, 7,  ..., 0, 4, 6],\n",
      "           [8, 9, 9,  ..., 1, 2, 5]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0, 2, 4,  ..., 7, 8, 3],\n",
      "           [6, 8, 6,  ..., 6, 5, 8],\n",
      "           [0, 1, 8,  ..., 6, 8, 3],\n",
      "           [7, 9, 0,  ..., 4, 3, 5],\n",
      "           [5, 9, 0,  ..., 0, 9, 3],\n",
      "           [7, 8, 6,  ..., 8, 0, 5]],\n",
      "\n",
      "          [[2, 2, 2,  ..., 6, 2, 1],\n",
      "           [6, 0, 1,  ..., 6, 5, 7],\n",
      "           [8, 0, 2,  ..., 5, 3, 9],\n",
      "           [8, 1, 9,  ..., 8, 7, 4],\n",
      "           [4, 8, 7,  ..., 8, 0, 0],\n",
      "           [8, 8, 0,  ..., 5, 8, 7]],\n",
      "\n",
      "          [[2, 3, 5,  ..., 0, 7, 4],\n",
      "           [7, 7, 7,  ..., 9, 8, 4],\n",
      "           [9, 8, 0,  ..., 1, 5, 6],\n",
      "           [4, 3, 6,  ..., 2, 8, 1],\n",
      "           [4, 2, 4,  ..., 0, 2, 7],\n",
      "           [6, 8, 9,  ..., 5, 7, 4]],\n",
      "\n",
      "          [[1, 9, 3,  ..., 2, 3, 7],\n",
      "           [6, 0, 3,  ..., 0, 5, 3],\n",
      "           [1, 3, 4,  ..., 4, 5, 5],\n",
      "           [6, 2, 4,  ..., 5, 6, 9],\n",
      "           [6, 6, 8,  ..., 2, 8, 2],\n",
      "           [6, 0, 2,  ..., 0, 5, 6]],\n",
      "\n",
      "          [[2, 5, 2,  ..., 8, 8, 3],\n",
      "           [1, 1, 1,  ..., 1, 2, 0],\n",
      "           [9, 9, 9,  ..., 3, 5, 6],\n",
      "           [1, 1, 7,  ..., 1, 8, 7],\n",
      "           [7, 3, 7,  ..., 3, 4, 8],\n",
      "           [3, 8, 8,  ..., 0, 1, 1]]],\n",
      "\n",
      "\n",
      "         [[[0, 1, 6,  ..., 3, 3, 2],\n",
      "           [2, 1, 9,  ..., 1, 1, 9],\n",
      "           [5, 0, 6,  ..., 7, 7, 4],\n",
      "           [2, 1, 0,  ..., 5, 4, 8],\n",
      "           [1, 9, 9,  ..., 8, 3, 9],\n",
      "           [4, 3, 2,  ..., 7, 4, 6]],\n",
      "\n",
      "          [[8, 3, 5,  ..., 7, 8, 0],\n",
      "           [1, 3, 6,  ..., 1, 8, 3],\n",
      "           [0, 3, 5,  ..., 6, 8, 3],\n",
      "           [5, 4, 9,  ..., 0, 7, 8],\n",
      "           [9, 4, 8,  ..., 6, 3, 3],\n",
      "           [1, 7, 1,  ..., 9, 5, 7]],\n",
      "\n",
      "          [[9, 2, 5,  ..., 8, 7, 0],\n",
      "           [6, 3, 6,  ..., 5, 3, 1],\n",
      "           [4, 9, 2,  ..., 9, 9, 0],\n",
      "           [2, 2, 2,  ..., 3, 2, 9],\n",
      "           [7, 6, 7,  ..., 3, 6, 0],\n",
      "           [7, 6, 2,  ..., 8, 1, 5]],\n",
      "\n",
      "          [[3, 6, 0,  ..., 4, 4, 9],\n",
      "           [0, 7, 0,  ..., 8, 5, 0],\n",
      "           [6, 0, 2,  ..., 4, 7, 6],\n",
      "           [3, 6, 0,  ..., 6, 3, 7],\n",
      "           [8, 3, 3,  ..., 1, 8, 9],\n",
      "           [0, 4, 1,  ..., 9, 3, 4]],\n",
      "\n",
      "          [[1, 6, 4,  ..., 9, 4, 7],\n",
      "           [5, 9, 7,  ..., 3, 2, 6],\n",
      "           [4, 7, 1,  ..., 5, 9, 1],\n",
      "           [7, 7, 1,  ..., 0, 7, 1],\n",
      "           [6, 5, 2,  ..., 8, 8, 1],\n",
      "           [6, 2, 3,  ..., 2, 9, 9]]],\n",
      "\n",
      "\n",
      "         [[[3, 9, 2,  ..., 9, 0, 6],\n",
      "           [1, 2, 7,  ..., 7, 3, 3],\n",
      "           [4, 2, 6,  ..., 9, 2, 5],\n",
      "           [3, 0, 8,  ..., 4, 0, 0],\n",
      "           [5, 0, 3,  ..., 9, 4, 7],\n",
      "           [4, 3, 8,  ..., 6, 7, 0]],\n",
      "\n",
      "          [[5, 1, 2,  ..., 3, 5, 5],\n",
      "           [3, 6, 6,  ..., 3, 3, 2],\n",
      "           [2, 9, 7,  ..., 9, 1, 2],\n",
      "           [4, 3, 0,  ..., 6, 4, 6],\n",
      "           [2, 9, 7,  ..., 6, 5, 3],\n",
      "           [0, 9, 4,  ..., 8, 5, 9]],\n",
      "\n",
      "          [[2, 4, 9,  ..., 9, 2, 4],\n",
      "           [6, 9, 8,  ..., 8, 3, 0],\n",
      "           [2, 2, 0,  ..., 1, 0, 0],\n",
      "           [6, 5, 4,  ..., 8, 0, 7],\n",
      "           [7, 5, 5,  ..., 6, 3, 3],\n",
      "           [9, 6, 8,  ..., 5, 5, 7]],\n",
      "\n",
      "          [[7, 5, 4,  ..., 5, 8, 0],\n",
      "           [6, 0, 9,  ..., 9, 7, 1],\n",
      "           [1, 2, 5,  ..., 4, 2, 7],\n",
      "           [5, 9, 1,  ..., 4, 0, 9],\n",
      "           [7, 7, 7,  ..., 0, 5, 6],\n",
      "           [9, 9, 5,  ..., 6, 1, 6]],\n",
      "\n",
      "          [[9, 1, 1,  ..., 1, 7, 7],\n",
      "           [8, 8, 4,  ..., 8, 0, 1],\n",
      "           [2, 7, 6,  ..., 2, 4, 0],\n",
      "           [4, 7, 6,  ..., 6, 9, 2],\n",
      "           [9, 7, 3,  ..., 1, 7, 2],\n",
      "           [5, 9, 8,  ..., 1, 6, 7]]],\n",
      "\n",
      "\n",
      "         [[[3, 6, 2,  ..., 3, 3, 9],\n",
      "           [0, 7, 9,  ..., 0, 2, 5],\n",
      "           [4, 9, 6,  ..., 9, 8, 7],\n",
      "           [0, 3, 9,  ..., 1, 7, 9],\n",
      "           [9, 9, 8,  ..., 8, 7, 5],\n",
      "           [3, 2, 5,  ..., 0, 9, 7]],\n",
      "\n",
      "          [[8, 0, 0,  ..., 9, 2, 7],\n",
      "           [8, 9, 6,  ..., 7, 7, 7],\n",
      "           [3, 2, 6,  ..., 5, 1, 7],\n",
      "           [0, 2, 7,  ..., 7, 6, 1],\n",
      "           [2, 5, 7,  ..., 0, 5, 5],\n",
      "           [5, 1, 9,  ..., 0, 7, 7]],\n",
      "\n",
      "          [[7, 8, 1,  ..., 2, 5, 5],\n",
      "           [0, 2, 1,  ..., 9, 5, 9],\n",
      "           [0, 9, 4,  ..., 5, 4, 1],\n",
      "           [6, 9, 7,  ..., 6, 4, 1],\n",
      "           [9, 6, 4,  ..., 0, 3, 2],\n",
      "           [7, 9, 6,  ..., 1, 0, 3]],\n",
      "\n",
      "          [[0, 8, 5,  ..., 4, 7, 5],\n",
      "           [0, 0, 2,  ..., 1, 1, 0],\n",
      "           [6, 5, 4,  ..., 7, 7, 0],\n",
      "           [4, 1, 3,  ..., 7, 4, 5],\n",
      "           [0, 6, 6,  ..., 6, 5, 0],\n",
      "           [5, 3, 6,  ..., 7, 4, 4]],\n",
      "\n",
      "          [[7, 4, 2,  ..., 9, 0, 7],\n",
      "           [3, 3, 2,  ..., 4, 2, 0],\n",
      "           [1, 3, 4,  ..., 0, 2, 2],\n",
      "           [7, 6, 2,  ..., 1, 3, 1],\n",
      "           [7, 4, 6,  ..., 9, 1, 4],\n",
      "           [2, 6, 4,  ..., 3, 0, 9]]]]])\n",
      "张量形状：torch.Size([3, 4, 5, 6, 7])\n",
      "张量形状：3\n",
      "张量形状：4\n",
      "张量形状：5\n",
      "张量形状：6\n",
      "张量形状：3\n",
      "张量形状：4\n",
      "张量形状：5\n",
      "张量形状：6\n",
      "张量修改形状(总数不变)：tensor([[[[[9, 7, 4,  ..., 7, 7, 9],\n",
      "           [1, 7, 1,  ..., 6, 2, 5],\n",
      "           [3, 4, 6,  ..., 1, 3, 4],\n",
      "           [5, 5, 3,  ..., 3, 6, 1],\n",
      "           [3, 0, 5,  ..., 6, 3, 0],\n",
      "           [6, 1, 8,  ..., 6, 9, 7]],\n",
      "\n",
      "          [[7, 1, 9,  ..., 9, 4, 3],\n",
      "           [6, 5, 9,  ..., 4, 6, 2],\n",
      "           [9, 9, 6,  ..., 4, 9, 2],\n",
      "           [3, 6, 4,  ..., 2, 4, 4],\n",
      "           [3, 0, 1,  ..., 2, 8, 6],\n",
      "           [5, 0, 4,  ..., 5, 0, 5]],\n",
      "\n",
      "          [[0, 6, 3,  ..., 8, 9, 7],\n",
      "           [5, 3, 7,  ..., 6, 8, 2],\n",
      "           [6, 7, 2,  ..., 0, 9, 1],\n",
      "           [2, 2, 9,  ..., 6, 7, 2],\n",
      "           [4, 7, 5,  ..., 0, 7, 0],\n",
      "           [0, 7, 1,  ..., 4, 0, 2]],\n",
      "\n",
      "          [[8, 0, 9,  ..., 4, 9, 6],\n",
      "           [9, 9, 5,  ..., 6, 6, 7],\n",
      "           [7, 3, 8,  ..., 8, 1, 5],\n",
      "           [7, 5, 0,  ..., 2, 9, 3],\n",
      "           [5, 8, 0,  ..., 1, 4, 8],\n",
      "           [4, 0, 6,  ..., 4, 8, 5]],\n",
      "\n",
      "          [[7, 4, 1,  ..., 3, 9, 5],\n",
      "           [8, 1, 7,  ..., 6, 4, 3],\n",
      "           [1, 2, 2,  ..., 5, 5, 2],\n",
      "           [5, 9, 8,  ..., 3, 3, 9],\n",
      "           [0, 0, 2,  ..., 5, 4, 7],\n",
      "           [8, 5, 9,  ..., 1, 5, 0]]],\n",
      "\n",
      "\n",
      "         [[[8, 2, 4,  ..., 2, 5, 6],\n",
      "           [3, 6, 1,  ..., 0, 7, 6],\n",
      "           [5, 8, 9,  ..., 6, 8, 3],\n",
      "           [4, 6, 6,  ..., 6, 1, 0],\n",
      "           [7, 8, 5,  ..., 7, 2, 2],\n",
      "           [3, 9, 7,  ..., 8, 7, 6]],\n",
      "\n",
      "          [[7, 0, 8,  ..., 0, 2, 4],\n",
      "           [9, 6, 0,  ..., 5, 3, 3],\n",
      "           [2, 1, 4,  ..., 8, 0, 4],\n",
      "           [3, 9, 7,  ..., 0, 5, 1],\n",
      "           [9, 0, 1,  ..., 4, 3, 6],\n",
      "           [5, 8, 6,  ..., 0, 4, 1]],\n",
      "\n",
      "          [[8, 7, 6,  ..., 7, 6, 1],\n",
      "           [8, 7, 9,  ..., 0, 6, 2],\n",
      "           [9, 7, 3,  ..., 9, 9, 5],\n",
      "           [0, 2, 3,  ..., 1, 9, 1],\n",
      "           [5, 8, 6,  ..., 5, 9, 3],\n",
      "           [2, 0, 1,  ..., 1, 3, 7]],\n",
      "\n",
      "          [[5, 4, 4,  ..., 8, 8, 2],\n",
      "           [6, 1, 3,  ..., 9, 0, 1],\n",
      "           [1, 1, 5,  ..., 5, 9, 9],\n",
      "           [9, 2, 7,  ..., 2, 7, 3],\n",
      "           [7, 4, 7,  ..., 6, 2, 0],\n",
      "           [9, 0, 2,  ..., 1, 4, 3]],\n",
      "\n",
      "          [[7, 3, 0,  ..., 5, 8, 3],\n",
      "           [6, 9, 3,  ..., 2, 6, 1],\n",
      "           [6, 3, 1,  ..., 2, 0, 6],\n",
      "           [7, 3, 6,  ..., 6, 7, 6],\n",
      "           [3, 2, 9,  ..., 6, 2, 7],\n",
      "           [1, 2, 9,  ..., 6, 3, 4]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[2, 5, 1,  ..., 6, 6, 2],\n",
      "           [8, 9, 1,  ..., 4, 4, 5],\n",
      "           [7, 9, 7,  ..., 9, 3, 3],\n",
      "           [7, 5, 2,  ..., 1, 0, 6],\n",
      "           [2, 0, 0,  ..., 8, 8, 5],\n",
      "           [6, 2, 2,  ..., 6, 5, 6]],\n",
      "\n",
      "          [[5, 8, 0,  ..., 6, 0, 9],\n",
      "           [1, 7, 3,  ..., 7, 9, 8],\n",
      "           [7, 5, 5,  ..., 0, 7, 5],\n",
      "           [3, 6, 3,  ..., 1, 5, 8],\n",
      "           [5, 2, 2,  ..., 1, 6, 3],\n",
      "           [9, 2, 0,  ..., 5, 2, 5]],\n",
      "\n",
      "          [[6, 6, 6,  ..., 0, 5, 3],\n",
      "           [3, 4, 7,  ..., 2, 9, 3],\n",
      "           [1, 2, 2,  ..., 0, 0, 9],\n",
      "           [3, 6, 4,  ..., 5, 5, 2],\n",
      "           [2, 4, 8,  ..., 6, 2, 0],\n",
      "           [0, 5, 7,  ..., 2, 9, 4]],\n",
      "\n",
      "          [[8, 6, 3,  ..., 3, 3, 1],\n",
      "           [3, 7, 4,  ..., 1, 6, 0],\n",
      "           [5, 3, 2,  ..., 4, 8, 4],\n",
      "           [1, 3, 6,  ..., 6, 7, 7],\n",
      "           [7, 5, 7,  ..., 0, 0, 7],\n",
      "           [9, 7, 0,  ..., 6, 4, 0]],\n",
      "\n",
      "          [[1, 2, 1,  ..., 7, 8, 0],\n",
      "           [4, 9, 2,  ..., 9, 2, 0],\n",
      "           [4, 5, 9,  ..., 3, 9, 6],\n",
      "           [1, 4, 5,  ..., 4, 2, 9],\n",
      "           [3, 2, 2,  ..., 0, 7, 8],\n",
      "           [5, 8, 2,  ..., 9, 9, 4]]],\n",
      "\n",
      "\n",
      "         [[[4, 8, 7,  ..., 8, 1, 8],\n",
      "           [6, 4, 5,  ..., 8, 1, 2],\n",
      "           [0, 2, 8,  ..., 4, 6, 3],\n",
      "           [4, 1, 6,  ..., 7, 9, 2],\n",
      "           [9, 4, 4,  ..., 7, 5, 4],\n",
      "           [6, 6, 8,  ..., 8, 0, 9]],\n",
      "\n",
      "          [[1, 7, 0,  ..., 6, 5, 2],\n",
      "           [6, 7, 0,  ..., 7, 1, 3],\n",
      "           [1, 8, 1,  ..., 9, 1, 9],\n",
      "           [8, 5, 2,  ..., 9, 5, 0],\n",
      "           [6, 1, 3,  ..., 2, 2, 2],\n",
      "           [3, 6, 2,  ..., 2, 2, 6]],\n",
      "\n",
      "          [[5, 1, 1,  ..., 3, 6, 2],\n",
      "           [4, 8, 1,  ..., 4, 3, 6],\n",
      "           [6, 2, 7,  ..., 9, 6, 0],\n",
      "           [9, 2, 4,  ..., 9, 8, 9],\n",
      "           [2, 1, 7,  ..., 5, 8, 2],\n",
      "           [7, 6, 8,  ..., 0, 8, 7]],\n",
      "\n",
      "          [[6, 4, 1,  ..., 8, 4, 4],\n",
      "           [2, 6, 9,  ..., 6, 8, 6],\n",
      "           [8, 0, 3,  ..., 1, 5, 0],\n",
      "           [4, 2, 9,  ..., 3, 1, 8],\n",
      "           [0, 5, 4,  ..., 2, 9, 2],\n",
      "           [0, 4, 1,  ..., 5, 2, 2]],\n",
      "\n",
      "          [[5, 9, 2,  ..., 3, 9, 2],\n",
      "           [9, 6, 2,  ..., 8, 4, 0],\n",
      "           [2, 8, 3,  ..., 3, 4, 1],\n",
      "           [9, 6, 0,  ..., 2, 4, 1],\n",
      "           [6, 4, 7,  ..., 5, 8, 2],\n",
      "           [7, 6, 7,  ..., 1, 2, 5]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0, 2, 4,  ..., 6, 5, 8],\n",
      "           [0, 1, 8,  ..., 4, 3, 5],\n",
      "           [5, 9, 0,  ..., 8, 0, 5],\n",
      "           [2, 2, 2,  ..., 6, 5, 7],\n",
      "           [8, 0, 2,  ..., 8, 7, 4],\n",
      "           [4, 8, 7,  ..., 5, 8, 7]],\n",
      "\n",
      "          [[2, 3, 5,  ..., 9, 8, 4],\n",
      "           [9, 8, 0,  ..., 2, 8, 1],\n",
      "           [4, 2, 4,  ..., 5, 7, 4],\n",
      "           [1, 9, 3,  ..., 0, 5, 3],\n",
      "           [1, 3, 4,  ..., 5, 6, 9],\n",
      "           [6, 6, 8,  ..., 0, 5, 6]],\n",
      "\n",
      "          [[2, 5, 2,  ..., 1, 2, 0],\n",
      "           [9, 9, 9,  ..., 1, 8, 7],\n",
      "           [7, 3, 7,  ..., 0, 1, 1],\n",
      "           [0, 1, 6,  ..., 1, 1, 9],\n",
      "           [5, 0, 6,  ..., 5, 4, 8],\n",
      "           [1, 9, 9,  ..., 7, 4, 6]],\n",
      "\n",
      "          [[8, 3, 5,  ..., 1, 8, 3],\n",
      "           [0, 3, 5,  ..., 0, 7, 8],\n",
      "           [9, 4, 8,  ..., 9, 5, 7],\n",
      "           [9, 2, 5,  ..., 5, 3, 1],\n",
      "           [4, 9, 2,  ..., 3, 2, 9],\n",
      "           [7, 6, 7,  ..., 8, 1, 5]],\n",
      "\n",
      "          [[3, 6, 0,  ..., 8, 5, 0],\n",
      "           [6, 0, 2,  ..., 6, 3, 7],\n",
      "           [8, 3, 3,  ..., 9, 3, 4],\n",
      "           [1, 6, 4,  ..., 3, 2, 6],\n",
      "           [4, 7, 1,  ..., 0, 7, 1],\n",
      "           [6, 5, 2,  ..., 2, 9, 9]]],\n",
      "\n",
      "\n",
      "         [[[3, 9, 2,  ..., 7, 3, 3],\n",
      "           [4, 2, 6,  ..., 4, 0, 0],\n",
      "           [5, 0, 3,  ..., 6, 7, 0],\n",
      "           [5, 1, 2,  ..., 3, 3, 2],\n",
      "           [2, 9, 7,  ..., 6, 4, 6],\n",
      "           [2, 9, 7,  ..., 8, 5, 9]],\n",
      "\n",
      "          [[2, 4, 9,  ..., 8, 3, 0],\n",
      "           [2, 2, 0,  ..., 8, 0, 7],\n",
      "           [7, 5, 5,  ..., 5, 5, 7],\n",
      "           [7, 5, 4,  ..., 9, 7, 1],\n",
      "           [1, 2, 5,  ..., 4, 0, 9],\n",
      "           [7, 7, 7,  ..., 6, 1, 6]],\n",
      "\n",
      "          [[9, 1, 1,  ..., 8, 0, 1],\n",
      "           [2, 7, 6,  ..., 6, 9, 2],\n",
      "           [9, 7, 3,  ..., 1, 6, 7],\n",
      "           [3, 6, 2,  ..., 0, 2, 5],\n",
      "           [4, 9, 6,  ..., 1, 7, 9],\n",
      "           [9, 9, 8,  ..., 0, 9, 7]],\n",
      "\n",
      "          [[8, 0, 0,  ..., 7, 7, 7],\n",
      "           [3, 2, 6,  ..., 7, 6, 1],\n",
      "           [2, 5, 7,  ..., 0, 7, 7],\n",
      "           [7, 8, 1,  ..., 9, 5, 9],\n",
      "           [0, 9, 4,  ..., 6, 4, 1],\n",
      "           [9, 6, 4,  ..., 1, 0, 3]],\n",
      "\n",
      "          [[0, 8, 5,  ..., 1, 1, 0],\n",
      "           [6, 5, 4,  ..., 7, 4, 5],\n",
      "           [0, 6, 6,  ..., 7, 4, 4],\n",
      "           [7, 4, 2,  ..., 4, 2, 0],\n",
      "           [1, 3, 4,  ..., 1, 3, 1],\n",
      "           [7, 4, 6,  ..., 3, 0, 9]]]]])\n",
      "torch.Size([3, 2, 5, 6, 14])\n",
      "torch.Size([2, 3]) 2 3\n",
      "torch.Size([2, 3]) 2 3\n",
      "torch.Size([1, 6])\n"
     ]
    }
   ],
   "execution_count": 104
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T10:38:20.927757Z",
     "start_time": "2025-03-23T10:38:20.917757Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "张量squeeze和unsqueeze\n",
    "- squeeze:删除指定位置形状为1的维度，不指定位置删除所有形状为1的维度（降维）\n",
    "- unsqueeze:在指定位置添加形状为1的维度（升维）\n",
    "'''\n",
    "\n",
    "\n",
    "def squeeze_or_unsqueeze():\n",
    "    squeeze_data = torch.tensor([1, 2, 3, 4, 5])\n",
    "    print(f'squeeze和unsqueeze案例 维度：{squeeze_data.shape}， 数据集:{squeeze_data}')\n",
    "\n",
    "    squeeze_data = squeeze_data.unsqueeze(dim=0)\n",
    "    print(f'在位置为0的位置添加形状为1的维度 维度：{squeeze_data.shape}， 数据集:{squeeze_data}')\n",
    "\n",
    "    squeeze_data = squeeze_data.unsqueeze(dim=1)\n",
    "    print(f'在1维上拓展维度 维度：{squeeze_data.shape}， 数据集:{squeeze_data}')\n",
    "\n",
    "    squeeze_data = squeeze_data.unsqueeze(dim=-1)\n",
    "    print(f'在-1维基础上拓展维度 维度：{squeeze_data.shape}， 数据集:{squeeze_data}')\n",
    "\n",
    "\n",
    "squeeze_or_unsqueeze()"
   ],
   "id": "319cfcf29aa145d3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "squeeze和unsqueeze案例 维度：torch.Size([5])， 数据集:tensor([1, 2, 3, 4, 5])\n",
      "在位置为0的位置添加形状为1的维度 维度：torch.Size([1, 5])， 数据集:tensor([[1, 2, 3, 4, 5]])\n",
      "在1维上拓展维度 维度：torch.Size([1, 1, 5])， 数据集:tensor([[[1, 2, 3, 4, 5]]])\n",
      "在-1维基础上拓展维度 维度：torch.Size([1, 1, 5, 1])， 数据集:tensor([[[[1],\n",
      "          [2],\n",
      "          [3],\n",
      "          [4],\n",
      "          [5]]]])\n"
     ]
    }
   ],
   "execution_count": 97
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T10:37:47.012563Z",
     "start_time": "2025-03-23T10:37:47.001711Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "transpose和permute\n",
    "transpose：实现交换正浪形状的指定维度，；例如一个形状为（2，3，4）把3和4进行交换，将张量变换为（2，4，3）\n",
    "permute：一次性交换更多的维度\n",
    "'''\n",
    "\n",
    "\n",
    "def transpose_or_permute():\n",
    "    # 创建一个三维的张量\n",
    "    # data = torch.tensor(np.random.randint(0, 10, [3, 4, 5]))\n",
    "    data = torch.randint(0, 10, [3, 4, 5])\n",
    "    print(f'data 维度：{data.shape}， 数据集:{data}')\n",
    "\n",
    "    exchange_transpose = torch.transpose(data, 1, 2)\n",
    "    print(f'交换1和2维度 形状：{exchange_transpose.shape}, 数据：{exchange_transpose}')\n",
    "\n",
    "    first_transpose = torch.transpose(data, 0, 1)\n",
    "    second_transpose = torch.transpose(first_transpose, 1, 2)\n",
    "    print(f'将形状修改为（4， 5， 3）形状：{second_transpose.shape}， 数据：{second_transpose}')\n",
    "\n",
    "    permute_data = torch.permute(data, [1, 2, 0])\n",
    "    print(f'使用permute函数将形状修改为（4， 5， 3）形状：{permute_data.shape}, 数据 ：{permute_data}')\n",
    "\n",
    "\n",
    "transpose_or_permute()"
   ],
   "id": "d43fd6448ed9d49a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data 维度：torch.Size([3, 4, 5])， 数据集:tensor([[[6, 6, 8, 3, 9],\n",
      "         [4, 9, 0, 1, 5],\n",
      "         [4, 3, 3, 8, 6],\n",
      "         [0, 1, 3, 4, 4]],\n",
      "\n",
      "        [[8, 3, 6, 9, 4],\n",
      "         [1, 2, 3, 2, 0],\n",
      "         [3, 0, 7, 0, 9],\n",
      "         [6, 7, 1, 4, 4]],\n",
      "\n",
      "        [[7, 0, 1, 2, 7],\n",
      "         [6, 4, 5, 5, 2],\n",
      "         [2, 2, 0, 1, 3],\n",
      "         [4, 7, 4, 0, 5]]])\n",
      "交换1和2维度 形状：torch.Size([3, 5, 4]), 数据：tensor([[[6, 4, 4, 0],\n",
      "         [6, 9, 3, 1],\n",
      "         [8, 0, 3, 3],\n",
      "         [3, 1, 8, 4],\n",
      "         [9, 5, 6, 4]],\n",
      "\n",
      "        [[8, 1, 3, 6],\n",
      "         [3, 2, 0, 7],\n",
      "         [6, 3, 7, 1],\n",
      "         [9, 2, 0, 4],\n",
      "         [4, 0, 9, 4]],\n",
      "\n",
      "        [[7, 6, 2, 4],\n",
      "         [0, 4, 2, 7],\n",
      "         [1, 5, 0, 4],\n",
      "         [2, 5, 1, 0],\n",
      "         [7, 2, 3, 5]]])\n",
      "将形状修改为（4， 5， 3）形状：torch.Size([4, 5, 3])， 数据：tensor([[[6, 8, 7],\n",
      "         [6, 3, 0],\n",
      "         [8, 6, 1],\n",
      "         [3, 9, 2],\n",
      "         [9, 4, 7]],\n",
      "\n",
      "        [[4, 1, 6],\n",
      "         [9, 2, 4],\n",
      "         [0, 3, 5],\n",
      "         [1, 2, 5],\n",
      "         [5, 0, 2]],\n",
      "\n",
      "        [[4, 3, 2],\n",
      "         [3, 0, 2],\n",
      "         [3, 7, 0],\n",
      "         [8, 0, 1],\n",
      "         [6, 9, 3]],\n",
      "\n",
      "        [[0, 6, 4],\n",
      "         [1, 7, 7],\n",
      "         [3, 1, 4],\n",
      "         [4, 4, 0],\n",
      "         [4, 4, 5]]])\n",
      "使用permute函数将形状修改为（4， 5， 3）形状：torch.Size([4, 5, 3]), 数据 ：tensor([[[6, 8, 7],\n",
      "         [6, 3, 0],\n",
      "         [8, 6, 1],\n",
      "         [3, 9, 2],\n",
      "         [9, 4, 7]],\n",
      "\n",
      "        [[4, 1, 6],\n",
      "         [9, 2, 4],\n",
      "         [0, 3, 5],\n",
      "         [1, 2, 5],\n",
      "         [5, 0, 2]],\n",
      "\n",
      "        [[4, 3, 2],\n",
      "         [3, 0, 2],\n",
      "         [3, 7, 0],\n",
      "         [8, 0, 1],\n",
      "         [6, 9, 3]],\n",
      "\n",
      "        [[0, 6, 4],\n",
      "         [1, 7, 7],\n",
      "         [3, 1, 4],\n",
      "         [4, 4, 0],\n",
      "         [4, 4, 5]]])\n"
     ]
    }
   ],
   "execution_count": 96
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T10:33:21.345790Z",
     "start_time": "2025-03-23T10:33:21.335393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "view和contiguous函数\n",
    "view：也可以用于修改张量形状，但只能用于连续张量，在PyTorch中有些张量的底层数据在内存中存储顺序与其在张量逻辑顺序不一致，view函数无反对这样的张量进行变形处理，eg：一个张量经过transpose或者permute函数的处理后，就无法使用view函数进行形状操作\n",
    "contiguous：将不连续张量转化为连续张量\n",
    "is_contiguous：判断张量是否连续，并返回True/False\n",
    "'''\n",
    "\n",
    "\n",
    "def view_or_contiguous_demo():\n",
    "    data = torch.tensor([[10, 20, 30], [40, 50, 60]])\n",
    "    print(f'shape：{data.shape}, data :{data}')\n",
    "\n",
    "    is_contiguous = data.is_contiguous()\n",
    "    print(f'张量是否连续：{is_contiguous}')\n",
    "\n",
    "    data = data.view(3, 2)\n",
    "    print(f'使用transpose改变张量形状 shape：{data.shape}, is_contiguous: {data.is_contiguous()} data:{data}')\n",
    "\n",
    "    data = torch.transpose(data, 0, 1)\n",
    "    print(f'使用transpose改变张量形状 shape：{data.shape}, is_contiguous: {data.is_contiguous()} data:{data}')\n",
    "\n",
    "    # 这里再使用view就会报错，因为当前张量不连续\n",
    "    #data = data.view(3, 2)\n",
    "    #print(f'使用view改变张量形状 shape：{data.shape}, is_contiguous: {data.is_contiguous()} data:{data}')\n",
    "\n",
    "    data = data.contiguous()\n",
    "    print(f'使用contiguous改为连续张量 shape：{data.shape}, is_contiguous: {data.is_contiguous()} data:{data}')\n",
    "\n",
    "    data = data.view(2, 3)\n",
    "    print(f'使用view改变张量形状 shape：{data.shape}, is_contiguous: {data.is_contiguous()} data:{data}')\n",
    "\n",
    "\n",
    "view_or_contiguous_demo()"
   ],
   "id": "bd259a277115ab02",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape：torch.Size([2, 3]), data :tensor([[10, 20, 30],\n",
      "        [40, 50, 60]])\n",
      "张量是否连续：True\n",
      "使用transpose改变张量形状 shape：torch.Size([3, 2]), is_contiguous: True data:tensor([[10, 20],\n",
      "        [30, 40],\n",
      "        [50, 60]])\n",
      "使用transpose改变张量形状 shape：torch.Size([2, 3]), is_contiguous: False data:tensor([[10, 30, 50],\n",
      "        [20, 40, 60]])\n",
      "使用contiguous改为连续张量 shape：torch.Size([2, 3]), is_contiguous: True data:tensor([[10, 30, 50],\n",
      "        [20, 40, 60]])\n",
      "使用view改变张量形状 shape：torch.Size([2, 3]), is_contiguous: True data:tensor([[10, 30, 50],\n",
      "        [20, 40, 60]])\n"
     ]
    }
   ],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T10:37:00.634315Z",
     "start_time": "2025-03-23T10:37:00.623572Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "Tensor拼接操作cat和concat\n",
    "cat:将多个张量按照指定维度拼接，要求张量在除拼接维度上其他维度保持一致\n",
    "concat:语法与cat保持一致，但更灵活，可以通过指定dim参数指定拼接维度\n",
    "stack：在一个新的维度上连接一系列张量，这回增加一个新维度，并且所有输入张量的形状必须完全相同\n",
    "备注：这里的dim可以理解为在第几层合并拼接，对应顺序位置shape增加\n",
    "'''\n",
    "\n",
    "\n",
    "def cat_demo():\n",
    "    data1 = torch.randint(0, 10, [1, 2, 3])\n",
    "    print(f'data1 shape：{data1.shape}, data :{data1}')\n",
    "    data2 = torch.randint(0, 10, [1, 2, 3])\n",
    "    print(f'data2 shape：{data2.shape}, data :{data2}')\n",
    "\n",
    "    data = torch.cat([data1, data2], dim=0)\n",
    "    print(f'data shape：{data.shape}, data :{data}')\n",
    "\n",
    "    data = torch.cat([data1, data2], dim=0)\n",
    "    print(f'data shape：{data.shape}, data :{data}')\n",
    "\n",
    "    data = torch.cat([data1, data2], dim=1)\n",
    "    print(f'data shape：{data.shape}, data :{data}')\n",
    "\n",
    "\n",
    "def stack_demo():\n",
    "    data1 = torch.randint(0, 10, [2, 3])\n",
    "    print(f'data1 shape：{data1.shape}, data :{data1}')\n",
    "    data2 = torch.randint(0, 10, [2, 3])\n",
    "    print(f'data2 shape：{data2.shape}, data :{data2}')\n",
    "\n",
    "    data = torch.stack([data1, data2], dim=0)\n",
    "    print(f'在0维上stack shape：{data.shape}, data :{data}')\n",
    "\n",
    "    data = torch.stack([data1, data2], dim=1)\n",
    "    print(f'在1维上stack shape：{data.shape}, data :{data}')\n",
    "\n",
    "    data = torch.stack([data1, data2], dim=2)\n",
    "    print(f'在2维上stack shape：{data.shape}, data :{data}')\n",
    "\n",
    "\n",
    "cat_demo()\n",
    "stack_demo()"
   ],
   "id": "f16537e1b12dfae4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data1 shape：torch.Size([1, 2, 3]), data :tensor([[[7, 1, 7],\n",
      "         [9, 2, 7]]])\n",
      "data2 shape：torch.Size([1, 2, 3]), data :tensor([[[4, 3, 5],\n",
      "         [9, 3, 4]]])\n",
      "data shape：torch.Size([2, 2, 3]), data :tensor([[[7, 1, 7],\n",
      "         [9, 2, 7]],\n",
      "\n",
      "        [[4, 3, 5],\n",
      "         [9, 3, 4]]])\n",
      "data shape：torch.Size([2, 2, 3]), data :tensor([[[7, 1, 7],\n",
      "         [9, 2, 7]],\n",
      "\n",
      "        [[4, 3, 5],\n",
      "         [9, 3, 4]]])\n",
      "data shape：torch.Size([1, 4, 3]), data :tensor([[[7, 1, 7],\n",
      "         [9, 2, 7],\n",
      "         [4, 3, 5],\n",
      "         [9, 3, 4]]])\n",
      "data1 shape：torch.Size([2, 3]), data :tensor([[7, 1, 9],\n",
      "        [8, 1, 1]])\n",
      "data2 shape：torch.Size([2, 3]), data :tensor([[6, 8, 3],\n",
      "        [7, 8, 2]])\n",
      "在0维上stack shape：torch.Size([2, 2, 3]), data :tensor([[[7, 1, 9],\n",
      "         [8, 1, 1]],\n",
      "\n",
      "        [[6, 8, 3],\n",
      "         [7, 8, 2]]])\n",
      "在1维上stack shape：torch.Size([2, 2, 3]), data :tensor([[[7, 1, 9],\n",
      "         [6, 8, 3]],\n",
      "\n",
      "        [[8, 1, 1],\n",
      "         [7, 8, 2]]])\n",
      "在2维上stack shape：torch.Size([2, 3, 2]), data :tensor([[[7, 6],\n",
      "         [1, 8],\n",
      "         [9, 3]],\n",
      "\n",
      "        [[8, 7],\n",
      "         [1, 8],\n",
      "         [1, 2]]])\n"
     ]
    }
   ],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T10:52:59.783360Z",
     "start_time": "2025-03-23T10:52:59.773694Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "自动微分模块：\n",
    "概念：自动微分就是自动计算梯度值,也就是计算导数\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "def scalar_gradient_calculation():\n",
    "    '''\n",
    "    标量张量梯度计算\n",
    "    :return: \n",
    "    '''\n",
    "\n",
    "    # 1、定义一个标量张量(点)\n",
    "    x = torch.tensor(10, requires_grad=True, dtype=torch.float32)\n",
    "    print(f'x shape：{x.shape}, data :{x}')\n",
    "\n",
    "    # 2、定义一个曲线\n",
    "    y = 2 * x ** 2\n",
    "\n",
    "    # 3、计算x点的梯度\n",
    "    # 此时y是一个标量,可以不用使用y.sum()转换成标量\n",
    "    # y'|(x=10) = (2*x**2)'|(x=10) = 4x|(x=10) = 40\n",
    "    # y.sum().backward()\n",
    "    y.backward()\n",
    "    print(f'x梯度：{x.grad}')\n",
    "\n",
    "\n",
    "def vector_gradient_calculation():\n",
    "    '''\n",
    "    向量张量梯度计算\n",
    "    :return: \n",
    "    '''\n",
    "    # 1、定义一个向量张量(点)\n",
    "    x = torch.tensor([10, 20], requires_grad=True, dtype=torch.float32)\n",
    "    print(f'x shape：{x.shape}, data :{x}')\n",
    "\n",
    "    # 2、定义一个曲线\n",
    "    y = 2 * x ** 2\n",
    "\n",
    "    # 计算梯度\n",
    "    # x和y都是向量张量,不能进行求导,需要将y转换成标量张量-->y.sum()\n",
    "    # y'|(x=10) = (2*x**2)'|(x=10) = 4x|(x=10) = 40\n",
    "    # y'|(x=20) = (2*x**2)'|(x=20) = 4x|(x=20) = 80\n",
    "    # 3、计算x点的梯度\n",
    "    # y.backward()\n",
    "    y.sum().backward()\n",
    "    print(f'x梯度：{x.grad}')\n",
    "\n",
    "\n",
    "scalar_gradient_calculation()\n",
    "vector_gradient_calculation()"
   ],
   "id": "1e6a24252a77660c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape：torch.Size([]), data :10.0\n",
      "x梯度：40.0\n",
      "x shape：torch.Size([2]), data :tensor([10., 20.], requires_grad=True)\n",
      "x梯度：tensor([40., 80.])\n"
     ]
    }
   ],
   "execution_count": 111
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T11:11:47.604225Z",
     "start_time": "2025-03-23T11:11:47.451797Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    " 求 y = x**2 + 20 的极小值点 并打印y是最小值时 w的值(梯度)\n",
    " 1 定义点 x=10 requires_grad=True  dtype=torch.float32\n",
    " 2 定义函数 y = x**2 + 20\n",
    " 3 利用梯度下降法 循环迭代1000 求最优解\n",
    " 3-1 正向计算(前向传播)\n",
    " 3-2 梯度清零 x.grad.zero_()\n",
    " 3-3 反向传播\n",
    " 3-4 梯度更新 x.data = x.data - 0.01 * x.grad\n",
    "'''\n",
    "\n",
    "\n",
    "def gradient_descent_calculation():\n",
    "    # 1 定义点x=10 requires_grad=True  dtype=torch.float32\n",
    "    x = torch.tensor(10, requires_grad=True, dtype=torch.float32)\n",
    "\n",
    "    # 2 定义函数 y = x ** 2 + 20\n",
    "    y = x ** 2 + 20\n",
    "    print('开始 权重x初始值:%.6f (0.01 * x.grad):无 y:%.6f' % (x, y))\n",
    "\n",
    "    # 3 利用梯度下降法 循环迭代1000 求最优解\n",
    "    for i in range(1, 1001):\n",
    "    \n",
    "        # 3-1 正向计算(前向传播)\n",
    "        y = x ** 2 + 20\n",
    "    \n",
    "        # 3-2 梯度清零 x.grad.zero_()\n",
    "        # 默认张量的 grad 属性会累加历史梯度值 需手工清零上一次的提取\n",
    "        # 一开始梯度不存在, 需要做判断\n",
    "        if x.grad is not None:\n",
    "            x.grad.zero_()\n",
    "    \n",
    "        # 3-3 反向传播\n",
    "        y.sum().backward()\n",
    "    \n",
    "        # 3-4 梯度更新 x.data = x.data - 0.01 * x.grad\n",
    "        # x.data是修改原始x内存中的数据,前后x的内存空间一样;如果使用x,此时修改前后x的内存空间不同\n",
    "        x.data = x.data - 0.01 * x.grad  # 注：不能 x = x - 0.01 * x.grad 这样写\n",
    "    \n",
    "        print('次数:%d 权重x: %.6f, (0.01 * x.grad):%.6f y:%.6f' % (i, x, 0.01 * x.grad, y))\n",
    "    print('x：', x, x.grad, 'y最小值', y)\n",
    "\n",
    "\n",
    "def gradient_descent_calculation_error():\n",
    "    '''\n",
    "    不能将自动微分的张量转换成numpy数组，会发生报错，可以通过detach()方法实现\n",
    "    :return: \n",
    "    '''\n",
    "    # 定义一个张量\n",
    "    x1 = torch.tensor([10, 20], requires_grad=True, dtype=torch.float64)\n",
    "\n",
    "    # 将x张量转换成numpy数组\n",
    "    # 发生报错,RuntimeError: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n",
    "    # 不能将自动微分的张量转换成numpy数组\n",
    "    # print(x1.numpy())\n",
    "\n",
    "    # 通过detach()方法产生一个新的张量,作为叶子结点\n",
    "    x2 = x1.detach()\n",
    "    # x1和x2张量共享数据,但是x2不会自动微分\n",
    "    print(x1.requires_grad)\n",
    "    print(x2.requires_grad)\n",
    "    # x1和x2张量的值一样,共用一份内存空间的数据\n",
    "    print(x1.data)\n",
    "    print(x2.data)\n",
    "    print(id(x1.data))\n",
    "    print(id(x2.data))\n",
    "\n",
    "    # 将x2张量转换成numpy数组\n",
    "    print(x2.detach())\n",
    "    # print(x2.numpy())\n",
    "\n",
    "gradient_descent_calculation()\n",
    "\n",
    "gradient_descent_calculation_error()\n"
   ],
   "id": "99dab4d56226efc5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始 权重x初始值:10.000000 (0.01 * x.grad):无 y:120.000000\n",
      "次数:1 权重x: 9.800000, (0.01 * x.grad):0.200000 y:120.000000\n",
      "次数:2 权重x: 9.604000, (0.01 * x.grad):0.196000 y:116.040001\n",
      "次数:3 权重x: 9.411921, (0.01 * x.grad):0.192080 y:112.236816\n",
      "次数:4 权重x: 9.223682, (0.01 * x.grad):0.188238 y:108.584251\n",
      "次数:5 权重x: 9.039208, (0.01 * x.grad):0.184474 y:105.076317\n",
      "次数:6 权重x: 8.858424, (0.01 * x.grad):0.180784 y:101.707291\n",
      "次数:7 权重x: 8.681255, (0.01 * x.grad):0.177168 y:98.471680\n",
      "次数:8 权重x: 8.507630, (0.01 * x.grad):0.173625 y:95.364197\n",
      "次数:9 权重x: 8.337478, (0.01 * x.grad):0.170153 y:92.379776\n",
      "次数:10 权重x: 8.170728, (0.01 * x.grad):0.166750 y:89.513535\n",
      "次数:11 权重x: 8.007313, (0.01 * x.grad):0.163415 y:86.760788\n",
      "次数:12 权重x: 7.847167, (0.01 * x.grad):0.160146 y:84.117058\n",
      "次数:13 权重x: 7.690223, (0.01 * x.grad):0.156943 y:81.578018\n",
      "次数:14 权重x: 7.536419, (0.01 * x.grad):0.153804 y:79.139534\n",
      "次数:15 权重x: 7.385691, (0.01 * x.grad):0.150728 y:76.797607\n",
      "次数:16 权重x: 7.237977, (0.01 * x.grad):0.147714 y:74.548431\n",
      "次数:17 权重x: 7.093217, (0.01 * x.grad):0.144760 y:72.388313\n",
      "次数:18 权重x: 6.951353, (0.01 * x.grad):0.141864 y:70.313736\n",
      "次数:19 权重x: 6.812326, (0.01 * x.grad):0.139027 y:68.321304\n",
      "次数:20 权重x: 6.676079, (0.01 * x.grad):0.136247 y:66.407784\n",
      "次数:21 权重x: 6.542558, (0.01 * x.grad):0.133522 y:64.570038\n",
      "次数:22 权重x: 6.411706, (0.01 * x.grad):0.130851 y:62.805061\n",
      "次数:23 权重x: 6.283473, (0.01 * x.grad):0.128234 y:61.109978\n",
      "次数:24 权重x: 6.157803, (0.01 * x.grad):0.125669 y:59.482029\n",
      "次数:25 权重x: 6.034647, (0.01 * x.grad):0.123156 y:57.918537\n",
      "次数:26 权重x: 5.913954, (0.01 * x.grad):0.120693 y:56.416965\n",
      "次数:27 权重x: 5.795675, (0.01 * x.grad):0.118279 y:54.974854\n",
      "次数:28 权重x: 5.679762, (0.01 * x.grad):0.115914 y:53.589851\n",
      "次数:29 权重x: 5.566167, (0.01 * x.grad):0.113595 y:52.259697\n",
      "次数:30 权重x: 5.454844, (0.01 * x.grad):0.111323 y:50.982216\n",
      "次数:31 权重x: 5.345747, (0.01 * x.grad):0.109097 y:49.755318\n",
      "次数:32 权重x: 5.238832, (0.01 * x.grad):0.106915 y:48.577003\n",
      "次数:33 权重x: 5.134055, (0.01 * x.grad):0.104777 y:47.445358\n",
      "次数:34 权重x: 5.031374, (0.01 * x.grad):0.102681 y:46.358517\n",
      "次数:35 权重x: 4.930746, (0.01 * x.grad):0.100627 y:45.314720\n",
      "次数:36 权重x: 4.832131, (0.01 * x.grad):0.098615 y:44.312256\n",
      "次数:37 权重x: 4.735489, (0.01 * x.grad):0.096643 y:43.349495\n",
      "次数:38 权重x: 4.640779, (0.01 * x.grad):0.094710 y:42.424854\n",
      "次数:39 权重x: 4.547964, (0.01 * x.grad):0.092816 y:41.536827\n",
      "次数:40 权重x: 4.457005, (0.01 * x.grad):0.090959 y:40.683975\n",
      "次数:41 权重x: 4.367865, (0.01 * x.grad):0.089140 y:39.864891\n",
      "次数:42 权重x: 4.280507, (0.01 * x.grad):0.087357 y:39.078239\n",
      "次数:43 权重x: 4.194897, (0.01 * x.grad):0.085610 y:38.322739\n",
      "次数:44 权重x: 4.110999, (0.01 * x.grad):0.083898 y:37.597160\n",
      "次数:45 权重x: 4.028779, (0.01 * x.grad):0.082220 y:36.900314\n",
      "次数:46 权重x: 3.948204, (0.01 * x.grad):0.080576 y:36.231060\n",
      "次数:47 权重x: 3.869240, (0.01 * x.grad):0.078964 y:35.588310\n",
      "次数:48 权重x: 3.791855, (0.01 * x.grad):0.077385 y:34.971016\n",
      "次数:49 权重x: 3.716018, (0.01 * x.grad):0.075837 y:34.378162\n",
      "次数:50 权重x: 3.641697, (0.01 * x.grad):0.074320 y:33.808788\n",
      "次数:51 权重x: 3.568863, (0.01 * x.grad):0.072834 y:33.261959\n",
      "次数:52 权重x: 3.497486, (0.01 * x.grad):0.071377 y:32.736786\n",
      "次数:53 权重x: 3.427536, (0.01 * x.grad):0.069950 y:32.232410\n",
      "次数:54 权重x: 3.358986, (0.01 * x.grad):0.068551 y:31.748007\n",
      "次数:55 权重x: 3.291806, (0.01 * x.grad):0.067180 y:31.282784\n",
      "次数:56 权重x: 3.225970, (0.01 * x.grad):0.065836 y:30.835987\n",
      "次数:57 权重x: 3.161450, (0.01 * x.grad):0.064519 y:30.406881\n",
      "次数:58 权重x: 3.098221, (0.01 * x.grad):0.063229 y:29.994768\n",
      "次数:59 权重x: 3.036257, (0.01 * x.grad):0.061964 y:29.598976\n",
      "次数:60 权重x: 2.975532, (0.01 * x.grad):0.060725 y:29.218855\n",
      "次数:61 权重x: 2.916021, (0.01 * x.grad):0.059511 y:28.853788\n",
      "次数:62 权重x: 2.857700, (0.01 * x.grad):0.058320 y:28.503178\n",
      "次数:63 权重x: 2.800546, (0.01 * x.grad):0.057154 y:28.166451\n",
      "次数:64 权重x: 2.744535, (0.01 * x.grad):0.056011 y:27.843060\n",
      "次数:65 权重x: 2.689645, (0.01 * x.grad):0.054891 y:27.532475\n",
      "次数:66 权重x: 2.635852, (0.01 * x.grad):0.053793 y:27.234188\n",
      "次数:67 权重x: 2.583135, (0.01 * x.grad):0.052717 y:26.947716\n",
      "次数:68 权重x: 2.531472, (0.01 * x.grad):0.051663 y:26.672586\n",
      "次数:69 权重x: 2.480843, (0.01 * x.grad):0.050629 y:26.408352\n",
      "次数:70 权重x: 2.431226, (0.01 * x.grad):0.049617 y:26.154581\n",
      "次数:71 权重x: 2.382601, (0.01 * x.grad):0.048625 y:25.910860\n",
      "次数:72 权重x: 2.334949, (0.01 * x.grad):0.047652 y:25.676790\n",
      "次数:73 权重x: 2.288250, (0.01 * x.grad):0.046699 y:25.451988\n",
      "次数:74 权重x: 2.242486, (0.01 * x.grad):0.045765 y:25.236090\n",
      "次数:75 权重x: 2.197636, (0.01 * x.grad):0.044850 y:25.028742\n",
      "次数:76 权重x: 2.153683, (0.01 * x.grad):0.043953 y:24.829603\n",
      "次数:77 权重x: 2.110610, (0.01 * x.grad):0.043074 y:24.638351\n",
      "次数:78 权重x: 2.068397, (0.01 * x.grad):0.042212 y:24.454674\n",
      "次数:79 权重x: 2.027029, (0.01 * x.grad):0.041368 y:24.278267\n",
      "次数:80 权重x: 1.986489, (0.01 * x.grad):0.040541 y:24.108849\n",
      "次数:81 权重x: 1.946759, (0.01 * x.grad):0.039730 y:23.946136\n",
      "次数:82 权重x: 1.907824, (0.01 * x.grad):0.038935 y:23.789871\n",
      "次数:83 权重x: 1.869667, (0.01 * x.grad):0.038156 y:23.639791\n",
      "次数:84 权重x: 1.832274, (0.01 * x.grad):0.037393 y:23.495655\n",
      "次数:85 权重x: 1.795628, (0.01 * x.grad):0.036645 y:23.357227\n",
      "次数:86 权重x: 1.759716, (0.01 * x.grad):0.035913 y:23.224281\n",
      "次数:87 权重x: 1.724522, (0.01 * x.grad):0.035194 y:23.096600\n",
      "次数:88 权重x: 1.690031, (0.01 * x.grad):0.034490 y:22.973974\n",
      "次数:89 权重x: 1.656231, (0.01 * x.grad):0.033801 y:22.856205\n",
      "次数:90 权重x: 1.623106, (0.01 * x.grad):0.033125 y:22.743099\n",
      "次数:91 权重x: 1.590644, (0.01 * x.grad):0.032462 y:22.634474\n",
      "次数:92 权重x: 1.558831, (0.01 * x.grad):0.031813 y:22.530148\n",
      "次数:93 权重x: 1.527654, (0.01 * x.grad):0.031177 y:22.429955\n",
      "次数:94 权重x: 1.497101, (0.01 * x.grad):0.030553 y:22.333729\n",
      "次数:95 权重x: 1.467159, (0.01 * x.grad):0.029942 y:22.241312\n",
      "次数:96 权重x: 1.437816, (0.01 * x.grad):0.029343 y:22.152557\n",
      "次数:97 权重x: 1.409060, (0.01 * x.grad):0.028756 y:22.067316\n",
      "次数:98 权重x: 1.380879, (0.01 * x.grad):0.028181 y:21.985449\n",
      "次数:99 权重x: 1.353261, (0.01 * x.grad):0.027618 y:21.906826\n",
      "次数:100 权重x: 1.326196, (0.01 * x.grad):0.027065 y:21.831316\n",
      "次数:101 权重x: 1.299672, (0.01 * x.grad):0.026524 y:21.758795\n",
      "次数:102 权重x: 1.273678, (0.01 * x.grad):0.025993 y:21.689146\n",
      "次数:103 权重x: 1.248205, (0.01 * x.grad):0.025474 y:21.622257\n",
      "次数:104 权重x: 1.223241, (0.01 * x.grad):0.024964 y:21.558016\n",
      "次数:105 权重x: 1.198776, (0.01 * x.grad):0.024465 y:21.496317\n",
      "次数:106 权重x: 1.174800, (0.01 * x.grad):0.023976 y:21.437063\n",
      "次数:107 权重x: 1.151304, (0.01 * x.grad):0.023496 y:21.380156\n",
      "次数:108 权重x: 1.128278, (0.01 * x.grad):0.023026 y:21.325500\n",
      "次数:109 权重x: 1.105713, (0.01 * x.grad):0.022566 y:21.273012\n",
      "次数:110 权重x: 1.083598, (0.01 * x.grad):0.022114 y:21.222601\n",
      "次数:111 权重x: 1.061926, (0.01 * x.grad):0.021672 y:21.174185\n",
      "次数:112 权重x: 1.040688, (0.01 * x.grad):0.021239 y:21.127687\n",
      "次数:113 权重x: 1.019874, (0.01 * x.grad):0.020814 y:21.083031\n",
      "次数:114 权重x: 0.999476, (0.01 * x.grad):0.020397 y:21.040142\n",
      "次数:115 权重x: 0.979487, (0.01 * x.grad):0.019990 y:20.998953\n",
      "次数:116 权重x: 0.959897, (0.01 * x.grad):0.019590 y:20.959394\n",
      "次数:117 权重x: 0.940699, (0.01 * x.grad):0.019198 y:20.921402\n",
      "次数:118 权重x: 0.921885, (0.01 * x.grad):0.018814 y:20.884914\n",
      "次数:119 权重x: 0.903448, (0.01 * x.grad):0.018438 y:20.849873\n",
      "次数:120 权重x: 0.885379, (0.01 * x.grad):0.018069 y:20.816217\n",
      "次数:121 权重x: 0.867671, (0.01 * x.grad):0.017708 y:20.783895\n",
      "次数:122 权重x: 0.850318, (0.01 * x.grad):0.017353 y:20.752853\n",
      "次数:123 权重x: 0.833311, (0.01 * x.grad):0.017006 y:20.723040\n",
      "次数:124 权重x: 0.816645, (0.01 * x.grad):0.016666 y:20.694408\n",
      "次数:125 权重x: 0.800312, (0.01 * x.grad):0.016333 y:20.666908\n",
      "次数:126 权重x: 0.784306, (0.01 * x.grad):0.016006 y:20.640499\n",
      "次数:127 权重x: 0.768620, (0.01 * x.grad):0.015686 y:20.615135\n",
      "次数:128 权重x: 0.753247, (0.01 * x.grad):0.015372 y:20.590776\n",
      "次数:129 权重x: 0.738182, (0.01 * x.grad):0.015065 y:20.567381\n",
      "次数:130 权重x: 0.723419, (0.01 * x.grad):0.014764 y:20.544914\n",
      "次数:131 权重x: 0.708950, (0.01 * x.grad):0.014468 y:20.523335\n",
      "次数:132 权重x: 0.694771, (0.01 * x.grad):0.014179 y:20.502611\n",
      "次数:133 权重x: 0.680876, (0.01 * x.grad):0.013895 y:20.482708\n",
      "次数:134 权重x: 0.667259, (0.01 * x.grad):0.013618 y:20.463593\n",
      "次数:135 权重x: 0.653913, (0.01 * x.grad):0.013345 y:20.445234\n",
      "次数:136 权重x: 0.640835, (0.01 * x.grad):0.013078 y:20.427603\n",
      "次数:137 权重x: 0.628018, (0.01 * x.grad):0.012817 y:20.410669\n",
      "次数:138 权重x: 0.615458, (0.01 * x.grad):0.012560 y:20.394407\n",
      "次数:139 权重x: 0.603149, (0.01 * x.grad):0.012309 y:20.378788\n",
      "次数:140 权重x: 0.591086, (0.01 * x.grad):0.012063 y:20.363789\n",
      "次数:141 权重x: 0.579264, (0.01 * x.grad):0.011822 y:20.349382\n",
      "次数:142 权重x: 0.567679, (0.01 * x.grad):0.011585 y:20.335546\n",
      "次数:143 权重x: 0.556325, (0.01 * x.grad):0.011354 y:20.322260\n",
      "次数:144 权重x: 0.545199, (0.01 * x.grad):0.011127 y:20.309498\n",
      "次数:145 权重x: 0.534295, (0.01 * x.grad):0.010904 y:20.297241\n",
      "次数:146 权重x: 0.523609, (0.01 * x.grad):0.010686 y:20.285471\n",
      "次数:147 权重x: 0.513137, (0.01 * x.grad):0.010472 y:20.274166\n",
      "次数:148 权重x: 0.502874, (0.01 * x.grad):0.010263 y:20.263309\n",
      "次数:149 权重x: 0.492817, (0.01 * x.grad):0.010057 y:20.252882\n",
      "次数:150 权重x: 0.482960, (0.01 * x.grad):0.009856 y:20.242868\n",
      "次数:151 权重x: 0.473301, (0.01 * x.grad):0.009659 y:20.233250\n",
      "次数:152 权重x: 0.463835, (0.01 * x.grad):0.009466 y:20.224014\n",
      "次数:153 权重x: 0.454558, (0.01 * x.grad):0.009277 y:20.215143\n",
      "次数:154 权重x: 0.445467, (0.01 * x.grad):0.009091 y:20.206623\n",
      "次数:155 权重x: 0.436558, (0.01 * x.grad):0.008909 y:20.198441\n",
      "次数:156 权重x: 0.427827, (0.01 * x.grad):0.008731 y:20.190582\n",
      "次数:157 权重x: 0.419270, (0.01 * x.grad):0.008557 y:20.183035\n",
      "次数:158 权重x: 0.410885, (0.01 * x.grad):0.008385 y:20.175787\n",
      "次数:159 权重x: 0.402667, (0.01 * x.grad):0.008218 y:20.168827\n",
      "次数:160 权重x: 0.394614, (0.01 * x.grad):0.008053 y:20.162140\n",
      "次数:161 权重x: 0.386721, (0.01 * x.grad):0.007892 y:20.155720\n",
      "次数:162 权重x: 0.378987, (0.01 * x.grad):0.007734 y:20.149553\n",
      "次数:163 权重x: 0.371407, (0.01 * x.grad):0.007580 y:20.143631\n",
      "次数:164 权重x: 0.363979, (0.01 * x.grad):0.007428 y:20.137943\n",
      "次数:165 权重x: 0.356699, (0.01 * x.grad):0.007280 y:20.132481\n",
      "次数:166 权重x: 0.349566, (0.01 * x.grad):0.007134 y:20.127235\n",
      "次数:167 权重x: 0.342574, (0.01 * x.grad):0.006991 y:20.122196\n",
      "次数:168 权重x: 0.335723, (0.01 * x.grad):0.006851 y:20.117357\n",
      "次数:169 权重x: 0.329008, (0.01 * x.grad):0.006714 y:20.112709\n",
      "次数:170 权重x: 0.322428, (0.01 * x.grad):0.006580 y:20.108246\n",
      "次数:171 权重x: 0.315980, (0.01 * x.grad):0.006449 y:20.103960\n",
      "次数:172 权重x: 0.309660, (0.01 * x.grad):0.006320 y:20.099844\n",
      "次数:173 权重x: 0.303467, (0.01 * x.grad):0.006193 y:20.095890\n",
      "次数:174 权重x: 0.297397, (0.01 * x.grad):0.006069 y:20.092093\n",
      "次数:175 权重x: 0.291449, (0.01 * x.grad):0.005948 y:20.088446\n",
      "次数:176 权重x: 0.285620, (0.01 * x.grad):0.005829 y:20.084942\n",
      "次数:177 权重x: 0.279908, (0.01 * x.grad):0.005712 y:20.081579\n",
      "次数:178 权重x: 0.274310, (0.01 * x.grad):0.005598 y:20.078348\n",
      "次数:179 权重x: 0.268824, (0.01 * x.grad):0.005486 y:20.075247\n",
      "次数:180 权重x: 0.263447, (0.01 * x.grad):0.005376 y:20.072266\n",
      "次数:181 权重x: 0.258178, (0.01 * x.grad):0.005269 y:20.069405\n",
      "次数:182 权重x: 0.253015, (0.01 * x.grad):0.005164 y:20.066656\n",
      "次数:183 权重x: 0.247954, (0.01 * x.grad):0.005060 y:20.064016\n",
      "次数:184 权重x: 0.242995, (0.01 * x.grad):0.004959 y:20.061481\n",
      "次数:185 权重x: 0.238135, (0.01 * x.grad):0.004860 y:20.059046\n",
      "次数:186 权重x: 0.233373, (0.01 * x.grad):0.004763 y:20.056709\n",
      "次数:187 权重x: 0.228705, (0.01 * x.grad):0.004667 y:20.054462\n",
      "次数:188 权重x: 0.224131, (0.01 * x.grad):0.004574 y:20.052305\n",
      "次数:189 权重x: 0.219649, (0.01 * x.grad):0.004483 y:20.050234\n",
      "次数:190 权重x: 0.215256, (0.01 * x.grad):0.004393 y:20.048246\n",
      "次数:191 权重x: 0.210950, (0.01 * x.grad):0.004305 y:20.046335\n",
      "次数:192 权重x: 0.206731, (0.01 * x.grad):0.004219 y:20.044500\n",
      "次数:193 权重x: 0.202597, (0.01 * x.grad):0.004135 y:20.042738\n",
      "次数:194 权重x: 0.198545, (0.01 * x.grad):0.004052 y:20.041046\n",
      "次数:195 权重x: 0.194574, (0.01 * x.grad):0.003971 y:20.039419\n",
      "次数:196 权重x: 0.190682, (0.01 * x.grad):0.003891 y:20.037859\n",
      "次数:197 权重x: 0.186869, (0.01 * x.grad):0.003814 y:20.036360\n",
      "次数:198 权重x: 0.183131, (0.01 * x.grad):0.003737 y:20.034920\n",
      "次数:199 权重x: 0.179469, (0.01 * x.grad):0.003663 y:20.033537\n",
      "次数:200 权重x: 0.175879, (0.01 * x.grad):0.003589 y:20.032209\n",
      "次数:201 权重x: 0.172362, (0.01 * x.grad):0.003518 y:20.030933\n",
      "次数:202 权重x: 0.168915, (0.01 * x.grad):0.003447 y:20.029709\n",
      "次数:203 权重x: 0.165536, (0.01 * x.grad):0.003378 y:20.028532\n",
      "次数:204 权重x: 0.162226, (0.01 * x.grad):0.003311 y:20.027403\n",
      "次数:205 权重x: 0.158981, (0.01 * x.grad):0.003245 y:20.026318\n",
      "次数:206 权重x: 0.155801, (0.01 * x.grad):0.003180 y:20.025274\n",
      "次数:207 权重x: 0.152685, (0.01 * x.grad):0.003116 y:20.024275\n",
      "次数:208 权重x: 0.149632, (0.01 * x.grad):0.003054 y:20.023314\n",
      "次数:209 权重x: 0.146639, (0.01 * x.grad):0.002993 y:20.022390\n",
      "次数:210 权重x: 0.143706, (0.01 * x.grad):0.002933 y:20.021503\n",
      "次数:211 权重x: 0.140832, (0.01 * x.grad):0.002874 y:20.020651\n",
      "次数:212 权重x: 0.138016, (0.01 * x.grad):0.002817 y:20.019835\n",
      "次数:213 权重x: 0.135255, (0.01 * x.grad):0.002760 y:20.019049\n",
      "次数:214 权重x: 0.132550, (0.01 * x.grad):0.002705 y:20.018293\n",
      "次数:215 权重x: 0.129899, (0.01 * x.grad):0.002651 y:20.017569\n",
      "次数:216 权重x: 0.127301, (0.01 * x.grad):0.002598 y:20.016874\n",
      "次数:217 权重x: 0.124755, (0.01 * x.grad):0.002546 y:20.016205\n",
      "次数:218 权重x: 0.122260, (0.01 * x.grad):0.002495 y:20.015564\n",
      "次数:219 权重x: 0.119815, (0.01 * x.grad):0.002445 y:20.014948\n",
      "次数:220 权重x: 0.117419, (0.01 * x.grad):0.002396 y:20.014355\n",
      "次数:221 权重x: 0.115070, (0.01 * x.grad):0.002348 y:20.013786\n",
      "次数:222 权重x: 0.112769, (0.01 * x.grad):0.002301 y:20.013241\n",
      "次数:223 权重x: 0.110513, (0.01 * x.grad):0.002255 y:20.012716\n",
      "次数:224 权重x: 0.108303, (0.01 * x.grad):0.002210 y:20.012213\n",
      "次数:225 权重x: 0.106137, (0.01 * x.grad):0.002166 y:20.011730\n",
      "次数:226 权重x: 0.104014, (0.01 * x.grad):0.002123 y:20.011265\n",
      "次数:227 权重x: 0.101934, (0.01 * x.grad):0.002080 y:20.010818\n",
      "次数:228 权重x: 0.099895, (0.01 * x.grad):0.002039 y:20.010391\n",
      "次数:229 权重x: 0.097897, (0.01 * x.grad):0.001998 y:20.009979\n",
      "次数:230 权重x: 0.095939, (0.01 * x.grad):0.001958 y:20.009584\n",
      "次数:231 权重x: 0.094021, (0.01 * x.grad):0.001919 y:20.009205\n",
      "次数:232 权重x: 0.092140, (0.01 * x.grad):0.001880 y:20.008841\n",
      "次数:233 权重x: 0.090297, (0.01 * x.grad):0.001843 y:20.008490\n",
      "次数:234 权重x: 0.088492, (0.01 * x.grad):0.001806 y:20.008154\n",
      "次数:235 权重x: 0.086722, (0.01 * x.grad):0.001770 y:20.007832\n",
      "次数:236 权重x: 0.084987, (0.01 * x.grad):0.001734 y:20.007521\n",
      "次数:237 权重x: 0.083288, (0.01 * x.grad):0.001700 y:20.007223\n",
      "次数:238 权重x: 0.081622, (0.01 * x.grad):0.001666 y:20.006937\n",
      "次数:239 权重x: 0.079989, (0.01 * x.grad):0.001632 y:20.006662\n",
      "次数:240 权重x: 0.078390, (0.01 * x.grad):0.001600 y:20.006399\n",
      "次数:241 权重x: 0.076822, (0.01 * x.grad):0.001568 y:20.006145\n",
      "次数:242 权重x: 0.075285, (0.01 * x.grad):0.001536 y:20.005901\n",
      "次数:243 权重x: 0.073780, (0.01 * x.grad):0.001506 y:20.005669\n",
      "次数:244 权重x: 0.072304, (0.01 * x.grad):0.001476 y:20.005444\n",
      "次数:245 权重x: 0.070858, (0.01 * x.grad):0.001446 y:20.005228\n",
      "次数:246 权重x: 0.069441, (0.01 * x.grad):0.001417 y:20.005020\n",
      "次数:247 权重x: 0.068052, (0.01 * x.grad):0.001389 y:20.004822\n",
      "次数:248 权重x: 0.066691, (0.01 * x.grad):0.001361 y:20.004631\n",
      "次数:249 权重x: 0.065357, (0.01 * x.grad):0.001334 y:20.004448\n",
      "次数:250 权重x: 0.064050, (0.01 * x.grad):0.001307 y:20.004272\n",
      "次数:251 权重x: 0.062769, (0.01 * x.grad):0.001281 y:20.004103\n",
      "次数:252 权重x: 0.061514, (0.01 * x.grad):0.001255 y:20.003941\n",
      "次数:253 权重x: 0.060283, (0.01 * x.grad):0.001230 y:20.003784\n",
      "次数:254 权重x: 0.059078, (0.01 * x.grad):0.001206 y:20.003633\n",
      "次数:255 权重x: 0.057896, (0.01 * x.grad):0.001182 y:20.003490\n",
      "次数:256 权重x: 0.056738, (0.01 * x.grad):0.001158 y:20.003351\n",
      "次数:257 权重x: 0.055603, (0.01 * x.grad):0.001135 y:20.003220\n",
      "次数:258 权重x: 0.054491, (0.01 * x.grad):0.001112 y:20.003092\n",
      "次数:259 权重x: 0.053402, (0.01 * x.grad):0.001090 y:20.002970\n",
      "次数:260 权重x: 0.052333, (0.01 * x.grad):0.001068 y:20.002851\n",
      "次数:261 权重x: 0.051287, (0.01 * x.grad):0.001047 y:20.002739\n",
      "次数:262 权重x: 0.050261, (0.01 * x.grad):0.001026 y:20.002630\n",
      "次数:263 权重x: 0.049256, (0.01 * x.grad):0.001005 y:20.002525\n",
      "次数:264 权重x: 0.048271, (0.01 * x.grad):0.000985 y:20.002426\n",
      "次数:265 权重x: 0.047305, (0.01 * x.grad):0.000965 y:20.002331\n",
      "次数:266 权重x: 0.046359, (0.01 * x.grad):0.000946 y:20.002237\n",
      "次数:267 权重x: 0.045432, (0.01 * x.grad):0.000927 y:20.002150\n",
      "次数:268 权重x: 0.044523, (0.01 * x.grad):0.000909 y:20.002064\n",
      "次数:269 权重x: 0.043633, (0.01 * x.grad):0.000890 y:20.001982\n",
      "次数:270 权重x: 0.042760, (0.01 * x.grad):0.000873 y:20.001904\n",
      "次数:271 权重x: 0.041905, (0.01 * x.grad):0.000855 y:20.001829\n",
      "次数:272 权重x: 0.041067, (0.01 * x.grad):0.000838 y:20.001757\n",
      "次数:273 权重x: 0.040246, (0.01 * x.grad):0.000821 y:20.001686\n",
      "次数:274 权重x: 0.039441, (0.01 * x.grad):0.000805 y:20.001619\n",
      "次数:275 权重x: 0.038652, (0.01 * x.grad):0.000789 y:20.001556\n",
      "次数:276 权重x: 0.037879, (0.01 * x.grad):0.000773 y:20.001493\n",
      "次数:277 权重x: 0.037121, (0.01 * x.grad):0.000758 y:20.001434\n",
      "次数:278 权重x: 0.036379, (0.01 * x.grad):0.000742 y:20.001377\n",
      "次数:279 权重x: 0.035651, (0.01 * x.grad):0.000728 y:20.001324\n",
      "次数:280 权重x: 0.034938, (0.01 * x.grad):0.000713 y:20.001270\n",
      "次数:281 权重x: 0.034239, (0.01 * x.grad):0.000699 y:20.001221\n",
      "次数:282 权重x: 0.033555, (0.01 * x.grad):0.000685 y:20.001173\n",
      "次数:283 权重x: 0.032884, (0.01 * x.grad):0.000671 y:20.001125\n",
      "次数:284 权重x: 0.032226, (0.01 * x.grad):0.000658 y:20.001081\n",
      "次数:285 权重x: 0.031581, (0.01 * x.grad):0.000645 y:20.001038\n",
      "次数:286 权重x: 0.030950, (0.01 * x.grad):0.000632 y:20.000998\n",
      "次数:287 权重x: 0.030331, (0.01 * x.grad):0.000619 y:20.000957\n",
      "次数:288 权重x: 0.029724, (0.01 * x.grad):0.000607 y:20.000919\n",
      "次数:289 权重x: 0.029130, (0.01 * x.grad):0.000594 y:20.000883\n",
      "次数:290 权重x: 0.028547, (0.01 * x.grad):0.000583 y:20.000849\n",
      "次数:291 权重x: 0.027976, (0.01 * x.grad):0.000571 y:20.000814\n",
      "次数:292 权重x: 0.027417, (0.01 * x.grad):0.000560 y:20.000782\n",
      "次数:293 权重x: 0.026868, (0.01 * x.grad):0.000548 y:20.000751\n",
      "次数:294 权重x: 0.026331, (0.01 * x.grad):0.000537 y:20.000721\n",
      "次数:295 权重x: 0.025804, (0.01 * x.grad):0.000527 y:20.000692\n",
      "次数:296 权重x: 0.025288, (0.01 * x.grad):0.000516 y:20.000666\n",
      "次数:297 权重x: 0.024782, (0.01 * x.grad):0.000506 y:20.000639\n",
      "次数:298 权重x: 0.024287, (0.01 * x.grad):0.000496 y:20.000614\n",
      "次数:299 权重x: 0.023801, (0.01 * x.grad):0.000486 y:20.000589\n",
      "次数:300 权重x: 0.023325, (0.01 * x.grad):0.000476 y:20.000566\n",
      "次数:301 权重x: 0.022859, (0.01 * x.grad):0.000467 y:20.000544\n",
      "次数:302 权重x: 0.022401, (0.01 * x.grad):0.000457 y:20.000523\n",
      "次数:303 权重x: 0.021953, (0.01 * x.grad):0.000448 y:20.000502\n",
      "次数:304 权重x: 0.021514, (0.01 * x.grad):0.000439 y:20.000483\n",
      "次数:305 权重x: 0.021084, (0.01 * x.grad):0.000430 y:20.000463\n",
      "次数:306 权重x: 0.020662, (0.01 * x.grad):0.000422 y:20.000444\n",
      "次数:307 权重x: 0.020249, (0.01 * x.grad):0.000413 y:20.000427\n",
      "次数:308 权重x: 0.019844, (0.01 * x.grad):0.000405 y:20.000410\n",
      "次数:309 权重x: 0.019447, (0.01 * x.grad):0.000397 y:20.000393\n",
      "次数:310 权重x: 0.019058, (0.01 * x.grad):0.000389 y:20.000378\n",
      "次数:311 权重x: 0.018677, (0.01 * x.grad):0.000381 y:20.000362\n",
      "次数:312 权重x: 0.018304, (0.01 * x.grad):0.000374 y:20.000349\n",
      "次数:313 权重x: 0.017937, (0.01 * x.grad):0.000366 y:20.000336\n",
      "次数:314 权重x: 0.017579, (0.01 * x.grad):0.000359 y:20.000322\n",
      "次数:315 权重x: 0.017227, (0.01 * x.grad):0.000352 y:20.000309\n",
      "次数:316 权重x: 0.016883, (0.01 * x.grad):0.000345 y:20.000298\n",
      "次数:317 权重x: 0.016545, (0.01 * x.grad):0.000338 y:20.000284\n",
      "次数:318 权重x: 0.016214, (0.01 * x.grad):0.000331 y:20.000275\n",
      "次数:319 权重x: 0.015890, (0.01 * x.grad):0.000324 y:20.000263\n",
      "次数:320 权重x: 0.015572, (0.01 * x.grad):0.000318 y:20.000252\n",
      "次数:321 权重x: 0.015261, (0.01 * x.grad):0.000311 y:20.000242\n",
      "次数:322 权重x: 0.014955, (0.01 * x.grad):0.000305 y:20.000233\n",
      "次数:323 权重x: 0.014656, (0.01 * x.grad):0.000299 y:20.000223\n",
      "次数:324 权重x: 0.014363, (0.01 * x.grad):0.000293 y:20.000216\n",
      "次数:325 权重x: 0.014076, (0.01 * x.grad):0.000287 y:20.000206\n",
      "次数:326 权重x: 0.013794, (0.01 * x.grad):0.000282 y:20.000198\n",
      "次数:327 权重x: 0.013518, (0.01 * x.grad):0.000276 y:20.000191\n",
      "次数:328 权重x: 0.013248, (0.01 * x.grad):0.000270 y:20.000183\n",
      "次数:329 权重x: 0.012983, (0.01 * x.grad):0.000265 y:20.000175\n",
      "次数:330 权重x: 0.012723, (0.01 * x.grad):0.000260 y:20.000168\n",
      "次数:331 权重x: 0.012469, (0.01 * x.grad):0.000254 y:20.000162\n",
      "次数:332 权重x: 0.012220, (0.01 * x.grad):0.000249 y:20.000156\n",
      "次数:333 权重x: 0.011975, (0.01 * x.grad):0.000244 y:20.000149\n",
      "次数:334 权重x: 0.011736, (0.01 * x.grad):0.000240 y:20.000143\n",
      "次数:335 权重x: 0.011501, (0.01 * x.grad):0.000235 y:20.000137\n",
      "次数:336 权重x: 0.011271, (0.01 * x.grad):0.000230 y:20.000132\n",
      "次数:337 权重x: 0.011046, (0.01 * x.grad):0.000225 y:20.000128\n",
      "次数:338 权重x: 0.010825, (0.01 * x.grad):0.000221 y:20.000122\n",
      "次数:339 权重x: 0.010608, (0.01 * x.grad):0.000216 y:20.000116\n",
      "次数:340 权重x: 0.010396, (0.01 * x.grad):0.000212 y:20.000113\n",
      "次数:341 权重x: 0.010188, (0.01 * x.grad):0.000208 y:20.000109\n",
      "次数:342 权重x: 0.009984, (0.01 * x.grad):0.000204 y:20.000103\n",
      "次数:343 权重x: 0.009785, (0.01 * x.grad):0.000200 y:20.000099\n",
      "次数:344 权重x: 0.009589, (0.01 * x.grad):0.000196 y:20.000095\n",
      "次数:345 权重x: 0.009397, (0.01 * x.grad):0.000192 y:20.000092\n",
      "次数:346 权重x: 0.009209, (0.01 * x.grad):0.000188 y:20.000088\n",
      "次数:347 权重x: 0.009025, (0.01 * x.grad):0.000184 y:20.000084\n",
      "次数:348 权重x: 0.008845, (0.01 * x.grad):0.000181 y:20.000082\n",
      "次数:349 权重x: 0.008668, (0.01 * x.grad):0.000177 y:20.000078\n",
      "次数:350 权重x: 0.008494, (0.01 * x.grad):0.000173 y:20.000074\n",
      "次数:351 权重x: 0.008324, (0.01 * x.grad):0.000170 y:20.000072\n",
      "次数:352 权重x: 0.008158, (0.01 * x.grad):0.000166 y:20.000069\n",
      "次数:353 权重x: 0.007995, (0.01 * x.grad):0.000163 y:20.000067\n",
      "次数:354 权重x: 0.007835, (0.01 * x.grad):0.000160 y:20.000065\n",
      "次数:355 权重x: 0.007678, (0.01 * x.grad):0.000157 y:20.000061\n",
      "次数:356 权重x: 0.007525, (0.01 * x.grad):0.000154 y:20.000059\n",
      "次数:357 权重x: 0.007374, (0.01 * x.grad):0.000150 y:20.000057\n",
      "次数:358 权重x: 0.007227, (0.01 * x.grad):0.000147 y:20.000055\n",
      "次数:359 权重x: 0.007082, (0.01 * x.grad):0.000145 y:20.000051\n",
      "次数:360 权重x: 0.006940, (0.01 * x.grad):0.000142 y:20.000050\n",
      "次数:361 权重x: 0.006802, (0.01 * x.grad):0.000139 y:20.000048\n",
      "次数:362 权重x: 0.006666, (0.01 * x.grad):0.000136 y:20.000046\n",
      "次数:363 权重x: 0.006532, (0.01 * x.grad):0.000133 y:20.000044\n",
      "次数:364 权重x: 0.006402, (0.01 * x.grad):0.000131 y:20.000042\n",
      "次数:365 权重x: 0.006274, (0.01 * x.grad):0.000128 y:20.000040\n",
      "次数:366 权重x: 0.006148, (0.01 * x.grad):0.000125 y:20.000040\n",
      "次数:367 权重x: 0.006025, (0.01 * x.grad):0.000123 y:20.000038\n",
      "次数:368 权重x: 0.005905, (0.01 * x.grad):0.000121 y:20.000036\n",
      "次数:369 权重x: 0.005787, (0.01 * x.grad):0.000118 y:20.000034\n",
      "次数:370 权重x: 0.005671, (0.01 * x.grad):0.000116 y:20.000034\n",
      "次数:371 权重x: 0.005557, (0.01 * x.grad):0.000113 y:20.000032\n",
      "次数:372 权重x: 0.005446, (0.01 * x.grad):0.000111 y:20.000031\n",
      "次数:373 权重x: 0.005337, (0.01 * x.grad):0.000109 y:20.000031\n",
      "次数:374 权重x: 0.005231, (0.01 * x.grad):0.000107 y:20.000029\n",
      "次数:375 权重x: 0.005126, (0.01 * x.grad):0.000105 y:20.000027\n",
      "次数:376 权重x: 0.005023, (0.01 * x.grad):0.000103 y:20.000027\n",
      "次数:377 权重x: 0.004923, (0.01 * x.grad):0.000100 y:20.000025\n",
      "次数:378 权重x: 0.004825, (0.01 * x.grad):0.000098 y:20.000025\n",
      "次数:379 权重x: 0.004728, (0.01 * x.grad):0.000096 y:20.000023\n",
      "次数:380 权重x: 0.004633, (0.01 * x.grad):0.000095 y:20.000023\n",
      "次数:381 权重x: 0.004541, (0.01 * x.grad):0.000093 y:20.000021\n",
      "次数:382 权重x: 0.004450, (0.01 * x.grad):0.000091 y:20.000021\n",
      "次数:383 权重x: 0.004361, (0.01 * x.grad):0.000089 y:20.000019\n",
      "次数:384 权重x: 0.004274, (0.01 * x.grad):0.000087 y:20.000019\n",
      "次数:385 权重x: 0.004188, (0.01 * x.grad):0.000085 y:20.000019\n",
      "次数:386 权重x: 0.004105, (0.01 * x.grad):0.000084 y:20.000017\n",
      "次数:387 权重x: 0.004022, (0.01 * x.grad):0.000082 y:20.000017\n",
      "次数:388 权重x: 0.003942, (0.01 * x.grad):0.000080 y:20.000015\n",
      "次数:389 权重x: 0.003863, (0.01 * x.grad):0.000079 y:20.000015\n",
      "次数:390 权重x: 0.003786, (0.01 * x.grad):0.000077 y:20.000015\n",
      "次数:391 权重x: 0.003710, (0.01 * x.grad):0.000076 y:20.000015\n",
      "次数:392 权重x: 0.003636, (0.01 * x.grad):0.000074 y:20.000013\n",
      "次数:393 权重x: 0.003563, (0.01 * x.grad):0.000073 y:20.000013\n",
      "次数:394 权重x: 0.003492, (0.01 * x.grad):0.000071 y:20.000013\n",
      "次数:395 权重x: 0.003422, (0.01 * x.grad):0.000070 y:20.000011\n",
      "次数:396 权重x: 0.003354, (0.01 * x.grad):0.000068 y:20.000011\n",
      "次数:397 权重x: 0.003287, (0.01 * x.grad):0.000067 y:20.000011\n",
      "次数:398 权重x: 0.003221, (0.01 * x.grad):0.000066 y:20.000011\n",
      "次数:399 权重x: 0.003156, (0.01 * x.grad):0.000064 y:20.000010\n",
      "次数:400 权重x: 0.003093, (0.01 * x.grad):0.000063 y:20.000010\n",
      "次数:401 权重x: 0.003031, (0.01 * x.grad):0.000062 y:20.000010\n",
      "次数:402 权重x: 0.002971, (0.01 * x.grad):0.000061 y:20.000010\n",
      "次数:403 权重x: 0.002911, (0.01 * x.grad):0.000059 y:20.000010\n",
      "次数:404 权重x: 0.002853, (0.01 * x.grad):0.000058 y:20.000008\n",
      "次数:405 权重x: 0.002796, (0.01 * x.grad):0.000057 y:20.000008\n",
      "次数:406 权重x: 0.002740, (0.01 * x.grad):0.000056 y:20.000008\n",
      "次数:407 权重x: 0.002685, (0.01 * x.grad):0.000055 y:20.000008\n",
      "次数:408 权重x: 0.002632, (0.01 * x.grad):0.000054 y:20.000008\n",
      "次数:409 权重x: 0.002579, (0.01 * x.grad):0.000053 y:20.000008\n",
      "次数:410 权重x: 0.002527, (0.01 * x.grad):0.000052 y:20.000006\n",
      "次数:411 权重x: 0.002477, (0.01 * x.grad):0.000051 y:20.000006\n",
      "次数:412 权重x: 0.002427, (0.01 * x.grad):0.000050 y:20.000006\n",
      "次数:413 权重x: 0.002379, (0.01 * x.grad):0.000049 y:20.000006\n",
      "次数:414 权重x: 0.002331, (0.01 * x.grad):0.000048 y:20.000006\n",
      "次数:415 权重x: 0.002285, (0.01 * x.grad):0.000047 y:20.000006\n",
      "次数:416 权重x: 0.002239, (0.01 * x.grad):0.000046 y:20.000006\n",
      "次数:417 权重x: 0.002194, (0.01 * x.grad):0.000045 y:20.000006\n",
      "次数:418 权重x: 0.002150, (0.01 * x.grad):0.000044 y:20.000006\n",
      "次数:419 权重x: 0.002107, (0.01 * x.grad):0.000043 y:20.000004\n",
      "次数:420 权重x: 0.002065, (0.01 * x.grad):0.000042 y:20.000004\n",
      "次数:421 权重x: 0.002024, (0.01 * x.grad):0.000041 y:20.000004\n",
      "次数:422 权重x: 0.001983, (0.01 * x.grad):0.000040 y:20.000004\n",
      "次数:423 权重x: 0.001944, (0.01 * x.grad):0.000040 y:20.000004\n",
      "次数:424 权重x: 0.001905, (0.01 * x.grad):0.000039 y:20.000004\n",
      "次数:425 权重x: 0.001867, (0.01 * x.grad):0.000038 y:20.000004\n",
      "次数:426 权重x: 0.001829, (0.01 * x.grad):0.000037 y:20.000004\n",
      "次数:427 权重x: 0.001793, (0.01 * x.grad):0.000037 y:20.000004\n",
      "次数:428 权重x: 0.001757, (0.01 * x.grad):0.000036 y:20.000004\n",
      "次数:429 权重x: 0.001722, (0.01 * x.grad):0.000035 y:20.000004\n",
      "次数:430 权重x: 0.001687, (0.01 * x.grad):0.000034 y:20.000004\n",
      "次数:431 权重x: 0.001654, (0.01 * x.grad):0.000034 y:20.000002\n",
      "次数:432 权重x: 0.001621, (0.01 * x.grad):0.000033 y:20.000002\n",
      "次数:433 权重x: 0.001588, (0.01 * x.grad):0.000032 y:20.000002\n",
      "次数:434 权重x: 0.001556, (0.01 * x.grad):0.000032 y:20.000002\n",
      "次数:435 权重x: 0.001525, (0.01 * x.grad):0.000031 y:20.000002\n",
      "次数:436 权重x: 0.001495, (0.01 * x.grad):0.000031 y:20.000002\n",
      "次数:437 权重x: 0.001465, (0.01 * x.grad):0.000030 y:20.000002\n",
      "次数:438 权重x: 0.001436, (0.01 * x.grad):0.000029 y:20.000002\n",
      "次数:439 权重x: 0.001407, (0.01 * x.grad):0.000029 y:20.000002\n",
      "次数:440 权重x: 0.001379, (0.01 * x.grad):0.000028 y:20.000002\n",
      "次数:441 权重x: 0.001351, (0.01 * x.grad):0.000028 y:20.000002\n",
      "次数:442 权重x: 0.001324, (0.01 * x.grad):0.000027 y:20.000002\n",
      "次数:443 权重x: 0.001298, (0.01 * x.grad):0.000026 y:20.000002\n",
      "次数:444 权重x: 0.001272, (0.01 * x.grad):0.000026 y:20.000002\n",
      "次数:445 权重x: 0.001246, (0.01 * x.grad):0.000025 y:20.000002\n",
      "次数:446 权重x: 0.001221, (0.01 * x.grad):0.000025 y:20.000002\n",
      "次数:447 权重x: 0.001197, (0.01 * x.grad):0.000024 y:20.000002\n",
      "次数:448 权重x: 0.001173, (0.01 * x.grad):0.000024 y:20.000002\n",
      "次数:449 权重x: 0.001149, (0.01 * x.grad):0.000023 y:20.000002\n",
      "次数:450 权重x: 0.001127, (0.01 * x.grad):0.000023 y:20.000002\n",
      "次数:451 权重x: 0.001104, (0.01 * x.grad):0.000023 y:20.000002\n",
      "次数:452 权重x: 0.001082, (0.01 * x.grad):0.000022 y:20.000002\n",
      "次数:453 权重x: 0.001060, (0.01 * x.grad):0.000022 y:20.000002\n",
      "次数:454 权重x: 0.001039, (0.01 * x.grad):0.000021 y:20.000002\n",
      "次数:455 权重x: 0.001018, (0.01 * x.grad):0.000021 y:20.000002\n",
      "次数:456 权重x: 0.000998, (0.01 * x.grad):0.000020 y:20.000002\n",
      "次数:457 权重x: 0.000978, (0.01 * x.grad):0.000020 y:20.000002\n",
      "次数:458 权重x: 0.000958, (0.01 * x.grad):0.000020 y:20.000002\n",
      "次数:459 权重x: 0.000939, (0.01 * x.grad):0.000019 y:20.000000\n",
      "次数:460 权重x: 0.000920, (0.01 * x.grad):0.000019 y:20.000000\n",
      "次数:461 权重x: 0.000902, (0.01 * x.grad):0.000018 y:20.000000\n",
      "次数:462 权重x: 0.000884, (0.01 * x.grad):0.000018 y:20.000000\n",
      "次数:463 权重x: 0.000866, (0.01 * x.grad):0.000018 y:20.000000\n",
      "次数:464 权重x: 0.000849, (0.01 * x.grad):0.000017 y:20.000000\n",
      "次数:465 权重x: 0.000832, (0.01 * x.grad):0.000017 y:20.000000\n",
      "次数:466 权重x: 0.000815, (0.01 * x.grad):0.000017 y:20.000000\n",
      "次数:467 权重x: 0.000799, (0.01 * x.grad):0.000016 y:20.000000\n",
      "次数:468 权重x: 0.000783, (0.01 * x.grad):0.000016 y:20.000000\n",
      "次数:469 权重x: 0.000767, (0.01 * x.grad):0.000016 y:20.000000\n",
      "次数:470 权重x: 0.000752, (0.01 * x.grad):0.000015 y:20.000000\n",
      "次数:471 权重x: 0.000737, (0.01 * x.grad):0.000015 y:20.000000\n",
      "次数:472 权重x: 0.000722, (0.01 * x.grad):0.000015 y:20.000000\n",
      "次数:473 权重x: 0.000708, (0.01 * x.grad):0.000014 y:20.000000\n",
      "次数:474 权重x: 0.000694, (0.01 * x.grad):0.000014 y:20.000000\n",
      "次数:475 权重x: 0.000680, (0.01 * x.grad):0.000014 y:20.000000\n",
      "次数:476 权重x: 0.000666, (0.01 * x.grad):0.000014 y:20.000000\n",
      "次数:477 权重x: 0.000653, (0.01 * x.grad):0.000013 y:20.000000\n",
      "次数:478 权重x: 0.000640, (0.01 * x.grad):0.000013 y:20.000000\n",
      "次数:479 权重x: 0.000627, (0.01 * x.grad):0.000013 y:20.000000\n",
      "次数:480 权重x: 0.000614, (0.01 * x.grad):0.000013 y:20.000000\n",
      "次数:481 权重x: 0.000602, (0.01 * x.grad):0.000012 y:20.000000\n",
      "次数:482 权重x: 0.000590, (0.01 * x.grad):0.000012 y:20.000000\n",
      "次数:483 权重x: 0.000578, (0.01 * x.grad):0.000012 y:20.000000\n",
      "次数:484 权重x: 0.000567, (0.01 * x.grad):0.000012 y:20.000000\n",
      "次数:485 权重x: 0.000555, (0.01 * x.grad):0.000011 y:20.000000\n",
      "次数:486 权重x: 0.000544, (0.01 * x.grad):0.000011 y:20.000000\n",
      "次数:487 权重x: 0.000533, (0.01 * x.grad):0.000011 y:20.000000\n",
      "次数:488 权重x: 0.000523, (0.01 * x.grad):0.000011 y:20.000000\n",
      "次数:489 权重x: 0.000512, (0.01 * x.grad):0.000010 y:20.000000\n",
      "次数:490 权重x: 0.000502, (0.01 * x.grad):0.000010 y:20.000000\n",
      "次数:491 权重x: 0.000492, (0.01 * x.grad):0.000010 y:20.000000\n",
      "次数:492 权重x: 0.000482, (0.01 * x.grad):0.000010 y:20.000000\n",
      "次数:493 权重x: 0.000473, (0.01 * x.grad):0.000010 y:20.000000\n",
      "次数:494 权重x: 0.000463, (0.01 * x.grad):0.000009 y:20.000000\n",
      "次数:495 权重x: 0.000454, (0.01 * x.grad):0.000009 y:20.000000\n",
      "次数:496 权重x: 0.000445, (0.01 * x.grad):0.000009 y:20.000000\n",
      "次数:497 权重x: 0.000436, (0.01 * x.grad):0.000009 y:20.000000\n",
      "次数:498 权重x: 0.000427, (0.01 * x.grad):0.000009 y:20.000000\n",
      "次数:499 权重x: 0.000419, (0.01 * x.grad):0.000009 y:20.000000\n",
      "次数:500 权重x: 0.000410, (0.01 * x.grad):0.000008 y:20.000000\n",
      "次数:501 权重x: 0.000402, (0.01 * x.grad):0.000008 y:20.000000\n",
      "次数:502 权重x: 0.000394, (0.01 * x.grad):0.000008 y:20.000000\n",
      "次数:503 权重x: 0.000386, (0.01 * x.grad):0.000008 y:20.000000\n",
      "次数:504 权重x: 0.000378, (0.01 * x.grad):0.000008 y:20.000000\n",
      "次数:505 权重x: 0.000371, (0.01 * x.grad):0.000008 y:20.000000\n",
      "次数:506 权重x: 0.000363, (0.01 * x.grad):0.000007 y:20.000000\n",
      "次数:507 权重x: 0.000356, (0.01 * x.grad):0.000007 y:20.000000\n",
      "次数:508 权重x: 0.000349, (0.01 * x.grad):0.000007 y:20.000000\n",
      "次数:509 权重x: 0.000342, (0.01 * x.grad):0.000007 y:20.000000\n",
      "次数:510 权重x: 0.000335, (0.01 * x.grad):0.000007 y:20.000000\n",
      "次数:511 权重x: 0.000328, (0.01 * x.grad):0.000007 y:20.000000\n",
      "次数:512 权重x: 0.000322, (0.01 * x.grad):0.000007 y:20.000000\n",
      "次数:513 权重x: 0.000315, (0.01 * x.grad):0.000006 y:20.000000\n",
      "次数:514 权重x: 0.000309, (0.01 * x.grad):0.000006 y:20.000000\n",
      "次数:515 权重x: 0.000303, (0.01 * x.grad):0.000006 y:20.000000\n",
      "次数:516 权重x: 0.000297, (0.01 * x.grad):0.000006 y:20.000000\n",
      "次数:517 权重x: 0.000291, (0.01 * x.grad):0.000006 y:20.000000\n",
      "次数:518 权重x: 0.000285, (0.01 * x.grad):0.000006 y:20.000000\n",
      "次数:519 权重x: 0.000279, (0.01 * x.grad):0.000006 y:20.000000\n",
      "次数:520 权重x: 0.000274, (0.01 * x.grad):0.000006 y:20.000000\n",
      "次数:521 权重x: 0.000268, (0.01 * x.grad):0.000005 y:20.000000\n",
      "次数:522 权重x: 0.000263, (0.01 * x.grad):0.000005 y:20.000000\n",
      "次数:523 权重x: 0.000258, (0.01 * x.grad):0.000005 y:20.000000\n",
      "次数:524 权重x: 0.000253, (0.01 * x.grad):0.000005 y:20.000000\n",
      "次数:525 权重x: 0.000248, (0.01 * x.grad):0.000005 y:20.000000\n",
      "次数:526 权重x: 0.000243, (0.01 * x.grad):0.000005 y:20.000000\n",
      "次数:527 权重x: 0.000238, (0.01 * x.grad):0.000005 y:20.000000\n",
      "次数:528 权重x: 0.000233, (0.01 * x.grad):0.000005 y:20.000000\n",
      "次数:529 权重x: 0.000228, (0.01 * x.grad):0.000005 y:20.000000\n",
      "次数:530 权重x: 0.000224, (0.01 * x.grad):0.000005 y:20.000000\n",
      "次数:531 权重x: 0.000219, (0.01 * x.grad):0.000004 y:20.000000\n",
      "次数:532 权重x: 0.000215, (0.01 * x.grad):0.000004 y:20.000000\n",
      "次数:533 权重x: 0.000211, (0.01 * x.grad):0.000004 y:20.000000\n",
      "次数:534 权重x: 0.000206, (0.01 * x.grad):0.000004 y:20.000000\n",
      "次数:535 权重x: 0.000202, (0.01 * x.grad):0.000004 y:20.000000\n",
      "次数:536 权重x: 0.000198, (0.01 * x.grad):0.000004 y:20.000000\n",
      "次数:537 权重x: 0.000194, (0.01 * x.grad):0.000004 y:20.000000\n",
      "次数:538 权重x: 0.000190, (0.01 * x.grad):0.000004 y:20.000000\n",
      "次数:539 权重x: 0.000187, (0.01 * x.grad):0.000004 y:20.000000\n",
      "次数:540 权重x: 0.000183, (0.01 * x.grad):0.000004 y:20.000000\n",
      "次数:541 权重x: 0.000179, (0.01 * x.grad):0.000004 y:20.000000\n",
      "次数:542 权重x: 0.000176, (0.01 * x.grad):0.000004 y:20.000000\n",
      "次数:543 权重x: 0.000172, (0.01 * x.grad):0.000004 y:20.000000\n",
      "次数:544 权重x: 0.000169, (0.01 * x.grad):0.000003 y:20.000000\n",
      "次数:545 权重x: 0.000165, (0.01 * x.grad):0.000003 y:20.000000\n",
      "次数:546 权重x: 0.000162, (0.01 * x.grad):0.000003 y:20.000000\n",
      "次数:547 权重x: 0.000159, (0.01 * x.grad):0.000003 y:20.000000\n",
      "次数:548 权重x: 0.000156, (0.01 * x.grad):0.000003 y:20.000000\n",
      "次数:549 权重x: 0.000152, (0.01 * x.grad):0.000003 y:20.000000\n",
      "次数:550 权重x: 0.000149, (0.01 * x.grad):0.000003 y:20.000000\n",
      "次数:551 权重x: 0.000146, (0.01 * x.grad):0.000003 y:20.000000\n",
      "次数:552 权重x: 0.000143, (0.01 * x.grad):0.000003 y:20.000000\n",
      "次数:553 权重x: 0.000141, (0.01 * x.grad):0.000003 y:20.000000\n",
      "次数:554 权重x: 0.000138, (0.01 * x.grad):0.000003 y:20.000000\n",
      "次数:555 权重x: 0.000135, (0.01 * x.grad):0.000003 y:20.000000\n",
      "次数:556 权重x: 0.000132, (0.01 * x.grad):0.000003 y:20.000000\n",
      "次数:557 权重x: 0.000130, (0.01 * x.grad):0.000003 y:20.000000\n",
      "次数:558 权重x: 0.000127, (0.01 * x.grad):0.000003 y:20.000000\n",
      "次数:559 权重x: 0.000125, (0.01 * x.grad):0.000003 y:20.000000\n",
      "次数:560 权重x: 0.000122, (0.01 * x.grad):0.000002 y:20.000000\n",
      "次数:561 权重x: 0.000120, (0.01 * x.grad):0.000002 y:20.000000\n",
      "次数:562 权重x: 0.000117, (0.01 * x.grad):0.000002 y:20.000000\n",
      "次数:563 权重x: 0.000115, (0.01 * x.grad):0.000002 y:20.000000\n",
      "次数:564 权重x: 0.000113, (0.01 * x.grad):0.000002 y:20.000000\n",
      "次数:565 权重x: 0.000110, (0.01 * x.grad):0.000002 y:20.000000\n",
      "次数:566 权重x: 0.000108, (0.01 * x.grad):0.000002 y:20.000000\n",
      "次数:567 权重x: 0.000106, (0.01 * x.grad):0.000002 y:20.000000\n",
      "次数:568 权重x: 0.000104, (0.01 * x.grad):0.000002 y:20.000000\n",
      "次数:569 权重x: 0.000102, (0.01 * x.grad):0.000002 y:20.000000\n",
      "次数:570 权重x: 0.000100, (0.01 * x.grad):0.000002 y:20.000000\n",
      "次数:571 权重x: 0.000098, (0.01 * x.grad):0.000002 y:20.000000\n",
      "次数:572 权重x: 0.000096, (0.01 * x.grad):0.000002 y:20.000000\n",
      "次数:573 权重x: 0.000094, (0.01 * x.grad):0.000002 y:20.000000\n",
      "次数:574 权重x: 0.000092, (0.01 * x.grad):0.000002 y:20.000000\n",
      "次数:575 权重x: 0.000090, (0.01 * x.grad):0.000002 y:20.000000\n",
      "次数:576 权重x: 0.000088, (0.01 * x.grad):0.000002 y:20.000000\n",
      "次数:577 权重x: 0.000087, (0.01 * x.grad):0.000002 y:20.000000\n",
      "次数:578 权重x: 0.000085, (0.01 * x.grad):0.000002 y:20.000000\n",
      "次数:579 权重x: 0.000083, (0.01 * x.grad):0.000002 y:20.000000\n",
      "次数:580 权重x: 0.000081, (0.01 * x.grad):0.000002 y:20.000000\n",
      "次数:581 权重x: 0.000080, (0.01 * x.grad):0.000002 y:20.000000\n",
      "次数:582 权重x: 0.000078, (0.01 * x.grad):0.000002 y:20.000000\n",
      "次数:583 权重x: 0.000077, (0.01 * x.grad):0.000002 y:20.000000\n",
      "次数:584 权重x: 0.000075, (0.01 * x.grad):0.000002 y:20.000000\n",
      "次数:585 权重x: 0.000074, (0.01 * x.grad):0.000002 y:20.000000\n",
      "次数:586 权重x: 0.000072, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:587 权重x: 0.000071, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:588 权重x: 0.000069, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:589 权重x: 0.000068, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:590 权重x: 0.000067, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:591 权重x: 0.000065, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:592 权重x: 0.000064, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:593 权重x: 0.000063, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:594 权重x: 0.000061, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:595 权重x: 0.000060, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:596 权重x: 0.000059, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:597 权重x: 0.000058, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:598 权重x: 0.000057, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:599 权重x: 0.000056, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:600 权重x: 0.000054, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:601 权重x: 0.000053, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:602 权重x: 0.000052, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:603 权重x: 0.000051, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:604 权重x: 0.000050, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:605 权重x: 0.000049, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:606 权重x: 0.000048, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:607 权重x: 0.000047, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:608 权重x: 0.000046, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:609 权重x: 0.000045, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:610 权重x: 0.000044, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:611 权重x: 0.000044, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:612 权重x: 0.000043, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:613 权重x: 0.000042, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:614 权重x: 0.000041, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:615 权重x: 0.000040, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:616 权重x: 0.000039, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:617 权重x: 0.000039, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:618 权重x: 0.000038, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:619 权重x: 0.000037, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:620 权重x: 0.000036, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:621 权重x: 0.000036, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:622 权重x: 0.000035, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:623 权重x: 0.000034, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:624 权重x: 0.000034, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:625 权重x: 0.000033, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:626 权重x: 0.000032, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:627 权重x: 0.000032, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:628 权重x: 0.000031, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:629 权重x: 0.000030, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:630 权重x: 0.000030, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:631 权重x: 0.000029, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:632 权重x: 0.000029, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:633 权重x: 0.000028, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:634 权重x: 0.000027, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:635 权重x: 0.000027, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:636 权重x: 0.000026, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:637 权重x: 0.000026, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:638 权重x: 0.000025, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:639 权重x: 0.000025, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:640 权重x: 0.000024, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:641 权重x: 0.000024, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:642 权重x: 0.000023, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:643 权重x: 0.000023, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:644 权重x: 0.000022, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:645 权重x: 0.000022, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:646 权重x: 0.000021, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:647 权重x: 0.000021, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:648 权重x: 0.000021, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:649 权重x: 0.000020, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:650 权重x: 0.000020, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:651 权重x: 0.000019, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:652 权重x: 0.000019, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:653 权重x: 0.000019, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:654 权重x: 0.000018, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:655 权重x: 0.000018, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:656 权重x: 0.000018, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:657 权重x: 0.000017, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:658 权重x: 0.000017, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:659 权重x: 0.000017, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:660 权重x: 0.000016, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:661 权重x: 0.000016, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:662 权重x: 0.000016, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:663 权重x: 0.000015, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:664 权重x: 0.000015, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:665 权重x: 0.000015, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:666 权重x: 0.000014, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:667 权重x: 0.000014, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:668 权重x: 0.000014, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:669 权重x: 0.000013, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:670 权重x: 0.000013, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:671 权重x: 0.000013, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:672 权重x: 0.000013, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:673 权重x: 0.000012, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:674 权重x: 0.000012, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:675 权重x: 0.000012, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:676 权重x: 0.000012, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:677 权重x: 0.000011, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:678 权重x: 0.000011, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:679 权重x: 0.000011, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:680 权重x: 0.000011, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:681 权重x: 0.000011, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:682 权重x: 0.000010, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:683 权重x: 0.000010, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:684 权重x: 0.000010, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:685 权重x: 0.000010, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:686 权重x: 0.000010, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:687 权重x: 0.000009, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:688 权重x: 0.000009, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:689 权重x: 0.000009, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:690 权重x: 0.000009, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:691 权重x: 0.000009, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:692 权重x: 0.000008, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:693 权重x: 0.000008, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:694 权重x: 0.000008, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:695 权重x: 0.000008, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:696 权重x: 0.000008, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:697 权重x: 0.000008, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:698 权重x: 0.000008, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:699 权重x: 0.000007, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:700 权重x: 0.000007, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:701 权重x: 0.000007, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:702 权重x: 0.000007, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:703 权重x: 0.000007, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:704 权重x: 0.000007, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:705 权重x: 0.000007, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:706 权重x: 0.000006, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:707 权重x: 0.000006, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:708 权重x: 0.000006, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:709 权重x: 0.000006, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:710 权重x: 0.000006, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:711 权重x: 0.000006, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:712 权重x: 0.000006, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:713 权重x: 0.000006, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:714 权重x: 0.000005, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:715 权重x: 0.000005, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:716 权重x: 0.000005, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:717 权重x: 0.000005, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:718 权重x: 0.000005, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:719 权重x: 0.000005, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:720 权重x: 0.000005, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:721 权重x: 0.000005, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:722 权重x: 0.000005, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:723 权重x: 0.000005, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:724 权重x: 0.000004, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:725 权重x: 0.000004, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:726 权重x: 0.000004, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:727 权重x: 0.000004, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:728 权重x: 0.000004, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:729 权重x: 0.000004, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:730 权重x: 0.000004, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:731 权重x: 0.000004, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:732 权重x: 0.000004, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:733 权重x: 0.000004, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:734 权重x: 0.000004, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:735 权重x: 0.000004, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:736 权重x: 0.000003, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:737 权重x: 0.000003, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:738 权重x: 0.000003, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:739 权重x: 0.000003, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:740 权重x: 0.000003, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:741 权重x: 0.000003, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:742 权重x: 0.000003, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:743 权重x: 0.000003, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:744 权重x: 0.000003, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:745 权重x: 0.000003, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:746 权重x: 0.000003, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:747 权重x: 0.000003, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:748 权重x: 0.000003, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:749 权重x: 0.000003, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:750 权重x: 0.000003, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:751 权重x: 0.000003, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:752 权重x: 0.000003, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:753 权重x: 0.000002, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:754 权重x: 0.000002, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:755 权重x: 0.000002, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:756 权重x: 0.000002, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:757 权重x: 0.000002, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:758 权重x: 0.000002, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:759 权重x: 0.000002, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:760 权重x: 0.000002, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:761 权重x: 0.000002, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:762 权重x: 0.000002, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:763 权重x: 0.000002, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:764 权重x: 0.000002, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:765 权重x: 0.000002, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:766 权重x: 0.000002, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:767 权重x: 0.000002, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:768 权重x: 0.000002, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:769 权重x: 0.000002, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:770 权重x: 0.000002, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:771 权重x: 0.000002, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:772 权重x: 0.000002, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:773 权重x: 0.000002, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:774 权重x: 0.000002, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:775 权重x: 0.000002, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:776 权重x: 0.000002, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:777 权重x: 0.000002, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:778 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:779 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:780 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:781 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:782 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:783 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:784 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:785 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:786 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:787 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:788 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:789 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:790 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:791 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:792 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:793 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:794 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:795 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:796 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:797 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:798 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:799 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:800 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:801 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:802 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:803 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:804 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:805 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:806 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:807 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:808 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:809 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:810 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:811 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:812 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:813 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:814 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:815 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:816 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:817 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:818 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:819 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:820 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:821 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:822 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:823 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:824 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:825 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:826 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:827 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:828 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:829 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:830 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:831 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:832 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:833 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:834 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:835 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:836 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:837 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:838 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:839 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:840 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:841 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:842 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:843 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:844 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:845 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:846 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:847 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:848 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:849 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:850 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:851 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:852 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:853 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:854 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:855 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:856 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:857 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:858 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:859 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:860 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:861 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:862 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:863 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:864 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:865 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:866 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:867 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:868 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:869 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:870 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:871 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:872 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:873 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:874 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:875 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:876 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:877 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:878 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:879 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:880 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:881 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:882 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:883 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:884 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:885 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:886 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:887 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:888 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:889 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:890 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:891 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:892 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:893 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:894 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:895 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:896 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:897 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:898 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:899 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:900 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:901 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:902 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:903 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:904 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:905 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:906 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:907 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:908 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:909 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:910 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:911 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:912 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:913 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:914 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:915 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:916 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:917 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:918 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:919 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:920 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:921 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:922 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:923 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:924 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:925 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:926 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:927 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:928 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:929 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:930 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:931 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:932 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:933 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:934 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:935 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:936 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:937 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:938 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:939 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:940 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:941 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:942 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:943 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:944 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:945 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:946 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:947 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:948 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:949 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:950 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:951 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:952 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:953 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:954 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:955 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:956 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:957 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:958 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:959 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:960 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:961 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:962 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:963 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:964 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:965 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:966 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:967 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:968 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:969 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:970 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:971 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:972 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:973 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:974 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:975 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:976 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:977 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:978 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:979 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:980 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:981 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:982 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:983 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:984 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:985 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:986 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:987 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:988 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:989 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:990 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:991 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:992 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:993 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:994 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:995 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:996 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:997 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:998 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:999 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:1000 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "x： tensor(1.6830e-08, requires_grad=True) tensor(3.4346e-08) y最小值 tensor(20., grad_fn=<AddBackward0>)\n",
      "True\n",
      "False\n",
      "tensor([10., 20.], dtype=torch.float64)\n",
      "tensor([10., 20.], dtype=torch.float64)\n",
      "140526910107792\n",
      "140526910107792\n",
      "tensor([10., 20.], dtype=torch.float64)\n"
     ]
    }
   ],
   "execution_count": 119
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T11:13:30.112455Z",
     "start_time": "2025-03-23T11:13:30.061218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "def automatic_differentiation():\n",
    "    '''\n",
    "    自动微分模块应用\n",
    "    :return: \n",
    "    '''\n",
    "\n",
    "    # 输入张量 2*5\n",
    "    x = torch.ones(2, 5)\n",
    "    # 目标值是 2*3    \n",
    "    y = torch.zeros(2, 3)\n",
    "    # 设置要更新的权重和偏置的初始值\n",
    "    w = torch.randn(5, 3, requires_grad=True)\n",
    "    b = torch.randn(3, requires_grad=True)\n",
    "    # 设置网络的输出值\n",
    "    z = torch.matmul(x, w) + b  # 矩阵乘法\n",
    "    # 设置损失函数，并进行损失的计算\n",
    "    loss = torch.nn.MSELoss()\n",
    "    loss = loss(z, y)\n",
    "    # 自动微分\n",
    "    loss.backward()\n",
    "    # 打印 w,b 变量的梯度\n",
    "    # backward 函数计算的梯度值会存储在张量的 grad 变量中\n",
    "    print(\"W的梯度:\", w.grad)\n",
    "    print(\"b的梯度\", b.grad)\n",
    "\n",
    "automatic_differentiation()"
   ],
   "id": "66fb6a3bec5f4bc9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W的梯度: tensor([[ 1.8780,  0.1972, -1.2748],\n",
      "        [ 1.8780,  0.1972, -1.2748],\n",
      "        [ 1.8780,  0.1972, -1.2748],\n",
      "        [ 1.8780,  0.1972, -1.2748],\n",
      "        [ 1.8780,  0.1972, -1.2748]])\n",
      "b的梯度 tensor([ 1.8780,  0.1972, -1.2748])\n"
     ]
    }
   ],
   "execution_count": 120
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T11:16:04.893745Z",
     "start_time": "2025-03-23T11:15:49.748260Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "使用 PyTorch 的 nn.MSELoss() 代替平方损失函数\n",
    "使用 PyTorch 的 data.DataLoader 代替数据加载器\n",
    "使用 PyTorch 的 optim.SGD 代替优化器\n",
    "使用 PyTorch 的 nn.Linear 代替假设函数\n",
    "'''\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset  # 构造数据集对象\n",
    "from torch.utils.data import DataLoader  # 数据加载器\n",
    "from torch import nn  # nn模块中有平方损失函数和假设函数\n",
    "from torch import optim  # optim模块中有优化器函数\n",
    "from sklearn.datasets import make_regression  # 创建线性回归模型数据集\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# 构造数据集\n",
    "def create_dataset():\n",
    "    x, y, coef = make_regression(n_samples=100,\n",
    "                                 n_features=1,\n",
    "                                 noise=10,\n",
    "                                 coef=True,\n",
    "                                 bias=14.5,\n",
    "                                 random_state=0)\n",
    "\n",
    "    # 将构建数据转换为张量类型\n",
    "    x = torch.tensor(x)\n",
    "    y = torch.tensor(y)\n",
    "\n",
    "    return x, y, coef\n",
    "\n",
    "# 训练模型\n",
    "def construct_liner_regression_model():\n",
    "    # 构造数据集\n",
    "    x, y, coef = create_dataset()\n",
    "\n",
    "    # 构造数据集对象\n",
    "    dataset = TensorDataset(x, y)\n",
    "\n",
    "    # 构造数据加载器\n",
    "    # dataset=:数据集对象\n",
    "    # batch_size=:批量训练样本数据\n",
    "    # shuffle=:样本数据是否进行乱序\n",
    "    dataloader = DataLoader(dataset=dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "    # 构造模型\n",
    "    # in_features指的是输入的二维张量的大小，即输入的[batch_size, size]中的size\n",
    "    # out_features指的是输出的二维张量的大小，即输出的[batch_size，size]中的size\n",
    "    model = nn.Linear(in_features=1, out_features=1)\n",
    "\n",
    "    # 构造平方损失函数\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # 构造优化函数\n",
    "    # params=model.parameters():训练的参数,w和b\n",
    "    # lr=1e-2:学习率, 1e-2为10的负二次方\n",
    "    print(\"w和b-->\", list(model.parameters()))\n",
    "    print(\"w-->\", model.weight)\n",
    "    print(\"b-->\", model.bias)\n",
    "    optimizer = optim.SGD(params=model.parameters(), lr=1e-2)\n",
    "\n",
    "    # 初始化训练次数\n",
    "    epochs = 100\n",
    "    # 损失的变化\n",
    "    epoch_loss = []\n",
    "    total_loss=0.0\n",
    "    train_sample=0.0\n",
    "    for _ in range(epochs):\n",
    "        for train_x, train_y in dataloader:\n",
    "            # 将一个batch的训练数据送入模型\n",
    "            y_pred = model(train_x.type(torch.float32))\n",
    "            # 计算损失值,均方误差,当前批次所有样本的平均误差 \n",
    "            loss = criterion(y_pred, train_y.reshape(-1, 1).type(torch.float32))\n",
    "            total_loss += loss.item()\n",
    "            # loss是平均误差,所以样本数+1\n",
    "            train_sample += 1\n",
    "            # 梯度清零\n",
    "            optimizer.zero_grad()\n",
    "            # 自动微分(反向传播)\n",
    "            loss.backward()\n",
    "            # 更新参数\n",
    "            optimizer.step()\n",
    "        # 计算所有batch的平均误差作为当前epoch的误差 \n",
    "        epoch_loss.append(total_loss/train_sample)\n",
    "\n",
    "    # 打印回归模型的w\n",
    "    print(model.weight)\n",
    "    # 打印回归模型的b\n",
    "    print(model.bias)\n",
    "\n",
    "    # 绘制损失变化曲线 \n",
    "    plt.plot(range(epochs), epoch_loss)\n",
    "    plt.title('损失变化曲线')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    # 绘制拟合直线\n",
    "    plt.scatter(x, y)\n",
    "    x = torch.linspace(x.min(), x.max(), 1000)\n",
    "    y1 = torch.tensor([v * model.weight + model.bias for v in x])\n",
    "    y2 = torch.tensor([v * coef + 14.5 for v in x])\n",
    "    plt.plot(x, y1, label='训练')\n",
    "    plt.plot(x, y2, label='真实')\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "construct_liner_regression_model()"
   ],
   "id": "6108a7b6bbbb583d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/opt/anaconda3/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/anaconda3/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/anaconda3/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/anaconda3/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/anaconda3/lib/python3.9/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3024, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3079, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3284, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3466, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/4n/qh91m_wd5fj7fm56fsm72yth0000gp/T/ipykernel_33093/629159242.py\", line 13, in <module>\n",
      "    from sklearn.datasets import make_regression  # 创建线性回归模型数据集\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/__init__.py\", line 73, in <module>\n",
      "    from .base import clone  # noqa: E402\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 19, in <module>\n",
      "    from .utils._estimator_html_repr import _HTMLDocumentationLinkMixin, estimator_html_repr\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py\", line 15, in <module>\n",
      "    from ._chunking import gen_batches, gen_even_slices\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_chunking.py\", line 11, in <module>\n",
      "    from ._param_validation import Interval, validate_params\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 17, in <module>\n",
      "    from .validation import _is_arraylike_not_scalar\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 21, in <module>\n",
      "    from ..utils._array_api import _asarray_with_order, _is_numpy_namespace, get_namespace\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_array_api.py\", line 17, in <module>\n",
      "    from .fixes import parse_version\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 20, in <module>\n",
      "    import pandas as pd\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/pandas/__init__.py\", line 26, in <module>\n",
      "    from pandas.compat import (\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/pandas/compat/__init__.py\", line 27, in <module>\n",
      "    from pandas.compat.pyarrow import (\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/pandas/compat/pyarrow.py\", line 8, in <module>\n",
      "    import pyarrow as pa\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/pyarrow/__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;31mAttributeError\u001B[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/opt/anaconda3/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/anaconda3/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/anaconda3/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/anaconda3/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/anaconda3/lib/python3.9/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3024, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3079, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3284, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3466, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/4n/qh91m_wd5fj7fm56fsm72yth0000gp/T/ipykernel_33093/629159242.py\", line 13, in <module>\n",
      "    from sklearn.datasets import make_regression  # 创建线性回归模型数据集\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/__init__.py\", line 73, in <module>\n",
      "    from .base import clone  # noqa: E402\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 19, in <module>\n",
      "    from .utils._estimator_html_repr import _HTMLDocumentationLinkMixin, estimator_html_repr\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py\", line 15, in <module>\n",
      "    from ._chunking import gen_batches, gen_even_slices\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_chunking.py\", line 11, in <module>\n",
      "    from ._param_validation import Interval, validate_params\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 17, in <module>\n",
      "    from .validation import _is_arraylike_not_scalar\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 21, in <module>\n",
      "    from ..utils._array_api import _asarray_with_order, _is_numpy_namespace, get_namespace\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_array_api.py\", line 17, in <module>\n",
      "    from .fixes import parse_version\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 20, in <module>\n",
      "    import pandas as pd\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/pandas/__init__.py\", line 49, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/pandas/core/api.py\", line 9, in <module>\n",
      "    from pandas.core.dtypes.dtypes import (\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/pandas/core/dtypes/dtypes.py\", line 24, in <module>\n",
      "    from pandas._libs import (\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/pyarrow/__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;31mAttributeError\u001B[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w和b--> [Parameter containing:\n",
      "tensor([[0.4836]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.5874], requires_grad=True)]\n",
      "w--> Parameter containing:\n",
      "tensor([[0.4836]], requires_grad=True)\n",
      "b--> Parameter containing:\n",
      "tensor([-0.5874], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[42.9084]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([13.9074], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 25439 (\\N{CJK UNIFIED IDEOGRAPH-635F}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 22833 (\\N{CJK UNIFIED IDEOGRAPH-5931}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 21464 (\\N{CJK UNIFIED IDEOGRAPH-53D8}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 21270 (\\N{CJK UNIFIED IDEOGRAPH-5316}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 26354 (\\N{CJK UNIFIED IDEOGRAPH-66F2}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 32447 (\\N{CJK UNIFIED IDEOGRAPH-7EBF}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[121], line 108\u001B[0m\n\u001B[1;32m    105\u001B[0m     plt\u001B[38;5;241m.\u001B[39mlegend()\n\u001B[1;32m    106\u001B[0m     plt\u001B[38;5;241m.\u001B[39mshow()\n\u001B[0;32m--> 108\u001B[0m \u001B[43mconstruct_liner_regression_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[121], line 98\u001B[0m, in \u001B[0;36mconstruct_liner_regression_model\u001B[0;34m()\u001B[0m\n\u001B[1;32m     95\u001B[0m plt\u001B[38;5;241m.\u001B[39mshow()\n\u001B[1;32m     97\u001B[0m \u001B[38;5;66;03m# 绘制拟合直线\u001B[39;00m\n\u001B[0;32m---> 98\u001B[0m \u001B[43mplt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscatter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     99\u001B[0m x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mlinspace(x\u001B[38;5;241m.\u001B[39mmin(), x\u001B[38;5;241m.\u001B[39mmax(), \u001B[38;5;241m1000\u001B[39m)\n\u001B[1;32m    100\u001B[0m y1 \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor([v \u001B[38;5;241m*\u001B[39m model\u001B[38;5;241m.\u001B[39mweight \u001B[38;5;241m+\u001B[39m model\u001B[38;5;241m.\u001B[39mbias \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m x])\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/matplotlib/pyplot.py:3903\u001B[0m, in \u001B[0;36mscatter\u001B[0;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, data, **kwargs)\u001B[0m\n\u001B[1;32m   3884\u001B[0m \u001B[38;5;129m@_copy_docstring_and_deprecators\u001B[39m(Axes\u001B[38;5;241m.\u001B[39mscatter)\n\u001B[1;32m   3885\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mscatter\u001B[39m(\n\u001B[1;32m   3886\u001B[0m     x: \u001B[38;5;28mfloat\u001B[39m \u001B[38;5;241m|\u001B[39m ArrayLike,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   3901\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   3902\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m PathCollection:\n\u001B[0;32m-> 3903\u001B[0m     __ret \u001B[38;5;241m=\u001B[39m \u001B[43mgca\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscatter\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   3904\u001B[0m \u001B[43m        \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3905\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3906\u001B[0m \u001B[43m        \u001B[49m\u001B[43ms\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43ms\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3907\u001B[0m \u001B[43m        \u001B[49m\u001B[43mc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3908\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmarker\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmarker\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3909\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcmap\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcmap\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3910\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnorm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnorm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3911\u001B[0m \u001B[43m        \u001B[49m\u001B[43mvmin\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvmin\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3912\u001B[0m \u001B[43m        \u001B[49m\u001B[43mvmax\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvmax\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3913\u001B[0m \u001B[43m        \u001B[49m\u001B[43malpha\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43malpha\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3914\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlinewidths\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlinewidths\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3915\u001B[0m \u001B[43m        \u001B[49m\u001B[43medgecolors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43medgecolors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3916\u001B[0m \u001B[43m        \u001B[49m\u001B[43mplotnonfinite\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mplotnonfinite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3917\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdata\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m}\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3918\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3919\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3920\u001B[0m     sci(__ret)\n\u001B[1;32m   3921\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m __ret\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/matplotlib/__init__.py:1473\u001B[0m, in \u001B[0;36m_preprocess_data.<locals>.inner\u001B[0;34m(ax, data, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1470\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m   1471\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minner\u001B[39m(ax, \u001B[38;5;241m*\u001B[39margs, data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m   1472\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1473\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1474\u001B[0m \u001B[43m            \u001B[49m\u001B[43max\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1475\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mmap\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msanitize_sequence\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1476\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m{\u001B[49m\u001B[43mk\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43msanitize_sequence\u001B[49m\u001B[43m(\u001B[49m\u001B[43mv\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitems\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1478\u001B[0m     bound \u001B[38;5;241m=\u001B[39m new_sig\u001B[38;5;241m.\u001B[39mbind(ax, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1479\u001B[0m     auto_label \u001B[38;5;241m=\u001B[39m (bound\u001B[38;5;241m.\u001B[39marguments\u001B[38;5;241m.\u001B[39mget(label_namer)\n\u001B[1;32m   1480\u001B[0m                   \u001B[38;5;129;01mor\u001B[39;00m bound\u001B[38;5;241m.\u001B[39mkwargs\u001B[38;5;241m.\u001B[39mget(label_namer))\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/matplotlib/axes/_axes.py:4781\u001B[0m, in \u001B[0;36mAxes.scatter\u001B[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, **kwargs)\u001B[0m\n\u001B[1;32m   4779\u001B[0m edgecolors \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124medgecolor\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m   4780\u001B[0m \u001B[38;5;66;03m# Process **kwargs to handle aliases, conflicts with explicit kwargs:\u001B[39;00m\n\u001B[0;32m-> 4781\u001B[0m x, y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_process_unit_info\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mx\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43my\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4782\u001B[0m \u001B[38;5;66;03m# np.ma.ravel yields an ndarray, not a masked array,\u001B[39;00m\n\u001B[1;32m   4783\u001B[0m \u001B[38;5;66;03m# unless its argument is a masked array.\u001B[39;00m\n\u001B[1;32m   4784\u001B[0m x \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mma\u001B[38;5;241m.\u001B[39mravel(x)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/matplotlib/axes/_base.py:2585\u001B[0m, in \u001B[0;36m_AxesBase._process_unit_info\u001B[0;34m(self, datasets, kwargs, convert)\u001B[0m\n\u001B[1;32m   2583\u001B[0m     \u001B[38;5;66;03m# Update from data if axis is already set but no unit is set yet.\u001B[39;00m\n\u001B[1;32m   2584\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m axis \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m axis\u001B[38;5;241m.\u001B[39mhave_units():\n\u001B[0;32m-> 2585\u001B[0m         \u001B[43maxis\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate_units\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2586\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m axis_name, axis \u001B[38;5;129;01min\u001B[39;00m axis_map\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m   2587\u001B[0m     \u001B[38;5;66;03m# Return if no axis is set.\u001B[39;00m\n\u001B[1;32m   2588\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m axis \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/matplotlib/axis.py:1750\u001B[0m, in \u001B[0;36mAxis.update_units\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mupdate_units\u001B[39m(\u001B[38;5;28mself\u001B[39m, data):\n\u001B[1;32m   1745\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1746\u001B[0m \u001B[38;5;124;03m    Introspect *data* for units converter and update the\u001B[39;00m\n\u001B[1;32m   1747\u001B[0m \u001B[38;5;124;03m    ``axis.converter`` instance if necessary. Return *True*\u001B[39;00m\n\u001B[1;32m   1748\u001B[0m \u001B[38;5;124;03m    if *data* is registered for unit conversion.\u001B[39;00m\n\u001B[1;32m   1749\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1750\u001B[0m     converter \u001B[38;5;241m=\u001B[39m \u001B[43mmunits\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mregistry\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_converter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1751\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m converter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1752\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/matplotlib/units.py:167\u001B[0m, in \u001B[0;36mRegistry.get_converter\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    165\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Get the converter interface instance for *x*, or None.\"\"\"\u001B[39;00m\n\u001B[1;32m    166\u001B[0m \u001B[38;5;66;03m# Unpack in case of e.g. Pandas or xarray object\u001B[39;00m\n\u001B[0;32m--> 167\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[43mcbook\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_unpack_to_numpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    169\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x, np\u001B[38;5;241m.\u001B[39mndarray):\n\u001B[1;32m    170\u001B[0m     \u001B[38;5;66;03m# In case x in a masked array, access the underlying data (only its\u001B[39;00m\n\u001B[1;32m    171\u001B[0m     \u001B[38;5;66;03m# type matters).  If x is a regular ndarray, getdata() just returns\u001B[39;00m\n\u001B[1;32m    172\u001B[0m     \u001B[38;5;66;03m# the array itself.\u001B[39;00m\n\u001B[1;32m    173\u001B[0m     x \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mma\u001B[38;5;241m.\u001B[39mgetdata(x)\u001B[38;5;241m.\u001B[39mravel()\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/matplotlib/cbook.py:2395\u001B[0m, in \u001B[0;36m_unpack_to_numpy\u001B[0;34m(x)\u001B[0m\n\u001B[1;32m   2393\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m xtmp\n\u001B[1;32m   2394\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _is_torch_array(x) \u001B[38;5;129;01mor\u001B[39;00m _is_jax_array(x):\n\u001B[0;32m-> 2395\u001B[0m     xtmp \u001B[38;5;241m=\u001B[39m \u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__array__\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2397\u001B[0m     \u001B[38;5;66;03m# In case __array__() method does not return a numpy array in future\u001B[39;00m\n\u001B[1;32m   2398\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(xtmp, np\u001B[38;5;241m.\u001B[39mndarray):\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/_tensor.py:1062\u001B[0m, in \u001B[0;36mTensor.__array__\u001B[0;34m(self, dtype)\u001B[0m\n\u001B[1;32m   1060\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(Tensor\u001B[38;5;241m.\u001B[39m__array__, (\u001B[38;5;28mself\u001B[39m,), \u001B[38;5;28mself\u001B[39m, dtype\u001B[38;5;241m=\u001B[39mdtype)\n\u001B[1;32m   1061\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1062\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnumpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1063\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1064\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnumpy()\u001B[38;5;241m.\u001B[39mastype(dtype, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Numpy is not available"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 121
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b7855a5b43cabc07"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
