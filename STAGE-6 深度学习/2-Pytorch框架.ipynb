{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# PyTorch框架学习目标：\n",
    "- 知道什么是PyTorch框架，相比于TensorFlow有哪些异同点\n",
    "- PyTorch框架有哪些特点\n",
    "- PyTorch发展史有哪些重要节点\n",
    "- 学习张量，知道其基本创建方式、特点，以及基本运算、索引、转换方法\n",
    "- 学习自动微分和梯度基本计算\n",
    "- 使用PyTorch构建基本线性模型\n",
    "\n",
    "\n",
    "# 1、什么是pyTorch框架？\n",
    "概念：PyTorch是基于Python的科学计算包\n",
    "```bash\n",
    "pip install torch -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "```\n",
    "\n",
    "# 2、PyTorch有哪些特点？\n",
    "- 类似于NumPy的张量计算：PyTorch中基本结构是张量（Tensor），它与NumPy中数组类似，但是PyTorch张量具有CPU加速的能力（通过CUDA），这使得深度学习模型能够高效的在GPU中运行\n",
    "- 自动微分系统：\n",
    "    - PyTorch提供了强大的自动微分功能（AutoGrad模块），能够自动计算模型中每个参数梯度，\n",
    "    - 自动唯粉使得梯度计算过程变得简洁高效，并且支持复杂的模型和动态计算图\n",
    "- 深度学习库：\n",
    "    - PyTorch提供了一个名为torch.nn的子模块，用于构建神经网络，它包括了大量的预构建曾层（如全联接层、卷积层、循环神经网络层），损失函数（如交叉熵、均方误差），以及优化算法（SGD、Adam等）\n",
    "    - torch.nn.module是PyTorch中构建神经网络的基础类，用户可以通过继承该类来定义自己的神经网络架构\n",
    "- 动态图计算：\n",
    "    - PyTorch使用动态计算机制，允许在运行时构建和修改模型结构，具有更高的灵活性，适合于研究人员进行实验和模型调试\n",
    "- GPU加速（CUDA支持：CUDA是NVIDIA开发的一种并行计算平台和编程模型，允许利用GPU加速计算密集型任务）：\n",
    "    - PyTorch提供对GPU的良好支持，可以轻松的将模型和数据从CPU转移到GPU或从一个GPU转移到GPU上，PyTorch回自动优化计算过程\n",
    "- 跨平台支持：\n",
    "    - PyTorch支持在多种硬件平台（如：CPU、GPU、TPU）上运行，并且支持不同的操作系统（Linux、Windows、MacOS）以及分布式计算环境（多GPU、分布式训练）\n",
    "\n",
    "# 3、PyTorch发展历史\n",
    "\n",
    "![PyTorch发展史](./file/PyTorch发展史.png)\n",
    "\n",
    "- Torch最早的是Torch框架，由Ronan·Collobert和Clement·Farabet等人开发，是一个科学计算框架，提供了多维张量操作可算计算工具\n",
    "- Torch7是Torch的一个后续版本，引入了Lua编程语言，随着pytorch的普及，Torch便不再维护，Torch7也就成为了Torch的最后一个版本。\n",
    "- Pytorch 0.1.0：是Facebook人工智能研究院（FAIR）于2016年发布了PyTorch的第一个版本，标志着PyTorch的正式诞生。\n",
    "- Pytorch 0.2.0：该版本首次引入了动态图机制，使得用户能够在构建神经网络时更加灵活。作为Pytorch后期制胜tensorflow的关键机制，该版本象征着Pytorch进入了一个新的阶段。\n",
    "- Pytorch 1.0.0：2018年发布了Pytorch的首个稳定版本，引入了Eager模式简化了模型的构建和训练过程。\n",
    "- Pytorch 2.0：Pytorch2.0引入了torch.compile，可以支持对训练过程的加速，同时引入了TorchDynamo，主要替换torch.jit.trace和torch.jit.script。另外在这个版本中编译器性能大幅提升，分布式运行方面也做了一定的优化。\n",
    "\n",
    "# 什么是张量？\n",
    "定义：张量（Tensor）是一种数学对象，也是在物理学和工程学中广泛使用的概念。它是一种多维数组，可以表示为一个n维数组，其中n是张量的阶数。张量在不同的领域有不同的应用和解释。\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "de4078022501cedb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T06:31:44.427407Z",
     "start_time": "2025-03-23T06:31:39.966584Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install torch -i https://pypi.tuna.tsinghua.edu.cn/simple",
   "id": "edacb791ab2b8c9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\r\n",
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.9/site-packages (2.2.2)\r\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.9/site-packages (from torch) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/lib/python3.9/site-packages (from torch) (4.12.2)\r\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.9/site-packages (from torch) (1.13.3)\r\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.9/site-packages (from torch) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.9/site-packages (from torch) (3.1.5)\r\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.9/site-packages (from torch) (2024.12.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.9/site-packages (from jinja2->torch) (3.0.2)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\r\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T07:39:14.793351Z",
     "start_time": "2025-04-14T07:39:09.299683Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch  # 需要安装torch模块\n",
    "import numpy as np\n",
    "\n",
    "# torch.tensor(data=, dtype=) 根据指定数据创建张量\n",
    "# 1.创建张量标量（data=, dtype=）\n",
    "data = torch.tensor(10)\n",
    "print(data)\n",
    "\n",
    "# 2.numpy数组，犹豫data为float64，张量元素类型也是float64\n",
    "data = np.random.randn(2, 3)\n",
    "data = torch.tensor(data)\n",
    "print(data)\n",
    "\n",
    "# 3.列表、浮点数默认都是flaot32\n",
    "data = [[10, 20, 30], [40, 50, 60]]\n",
    "data = torch.tensor(data)\n",
    "print(data)"
   ],
   "id": "c9ccaf69f6596041",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10)\n",
      "tensor([[ 0.5980, -0.0095, -0.5941],\n",
      "        [-1.0971, -0.5787, -0.6149]], dtype=torch.float64)\n",
      "tensor([[10, 20, 30],\n",
      "        [40, 50, 60]])\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T06:32:11.100080Z",
     "start_time": "2025-03-23T06:32:11.089073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# torch.Tensor(size=) 根据形状来创建张量\n",
    "# 1、创建一个2行3列的张量，默认dtype为float32\n",
    "data = torch.Tensor(2, 3)\n",
    "print(data)\n",
    "\n",
    "# 2、如果传递列表代表，则包含创建包含指定元素的张量\n",
    "data = torch.Tensor([10])\n",
    "print(data)\n",
    "\n",
    "data = torch.Tensor([10, 20])\n",
    "print(data)"
   ],
   "id": "94ee1badfcd1d5a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([10.])\n",
      "tensor([10., 20.])\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T06:32:23.434940Z",
     "start_time": "2025-03-23T06:32:23.426063Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# torch.IntTensor()/torch.FloatTensor() 创建指定类型的张量\n",
    "\n",
    "# 1、创建2行3列，dtype为int32的张量\n",
    "data = torch.IntTensor(2, 3)\n",
    "print(f'2行3列，dtype为int32的张量：{data}')\n",
    "\n",
    "# 2、如果传入的元素类型不正确，则回进行类型转换\n",
    "#data = torch.IntTensor([2.5, 3.3])\n",
    "#print(f'类型转换张量：{data}')\n",
    "\n",
    "# 3、其他类型\n",
    "data = torch.ShortTensor()  # int16\n",
    "print(f'int16类型张量：{data}')\n",
    "\n",
    "data = torch.LongTensor()  # int64\n",
    "print(f'int64类型张量：{data}')\n",
    "\n",
    "data = torch.FloatTensor()  # float32\n",
    "print(f'float32类型张量：{data}')\n",
    "\n",
    "data = torch.DoubleTensor()  # float64\n",
    "print(f'float64类型张量：{data}')"
   ],
   "id": "ecd7bc3be72c99fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2行3列，dtype为int32的张量：tensor([[0, 0, 0],\n",
      "        [0, 0, 0]], dtype=torch.int32)\n",
      "int16类型张量：tensor([], dtype=torch.int16)\n",
      "int64类型张量：tensor([], dtype=torch.int64)\n",
      "float32类型张量：tensor([])\n",
      "float64类型张量：tensor([], dtype=torch.float64)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T06:32:29.043125Z",
     "start_time": "2025-03-23T06:32:29.026188Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 线性和随机张量\n",
    "\n",
    "# torch.arange(start=, end=, step=)：固定步长线性张量\n",
    "# 1、在指定区间按照补偿生成元素[start, end, steps]左闭右开\n",
    "data = torch.arange(0, 10, 2)\n",
    "print(data)\n",
    "\n",
    "# 2、在指定区间啊找元素个数生成[start, end, steps]左闭右闭\n",
    "# step = (end - start) /( step - 1)\n",
    "# value_i = start + step * i\n",
    "data = torch.linspace(0, 9, 10)\n",
    "print(data)"
   ],
   "id": "d45831a7fe5bb756",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 2, 4, 6, 8])\n",
      "tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T06:32:36.546413Z",
     "start_time": "2025-03-23T06:32:36.528380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# torch.randn/rand(size=) 创建随机浮点数类型张量\n",
    "# torch.randint(low=, high=, size=) 创建随机整数类型张量 左闭右开\n",
    "# torch.initial_seed() 和 torch.manual_seed(seed=) 随机种子设置\n",
    "\n",
    "# 1、创建随机张量\n",
    "data = torch.randn(2, 3)\n",
    "print(data)\n",
    "print(f'查看随机数种子：{torch.initial_seed()}')\n",
    "\n",
    "# 2、随机数种子设置\n",
    "torch.manual_seed(100)\n",
    "data = torch.randn(2, 3)\n",
    "print(data)\n",
    "print(f'随机数种子：{torch.initial_seed()}')\n",
    "\n"
   ],
   "id": "e1ae5bef275d6fc8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4337, -2.1093, -1.0010],\n",
      "        [ 0.4639, -1.2823, -1.4343]])\n",
      "查看随机数种子：4910714865061174651\n",
      "tensor([[ 0.3607, -0.2859, -0.3938],\n",
      "        [ 0.2429, -1.3833, -2.3134]])\n",
      "随机数种子：100\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T06:32:43.748117Z",
     "start_time": "2025-03-23T06:32:43.725278Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 指定值张量\n",
    "\n",
    "# torch.zeros(size=) 和 torch.zeros_like(input=) 创建全0张量\n",
    "# 1、创建指定形状全0张量\n",
    "data = torch.zeros(2, 3)\n",
    "print(f'创建指定形状全零张量:{data}')\n",
    "\n",
    "# 2、根据张量形状创建全0张量\n",
    "data = torch.zeros_like(data)\n",
    "print(f'根据传入张量形状创建全零张量：{data}')\n",
    "\n",
    "# torch.ones(size=) 和 torch.ones_like(input=) 创建全1张量\n",
    "# 3、创建指定形状全1张量\n",
    "data = torch.ones(2, 3)\n",
    "print(f'指定形状全一张量：{data}')\n",
    "\n",
    "data = torch.ones_like(data)\n",
    "print(f'根据输入张量形状创建全一张量：{data}')\n",
    "\n",
    "# torch.full(size=, fill_value=) 和 torch.full_like(input=, fill_value=) 创建全为指定值张量\n",
    "# 4、 创建指定形状指定值的张量\n",
    "data = torch.full([2, 3], 10)\n",
    "print(f'全为指定值张量:{data}')\n",
    "\n",
    "# 5、根据张量形状创建指定值的张量\n",
    "data = torch.full_like(data, 20)\n",
    "print(f'根据张量形状创建指定值的张量:{data}')\n"
   ],
   "id": "f8503d70defd155e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "创建指定形状全零张量:tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "根据传入张量形状创建全零张量：tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "指定形状全一张量：tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "根据输入张量形状创建全一张量：tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "全为指定值张量:tensor([[10, 10, 10],\n",
      "        [10, 10, 10]])\n",
      "根据张量形状创建指定值的张量:tensor([[20, 20, 20],\n",
      "        [20, 20, 20]])\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T06:32:50.693795Z",
     "start_time": "2025-03-23T06:32:50.677115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 指定元素类型张量\n",
    "# data.type(dtype=)\n",
    "data = torch.full([2, 3], 10)\n",
    "print(data.dtype)\n",
    "\n",
    "# 将 data 元素类型转换为 float64 类型\n",
    "data = data.type(torch.DoubleTensor)\n",
    "print(data.dtype)\n",
    "\n",
    "# 转换为其他类型\n",
    "data = data.type(torch.ShortTensor)\n",
    "data = data.type(torch.IntTensor)\n",
    "data = data.type(torch.LongTensor)\n",
    "data = data.type(torch.FloatTensor)\n",
    "data = data.type(dtype=torch.float16)\n",
    "\n",
    "# data.half/float/double/short/int/long()\n",
    "data = torch.full([2, 3], 10)\n",
    "print(data.dtype)\n",
    "# 将 data 元素类型转换为 float64 类型\n",
    "data = data.double()\n",
    "print(data.dtype)\n",
    "# 转换为其他类型\n",
    "# data = data.short()\n",
    "# data = data.int()\n",
    "# data = data.long()\n",
    "# data = data.float()\n"
   ],
   "id": "cbc360241f2b8150",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "torch.float64\n",
      "torch.int64\n",
      "torch.float64\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T06:32:58.865841Z",
     "start_time": "2025-03-23T06:32:57.489355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 张量类型转换\n",
    "\n",
    "# 使用 t.numpy() 函数可以将张量转换为 ndarray 数组，但是共享内存，可以使用copy函数避免共享。\n",
    "\n",
    "# 1、张量转换为NumPy数组\n",
    "data_tensor = torch.tensor([2, 3, 4])\n",
    "# 使用张量对象中的 numpy 函数进行转换\n",
    "data_numpy = data_tensor.numpy()\n",
    "print(type(data_tensor))\n",
    "print(type(data_numpy))\n",
    "# 注意: data_tensor 和 data_numpy 共享内存\n",
    "# 修改其中的一个，另外一个也会发生改变\n",
    "# data_tensor[0] = 100\n",
    "data_numpy[0] = 100\n",
    "print(data_tensor)\n",
    "print(data_numpy)\n",
    "\n",
    "# 2. 对象拷贝避免共享内存\n",
    "data_tensor = torch.tensor([2, 3, 4])\n",
    "# 使用张量对象中的 numpy 函数进行转换，通过copy方法拷贝对象\n",
    "data_numpy = data_tensor.numpy().copy()\n",
    "print(type(data_tensor))\n",
    "print(type(data_numpy))\n",
    "# 注意: data_tensor 和 data_numpy 此时不共享内存\n",
    "# 修改其中的一个，另外一个不会发生改变\n",
    "# data_tensor[0] = 100\n",
    "data_numpy[0] = 100\n",
    "print(data_tensor)\n",
    "print(data_numpy)\n"
   ],
   "id": "f4b56236b83f2901",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 8\u001B[0m\n\u001B[1;32m      6\u001B[0m data_tensor \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor([\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m4\u001B[39m])\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# 使用张量对象中的 numpy 函数进行转换\u001B[39;00m\n\u001B[0;32m----> 8\u001B[0m data_numpy \u001B[38;5;241m=\u001B[39m \u001B[43mdata_tensor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnumpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28mtype\u001B[39m(data_tensor))\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28mtype\u001B[39m(data_numpy))\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Numpy is not available"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T06:33:04.983854Z",
     "start_time": "2025-03-23T06:33:04.977513Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 当张量只包含一个元素时, 可以通过 item() 函数提取出该值\n",
    "data = torch.tensor([30, ])\n",
    "print(data.item())\n",
    "data = torch.tensor(30)\n",
    "print(data.item())"
   ],
   "id": "ce5266e39214d8c4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "30\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T06:33:13.276277Z",
     "start_time": "2025-03-23T06:33:13.248904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = torch.randint(0, 10, [2, 3])\n",
    "print(f'初始化张量:{data}')\n",
    "\n",
    "# 1. 不修改原数据\n",
    "new_data = data.add(10)  # 等价 new_data = data + 10\n",
    "print(f'张量+10:{data}')\n",
    "\n",
    "# 2. 直接修改原数据 注意: 带下划线的函数为修改原数据本身\n",
    "data.add_(10)\n",
    "print(f'张量再+10:{data}')\n",
    "\n",
    "# 3. 其他函数\n",
    "print(f'张量减100:{data.sub(100)}')\n",
    "print(f'张量乘100:{data.mul(100)}')\n",
    "print(f'张量除100:{data.div(100)}')\n",
    "print(f'张量除100:{data.neg()}')"
   ],
   "id": "6cb7bd9ad995b8f5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初始化张量:tensor([[8, 8, 4],\n",
      "        [4, 1, 0]])\n",
      "张量+10:tensor([[8, 8, 4],\n",
      "        [4, 1, 0]])\n",
      "张量再+10:tensor([[18, 18, 14],\n",
      "        [14, 11, 10]])\n",
      "张量减100:tensor([[-82, -82, -86],\n",
      "        [-86, -89, -90]])\n",
      "张量乘100:tensor([[1800, 1800, 1400],\n",
      "        [1400, 1100, 1000]])\n",
      "张量除100:tensor([[0.1800, 0.1800, 0.1400],\n",
      "        [0.1400, 0.1100, 0.1000]])\n",
      "张量除100:tensor([[-18, -18, -14],\n",
      "        [-14, -11, -10]])\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T06:33:20.690413Z",
     "start_time": "2025-03-23T06:33:20.681187Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 点乘运算\n",
    "data1 = torch.tensor([[1, 2], [3, 4]])\n",
    "data2 = torch.tensor([[5, 6], [7, 8]])\n",
    "# 第一种方式\n",
    "data = torch.mul(data1, data2)\n",
    "print(data)\n",
    "# 第二种方式\n",
    "data = data1 * data2\n",
    "print(data)"
   ],
   "id": "f25ffb8a3c84c5d5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5, 12],\n",
      "        [21, 32]])\n",
      "tensor([[ 5, 12],\n",
      "        [21, 32]])\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T06:33:26.227026Z",
     "start_time": "2025-03-23T06:33:26.203973Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 矩阵乘法运算\n",
    "# 点积运算\n",
    "data1 = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
    "data2 = torch.tensor([[5, 6], [7, 8]])\n",
    "# 方式一:\n",
    "data3 = data1 @ data2\n",
    "print(\"data3-->\", data3)\n",
    "# 方式二:\n",
    "data4 = torch.matmul(data1, data2)\n",
    "print(\"data4-->\", data4)"
   ],
   "id": "83c39d09dca574eb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data3--> tensor([[19, 22],\n",
      "        [43, 50],\n",
      "        [67, 78]])\n",
      "data4--> tensor([[19, 22],\n",
      "        [43, 50],\n",
      "        [67, 78]])\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T10:43:35.105099Z",
     "start_time": "2025-03-23T10:43:35.094607Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "张量运算函数\n",
    "tensor.mean(dim=):平均值\n",
    "tensor.sum(dim=):求和\n",
    "tensor.min/max(dim=):最小值/最大值\n",
    "tensor.pow(exponent=):幂次方 $$x^n$$\n",
    "tensor.sqrt(dim=):平方根\n",
    "tensor.exp():指数 $$e^x$$\n",
    "tensor.log(dim=):对数 以e为底\n",
    "dim=0按列计算,dim=1按行计算\n",
    "'''\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "def fundamental_operation():\n",
    "    data = torch.randint(0, 10, [2, 3], dtype=torch.float64)\n",
    "    print(data)\n",
    "    # 1. 计算均值\n",
    "    # 注意: tensor 必须为 Float 或者 Double 类型\n",
    "    print(data.mean())\n",
    "    print(data.mean(dim=0))  # 按列计算均值\n",
    "    print(data.mean(dim=1))  # 按行计算均值\n",
    "    # 2. 计算总和\n",
    "    print(data.sum())\n",
    "    print(data.sum(dim=0))\n",
    "    print(data.sum(dim=1))\n",
    "    # 3. 计算平方\n",
    "    print(torch.pow(data, 2))\n",
    "    # 4. 计算平方根\n",
    "    print(data.sqrt())\n",
    "    # 5. 指数计算, e^n 次方\n",
    "    print(data.exp())\n",
    "    # 6. 对数计算\n",
    "    print(data.log())  # 以 e 为底\n",
    "    print(data.log2())\n",
    "    print(data.log10())\n",
    "\n",
    "\n",
    "fundamental_operation()"
   ],
   "id": "8050034c006a71df",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7., 4., 8.],\n",
      "        [4., 4., 7.]], dtype=torch.float64)\n",
      "tensor(5.6667, dtype=torch.float64)\n",
      "tensor([5.5000, 4.0000, 7.5000], dtype=torch.float64)\n",
      "tensor([6.3333, 5.0000], dtype=torch.float64)\n",
      "tensor(34., dtype=torch.float64)\n",
      "tensor([11.,  8., 15.], dtype=torch.float64)\n",
      "tensor([19., 15.], dtype=torch.float64)\n",
      "tensor([[49., 16., 64.],\n",
      "        [16., 16., 49.]], dtype=torch.float64)\n",
      "tensor([[2.6458, 2.0000, 2.8284],\n",
      "        [2.0000, 2.0000, 2.6458]], dtype=torch.float64)\n",
      "tensor([[1096.6332,   54.5982, 2980.9580],\n",
      "        [  54.5982,   54.5982, 1096.6332]], dtype=torch.float64)\n",
      "tensor([[1.9459, 1.3863, 2.0794],\n",
      "        [1.3863, 1.3863, 1.9459]], dtype=torch.float64)\n",
      "tensor([[2.8074, 2.0000, 3.0000],\n",
      "        [2.0000, 2.0000, 2.8074]], dtype=torch.float64)\n",
      "tensor([[0.8451, 0.6021, 0.9031],\n",
      "        [0.6021, 0.6021, 0.8451]], dtype=torch.float64)\n"
     ]
    }
   ],
   "execution_count": 103
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T10:42:43.765058Z",
     "start_time": "2025-03-23T10:42:43.743601Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "'''\n",
    "张量索引操作\n",
    "我们在操作张量时，经常需要去获取某些元素就进行处理或者修改操作，在这里我们需要了解在torch中的索引操作。\n",
    "'''\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "def tensor_index():\n",
    "    # 随机生成数据 data[开始行(可省略默认：0): 行步长(可省略默认：1): 结束行(可省略默认：shape), 开始列(可省略默认：0): 列步长(可省略默认：1): 结束列(可省略默认：shape)]\n",
    "    data = torch.randint(0, 10, [4, 5])\n",
    "    print(f'随机生成张量：{data}')\n",
    "\n",
    "    # 1、简单行列索引\n",
    "    print(f'行索引：{data[0]}')\n",
    "    print(f'列索引：{data[:, 0]}')\n",
    "\n",
    "    # 2、列表索引\n",
    "    print(f'返回(0, 1)和(1, 2)对应位置数据：{data[[0, 1], [1, 2]]}')\n",
    "    print(f'返回0、1行的1、2列共4个元素：{data[:2, 1:3]}')\n",
    "    print(f'返回0、1行的1、2列共4个元素：{data[[[0], [1]], [1, 2]]}')\n",
    "\n",
    "    # 3、范围索引\n",
    "    print(f'前三行前两列数据：{data[:3, :2]}')\n",
    "    print(f'第二行到最后的前两列数据：{data[2:, :2]}')\n",
    "\n",
    "    # 4、布尔索引\n",
    "    print(f'第三列大于5的行数据:{data[:, :3][data[:, :3] > 5]}')\n",
    "    print(f'第二行大于5的数据：{data[:, [1]][data[:, [1]] > 5]}')\n",
    "    print(f'第二行大于5的数据：{data[:, 1:2][data[:, 1:2] > 5]}')\n",
    "\n",
    "    # 5、多维索引\n",
    "    data = torch.randint(0, 10, [3, 4, 5])\n",
    "    print(f'随机生成三维数据：{data}')\n",
    "    print(f'获取0轴上第一个数据：{data[0, :, :]}')\n",
    "    print(f'获取0轴上第一个数据：{data[[0]]}')\n",
    "\n",
    "    print(f'获取0轴上第一个数据：{data[[1]]}')\n",
    "    print(f'获取1轴上第一个数据：{data[:, 0, :]}')\n",
    "    print(f'获取2轴上第一个数据：{data[:, :, 0]}')\n",
    "\n",
    "\n",
    "tensor_index()"
   ],
   "id": "5f712379eda08afe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "随机生成张量：tensor([[6, 6, 4, 5, 2],\n",
      "        [2, 4, 0, 9, 6],\n",
      "        [5, 8, 2, 8, 2],\n",
      "        [3, 1, 5, 9, 1]])\n",
      "行索引：tensor([6, 6, 4, 5, 2])\n",
      "列索引：tensor([6, 2, 5, 3])\n",
      "返回(0, 1)和(1, 2)对应位置数据：tensor([6, 0])\n",
      "返回0、1行的1、2列共4个元素：tensor([[6, 4],\n",
      "        [4, 0]])\n",
      "返回0、1行的1、2列共4个元素：tensor([[6, 4],\n",
      "        [4, 0]])\n",
      "前三行前两列数据：tensor([[6, 6],\n",
      "        [2, 4],\n",
      "        [5, 8]])\n",
      "第二行到最后的前两列数据：tensor([[5, 8],\n",
      "        [3, 1]])\n",
      "第三列大于5的行数据:tensor([6, 6, 8])\n",
      "第二行大于5的数据：tensor([6, 8])\n",
      "第二行大于5的数据：tensor([6, 8])\n",
      "随机生成三维数据：tensor([[[7, 0, 9, 8, 0],\n",
      "         [7, 9, 7, 9, 7],\n",
      "         [2, 0, 4, 0, 7],\n",
      "         [0, 9, 6, 0, 0]],\n",
      "\n",
      "        [[1, 1, 2, 5, 3],\n",
      "         [7, 1, 3, 1, 5],\n",
      "         [9, 2, 2, 1, 5],\n",
      "         [3, 8, 7, 4, 3]],\n",
      "\n",
      "        [[0, 9, 4, 7, 9],\n",
      "         [6, 4, 6, 3, 2],\n",
      "         [1, 4, 1, 4, 4],\n",
      "         [3, 7, 4, 8, 2]]])\n",
      "获取0轴上第一个数据：tensor([[7, 0, 9, 8, 0],\n",
      "        [7, 9, 7, 9, 7],\n",
      "        [2, 0, 4, 0, 7],\n",
      "        [0, 9, 6, 0, 0]])\n",
      "获取0轴上第一个数据：tensor([[[7, 0, 9, 8, 0],\n",
      "         [7, 9, 7, 9, 7],\n",
      "         [2, 0, 4, 0, 7],\n",
      "         [0, 9, 6, 0, 0]]])\n",
      "获取0轴上第一个数据：tensor([[[1, 1, 2, 5, 3],\n",
      "         [7, 1, 3, 1, 5],\n",
      "         [9, 2, 2, 1, 5],\n",
      "         [3, 8, 7, 4, 3]]])\n",
      "获取1轴上第一个数据：tensor([[7, 0, 9, 8, 0],\n",
      "        [1, 1, 2, 5, 3],\n",
      "        [0, 9, 4, 7, 9]])\n",
      "获取2轴上第一个数据：tensor([[7, 7, 2, 0],\n",
      "        [1, 7, 9, 3],\n",
      "        [0, 6, 1, 3]])\n"
     ]
    }
   ],
   "execution_count": 100
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T10:44:24.217767Z",
     "start_time": "2025-03-23T10:44:24.176012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def reshape():\n",
    "    # 张量形状操作\n",
    "    data = torch.tensor([[10, 20, 30], [40, 50, 60]])\n",
    "    # 1. 使用 shape 属性或者 size 方法都可以获得张量的形状\n",
    "    print(data.shape, data.shape[0], data.shape[1])\n",
    "    print(data.size(), data.size(0), data.size(1))\n",
    "\n",
    "    # 2. 使用 reshape 函数修改张量形状\n",
    "    new_data = data.reshape(1, 6)\n",
    "    print(new_data.shape)\n",
    "\n",
    "    data = torch.randint(0, 10, [3, 4, 5, 6, 7])\n",
    "    print(f'张量：{data}')\n",
    "    print(f'张量形状：{data.shape}')\n",
    "    print(f'张量形状：{data.shape[0]}')\n",
    "    print(f'张量形状：{data.shape[1]}')\n",
    "    print(f'张量形状：{data.shape[2]}')\n",
    "    print(f'张量形状：{data.shape[3]}')\n",
    "\n",
    "    print(f'张量形状：{data.size(0)}')\n",
    "    print(f'张量形状：{data.size(1)}')\n",
    "    print(f'张量形状：{data.size(2)}')\n",
    "    print(f'张量形状：{data.size(3)}')\n",
    "\n",
    "    # 2. 使用 reshape 函数修改张量形状\n",
    "    reshape_data = data.reshape([3, 2, 5, 6, 14])\n",
    "    print(f'张量修改形状(总数不变)：{reshape_data}')\n",
    "    print(reshape_data.shape)\n",
    "\n",
    "    data = torch.tensor([[10, 20, 30], [40, 50, 60]])\n",
    "    # 1. 使用 shape 属性或者 size 方法都可以获得张量的形状\n",
    "    print(data.shape, data.shape[0], data.shape[1])\n",
    "    print(data.size(), data.size(0), data.size(1))\n",
    "\n",
    "    # 2. 使用 reshape 函数修改张量形状\n",
    "    new_data = data.reshape(1, 6)\n",
    "    print(new_data.shape)\n",
    "\n",
    "\n",
    "reshape()"
   ],
   "id": "80a1fb2f6f0348e3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3]) 2 3\n",
      "torch.Size([2, 3]) 2 3\n",
      "torch.Size([1, 6])\n",
      "张量：tensor([[[[[9, 7, 4,  ..., 3, 2, 4],\n",
      "           [6, 1, 0,  ..., 7, 7, 9],\n",
      "           [1, 7, 1,  ..., 9, 4, 9],\n",
      "           [0, 8, 5,  ..., 6, 2, 5],\n",
      "           [3, 4, 6,  ..., 8, 4, 7],\n",
      "           [1, 3, 8,  ..., 1, 3, 4]],\n",
      "\n",
      "          [[5, 5, 3,  ..., 9, 7, 3],\n",
      "           [1, 7, 7,  ..., 3, 6, 1],\n",
      "           [3, 0, 5,  ..., 7, 9, 6],\n",
      "           [3, 7, 1,  ..., 6, 3, 0],\n",
      "           [6, 1, 8,  ..., 8, 1, 6],\n",
      "           [5, 0, 8,  ..., 6, 9, 7]],\n",
      "\n",
      "          [[7, 1, 9,  ..., 7, 4, 9],\n",
      "           [2, 1, 9,  ..., 9, 4, 3],\n",
      "           [6, 5, 9,  ..., 7, 6, 0],\n",
      "           [1, 1, 1,  ..., 4, 6, 2],\n",
      "           [9, 9, 6,  ..., 9, 4, 1],\n",
      "           [2, 4, 7,  ..., 4, 9, 2]],\n",
      "\n",
      "          [[3, 6, 4,  ..., 6, 2, 8],\n",
      "           [9, 8, 1,  ..., 2, 4, 4],\n",
      "           [3, 0, 1,  ..., 6, 5, 5],\n",
      "           [9, 7, 3,  ..., 2, 8, 6],\n",
      "           [5, 0, 4,  ..., 5, 0, 0],\n",
      "           [1, 7, 2,  ..., 5, 0, 5]],\n",
      "\n",
      "          [[0, 6, 3,  ..., 4, 2, 4],\n",
      "           [5, 6, 4,  ..., 8, 9, 7],\n",
      "           [5, 3, 7,  ..., 5, 2, 8],\n",
      "           [4, 8, 2,  ..., 6, 8, 2],\n",
      "           [6, 7, 2,  ..., 3, 9, 4],\n",
      "           [0, 4, 9,  ..., 0, 9, 1]]],\n",
      "\n",
      "\n",
      "         [[[2, 2, 9,  ..., 6, 3, 7],\n",
      "           [0, 3, 1,  ..., 6, 7, 2],\n",
      "           [4, 7, 5,  ..., 6, 5, 0],\n",
      "           [4, 3, 0,  ..., 0, 7, 0],\n",
      "           [0, 7, 1,  ..., 5, 6, 6],\n",
      "           [4, 8, 0,  ..., 4, 0, 2]],\n",
      "\n",
      "          [[8, 0, 9,  ..., 9, 1, 8],\n",
      "           [7, 1, 5,  ..., 4, 9, 6],\n",
      "           [9, 9, 5,  ..., 2, 4, 2],\n",
      "           [4, 6, 4,  ..., 6, 6, 7],\n",
      "           [7, 3, 8,  ..., 7, 3, 0],\n",
      "           [4, 3, 9,  ..., 8, 1, 5]],\n",
      "\n",
      "          [[7, 5, 0,  ..., 1, 0, 4],\n",
      "           [3, 6, 3,  ..., 2, 9, 3],\n",
      "           [5, 8, 0,  ..., 0, 9, 9],\n",
      "           [2, 1, 4,  ..., 1, 4, 8],\n",
      "           [4, 0, 6,  ..., 6, 6, 1],\n",
      "           [5, 6, 3,  ..., 4, 8, 5]],\n",
      "\n",
      "          [[7, 4, 1,  ..., 7, 8, 0],\n",
      "           [7, 2, 3,  ..., 3, 9, 5],\n",
      "           [8, 1, 7,  ..., 6, 2, 9],\n",
      "           [4, 3, 3,  ..., 6, 4, 3],\n",
      "           [1, 2, 2,  ..., 3, 4, 9],\n",
      "           [7, 1, 9,  ..., 5, 5, 2]],\n",
      "\n",
      "          [[5, 9, 8,  ..., 5, 0, 5],\n",
      "           [0, 9, 3,  ..., 3, 3, 9],\n",
      "           [0, 0, 2,  ..., 8, 6, 9],\n",
      "           [1, 1, 5,  ..., 5, 4, 7],\n",
      "           [8, 5, 9,  ..., 2, 8, 5],\n",
      "           [2, 7, 2,  ..., 1, 5, 0]]],\n",
      "\n",
      "\n",
      "         [[[8, 2, 4,  ..., 5, 8, 0],\n",
      "           [6, 2, 6,  ..., 2, 5, 6],\n",
      "           [3, 6, 1,  ..., 4, 1, 3],\n",
      "           [2, 1, 7,  ..., 0, 7, 6],\n",
      "           [5, 8, 9,  ..., 7, 4, 3],\n",
      "           [2, 8, 1,  ..., 6, 8, 3]],\n",
      "\n",
      "          [[4, 6, 6,  ..., 5, 5, 2],\n",
      "           [0, 0, 5,  ..., 6, 1, 0],\n",
      "           [7, 8, 5,  ..., 3, 1, 7],\n",
      "           [3, 3, 9,  ..., 7, 2, 2],\n",
      "           [3, 9, 7,  ..., 6, 9, 0],\n",
      "           [3, 2, 6,  ..., 8, 7, 6]],\n",
      "\n",
      "          [[7, 0, 8,  ..., 1, 7, 8],\n",
      "           [5, 3, 3,  ..., 0, 2, 4],\n",
      "           [9, 6, 0,  ..., 7, 5, 8],\n",
      "           [4, 3, 6,  ..., 5, 3, 3],\n",
      "           [2, 1, 4,  ..., 1, 7, 3],\n",
      "           [5, 7, 7,  ..., 8, 0, 4]],\n",
      "\n",
      "          [[3, 9, 7,  ..., 3, 8, 2],\n",
      "           [5, 2, 3,  ..., 0, 5, 1],\n",
      "           [9, 0, 1,  ..., 1, 5, 1],\n",
      "           [6, 0, 4,  ..., 4, 3, 6],\n",
      "           [5, 8, 6,  ..., 2, 8, 0],\n",
      "           [8, 6, 4,  ..., 0, 4, 1]],\n",
      "\n",
      "          [[8, 7, 6,  ..., 2, 3, 5],\n",
      "           [4, 7, 4,  ..., 7, 6, 1],\n",
      "           [8, 7, 9,  ..., 8, 8, 3],\n",
      "           [5, 2, 4,  ..., 0, 6, 2],\n",
      "           [9, 7, 3,  ..., 0, 9, 2],\n",
      "           [8, 9, 0,  ..., 9, 9, 5]]],\n",
      "\n",
      "\n",
      "         [[[0, 2, 3,  ..., 5, 2, 4],\n",
      "           [0, 6, 0,  ..., 1, 9, 1],\n",
      "           [5, 8, 6,  ..., 8, 0, 5],\n",
      "           [9, 5, 2,  ..., 5, 9, 3],\n",
      "           [2, 0, 1,  ..., 7, 7, 2],\n",
      "           [7, 4, 0,  ..., 1, 3, 7]],\n",
      "\n",
      "          [[5, 4, 4,  ..., 0, 5, 8],\n",
      "           [9, 9, 3,  ..., 8, 8, 2],\n",
      "           [6, 1, 3,  ..., 4, 1, 3],\n",
      "           [8, 4, 0,  ..., 9, 0, 1],\n",
      "           [1, 1, 5,  ..., 4, 2, 4],\n",
      "           [5, 5, 6,  ..., 5, 9, 9]],\n",
      "\n",
      "          [[9, 2, 7,  ..., 1, 9, 7],\n",
      "           [2, 0, 9,  ..., 2, 7, 3],\n",
      "           [7, 4, 7,  ..., 2, 3, 5],\n",
      "           [4, 3, 3,  ..., 6, 2, 0],\n",
      "           [9, 0, 2,  ..., 6, 8, 1],\n",
      "           [4, 4, 1,  ..., 1, 4, 3]],\n",
      "\n",
      "          [[7, 3, 0,  ..., 9, 4, 1],\n",
      "           [2, 2, 7,  ..., 5, 8, 3],\n",
      "           [6, 9, 3,  ..., 4, 1, 2],\n",
      "           [1, 2, 4,  ..., 2, 6, 1],\n",
      "           [6, 3, 1,  ..., 0, 0, 1],\n",
      "           [0, 0, 2,  ..., 2, 0, 6]],\n",
      "\n",
      "          [[7, 3, 6,  ..., 6, 1, 9],\n",
      "           [8, 8, 0,  ..., 6, 7, 6],\n",
      "           [3, 2, 9,  ..., 9, 6, 2],\n",
      "           [3, 4, 3,  ..., 6, 2, 7],\n",
      "           [1, 2, 9,  ..., 4, 6, 2],\n",
      "           [6, 3, 8,  ..., 6, 3, 4]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[2, 5, 1,  ..., 1, 5, 0],\n",
      "           [9, 6, 4,  ..., 6, 6, 2],\n",
      "           [8, 9, 1,  ..., 8, 2, 3],\n",
      "           [0, 3, 1,  ..., 4, 4, 5],\n",
      "           [7, 9, 7,  ..., 1, 4, 7],\n",
      "           [5, 6, 5,  ..., 9, 3, 3]],\n",
      "\n",
      "          [[7, 5, 2,  ..., 7, 7, 1],\n",
      "           [4, 1, 4,  ..., 1, 0, 6],\n",
      "           [2, 0, 0,  ..., 8, 6, 8],\n",
      "           [2, 1, 5,  ..., 8, 8, 5],\n",
      "           [6, 2, 2,  ..., 0, 7, 9],\n",
      "           [8, 8, 3,  ..., 6, 5, 6]],\n",
      "\n",
      "          [[5, 8, 0,  ..., 4, 2, 9],\n",
      "           [6, 1, 0,  ..., 6, 0, 9],\n",
      "           [1, 7, 3,  ..., 6, 2, 8],\n",
      "           [0, 0, 2,  ..., 7, 9, 8],\n",
      "           [7, 5, 5,  ..., 0, 4, 3],\n",
      "           [9, 3, 1,  ..., 0, 7, 5]],\n",
      "\n",
      "          [[3, 6, 3,  ..., 3, 8, 8],\n",
      "           [6, 7, 3,  ..., 1, 5, 8],\n",
      "           [5, 2, 2,  ..., 0, 8, 0],\n",
      "           [2, 9, 6,  ..., 1, 6, 3],\n",
      "           [9, 2, 0,  ..., 1, 4, 0],\n",
      "           [4, 6, 7,  ..., 5, 2, 5]],\n",
      "\n",
      "          [[6, 6, 6,  ..., 1, 0, 9],\n",
      "           [5, 8, 5,  ..., 0, 5, 3],\n",
      "           [3, 4, 7,  ..., 4, 6, 7],\n",
      "           [3, 9, 8,  ..., 2, 9, 3],\n",
      "           [1, 2, 2,  ..., 4, 2, 2],\n",
      "           [6, 9, 1,  ..., 0, 0, 9]]],\n",
      "\n",
      "\n",
      "         [[[3, 6, 4,  ..., 4, 5, 8],\n",
      "           [3, 7, 3,  ..., 5, 5, 2],\n",
      "           [2, 4, 8,  ..., 7, 0, 7],\n",
      "           [0, 7, 6,  ..., 6, 2, 0],\n",
      "           [0, 5, 7,  ..., 7, 2, 3],\n",
      "           [9, 9, 4,  ..., 2, 9, 4]],\n",
      "\n",
      "          [[8, 6, 3,  ..., 3, 9, 5],\n",
      "           [9, 0, 5,  ..., 3, 3, 1],\n",
      "           [3, 7, 4,  ..., 5, 5, 8],\n",
      "           [9, 6, 4,  ..., 1, 6, 0],\n",
      "           [5, 3, 2,  ..., 3, 7, 8],\n",
      "           [0, 4, 6,  ..., 4, 8, 4]],\n",
      "\n",
      "          [[1, 3, 6,  ..., 7, 5, 2],\n",
      "           [5, 8, 3,  ..., 6, 7, 7],\n",
      "           [7, 5, 7,  ..., 0, 0, 3],\n",
      "           [6, 0, 5,  ..., 0, 0, 7],\n",
      "           [9, 7, 0,  ..., 2, 3, 6],\n",
      "           [8, 1, 3,  ..., 6, 4, 0]],\n",
      "\n",
      "          [[1, 2, 1,  ..., 2, 9, 0],\n",
      "           [0, 0, 5,  ..., 7, 8, 0],\n",
      "           [4, 9, 2,  ..., 1, 4, 3],\n",
      "           [1, 2, 3,  ..., 9, 2, 0],\n",
      "           [4, 5, 9,  ..., 6, 3, 5],\n",
      "           [7, 7, 6,  ..., 3, 9, 6]],\n",
      "\n",
      "          [[1, 4, 5,  ..., 5, 2, 2],\n",
      "           [3, 5, 9,  ..., 4, 2, 9],\n",
      "           [3, 2, 2,  ..., 8, 1, 4],\n",
      "           [3, 0, 2,  ..., 0, 7, 8],\n",
      "           [5, 8, 2,  ..., 7, 4, 0],\n",
      "           [1, 3, 5,  ..., 9, 9, 4]]],\n",
      "\n",
      "\n",
      "         [[[4, 8, 7,  ..., 7, 2, 3],\n",
      "           [7, 2, 5,  ..., 8, 1, 8],\n",
      "           [6, 4, 5,  ..., 5, 6, 2],\n",
      "           [8, 1, 1,  ..., 8, 1, 2],\n",
      "           [0, 2, 8,  ..., 4, 6, 6],\n",
      "           [7, 6, 2,  ..., 4, 6, 3]],\n",
      "\n",
      "          [[4, 1, 6,  ..., 0, 3, 5],\n",
      "           [9, 2, 5,  ..., 7, 9, 2],\n",
      "           [9, 4, 4,  ..., 6, 0, 2],\n",
      "           [2, 6, 2,  ..., 7, 5, 4],\n",
      "           [6, 6, 8,  ..., 8, 3, 6],\n",
      "           [9, 0, 6,  ..., 8, 0, 9]],\n",
      "\n",
      "          [[1, 7, 0,  ..., 8, 4, 0],\n",
      "           [2, 4, 5,  ..., 6, 5, 2],\n",
      "           [6, 7, 0,  ..., 8, 7, 9],\n",
      "           [7, 1, 2,  ..., 7, 1, 3],\n",
      "           [1, 8, 1,  ..., 5, 7, 3],\n",
      "           [7, 8, 0,  ..., 9, 1, 9]],\n",
      "\n",
      "          [[8, 5, 2,  ..., 7, 7, 0],\n",
      "           [9, 9, 4,  ..., 9, 5, 0],\n",
      "           [6, 1, 3,  ..., 1, 9, 4],\n",
      "           [1, 4, 3,  ..., 2, 2, 2],\n",
      "           [3, 6, 2,  ..., 1, 3, 8],\n",
      "           [2, 2, 2,  ..., 2, 2, 6]],\n",
      "\n",
      "          [[5, 1, 1,  ..., 8, 3, 3],\n",
      "           [1, 3, 3,  ..., 3, 6, 2],\n",
      "           [4, 8, 1,  ..., 4, 6, 4],\n",
      "           [0, 3, 0,  ..., 4, 3, 6],\n",
      "           [6, 2, 7,  ..., 0, 2, 7],\n",
      "           [0, 3, 9,  ..., 9, 6, 0]]],\n",
      "\n",
      "\n",
      "         [[[9, 2, 4,  ..., 4, 6, 2],\n",
      "           [1, 4, 8,  ..., 9, 8, 9],\n",
      "           [2, 1, 7,  ..., 6, 4, 9],\n",
      "           [2, 5, 9,  ..., 5, 8, 2],\n",
      "           [7, 6, 8,  ..., 4, 8, 3],\n",
      "           [1, 7, 4,  ..., 0, 8, 7]],\n",
      "\n",
      "          [[6, 4, 1,  ..., 0, 2, 1],\n",
      "           [3, 8, 5,  ..., 8, 4, 4],\n",
      "           [2, 6, 9,  ..., 1, 4, 2],\n",
      "           [8, 3, 9,  ..., 6, 8, 6],\n",
      "           [8, 0, 3,  ..., 5, 1, 0],\n",
      "           [0, 7, 6,  ..., 1, 5, 0]],\n",
      "\n",
      "          [[4, 2, 9,  ..., 2, 7, 8],\n",
      "           [6, 2, 2,  ..., 3, 1, 8],\n",
      "           [0, 5, 4,  ..., 0, 7, 4],\n",
      "           [5, 5, 9,  ..., 2, 9, 2],\n",
      "           [0, 4, 1,  ..., 5, 7, 3],\n",
      "           [8, 8, 0,  ..., 5, 2, 2]],\n",
      "\n",
      "          [[5, 9, 2,  ..., 7, 0, 9],\n",
      "           [0, 4, 8,  ..., 3, 9, 2],\n",
      "           [9, 6, 2,  ..., 2, 9, 6],\n",
      "           [7, 5, 4,  ..., 8, 4, 0],\n",
      "           [2, 8, 3,  ..., 8, 9, 7],\n",
      "           [4, 7, 9,  ..., 3, 4, 1]],\n",
      "\n",
      "          [[9, 6, 0,  ..., 8, 3, 3],\n",
      "           [9, 1, 1,  ..., 2, 4, 1],\n",
      "           [6, 4, 7,  ..., 6, 3, 6],\n",
      "           [5, 0, 0,  ..., 5, 8, 2],\n",
      "           [7, 6, 7,  ..., 0, 4, 6],\n",
      "           [8, 9, 9,  ..., 1, 2, 5]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0, 2, 4,  ..., 7, 8, 3],\n",
      "           [6, 8, 6,  ..., 6, 5, 8],\n",
      "           [0, 1, 8,  ..., 6, 8, 3],\n",
      "           [7, 9, 0,  ..., 4, 3, 5],\n",
      "           [5, 9, 0,  ..., 0, 9, 3],\n",
      "           [7, 8, 6,  ..., 8, 0, 5]],\n",
      "\n",
      "          [[2, 2, 2,  ..., 6, 2, 1],\n",
      "           [6, 0, 1,  ..., 6, 5, 7],\n",
      "           [8, 0, 2,  ..., 5, 3, 9],\n",
      "           [8, 1, 9,  ..., 8, 7, 4],\n",
      "           [4, 8, 7,  ..., 8, 0, 0],\n",
      "           [8, 8, 0,  ..., 5, 8, 7]],\n",
      "\n",
      "          [[2, 3, 5,  ..., 0, 7, 4],\n",
      "           [7, 7, 7,  ..., 9, 8, 4],\n",
      "           [9, 8, 0,  ..., 1, 5, 6],\n",
      "           [4, 3, 6,  ..., 2, 8, 1],\n",
      "           [4, 2, 4,  ..., 0, 2, 7],\n",
      "           [6, 8, 9,  ..., 5, 7, 4]],\n",
      "\n",
      "          [[1, 9, 3,  ..., 2, 3, 7],\n",
      "           [6, 0, 3,  ..., 0, 5, 3],\n",
      "           [1, 3, 4,  ..., 4, 5, 5],\n",
      "           [6, 2, 4,  ..., 5, 6, 9],\n",
      "           [6, 6, 8,  ..., 2, 8, 2],\n",
      "           [6, 0, 2,  ..., 0, 5, 6]],\n",
      "\n",
      "          [[2, 5, 2,  ..., 8, 8, 3],\n",
      "           [1, 1, 1,  ..., 1, 2, 0],\n",
      "           [9, 9, 9,  ..., 3, 5, 6],\n",
      "           [1, 1, 7,  ..., 1, 8, 7],\n",
      "           [7, 3, 7,  ..., 3, 4, 8],\n",
      "           [3, 8, 8,  ..., 0, 1, 1]]],\n",
      "\n",
      "\n",
      "         [[[0, 1, 6,  ..., 3, 3, 2],\n",
      "           [2, 1, 9,  ..., 1, 1, 9],\n",
      "           [5, 0, 6,  ..., 7, 7, 4],\n",
      "           [2, 1, 0,  ..., 5, 4, 8],\n",
      "           [1, 9, 9,  ..., 8, 3, 9],\n",
      "           [4, 3, 2,  ..., 7, 4, 6]],\n",
      "\n",
      "          [[8, 3, 5,  ..., 7, 8, 0],\n",
      "           [1, 3, 6,  ..., 1, 8, 3],\n",
      "           [0, 3, 5,  ..., 6, 8, 3],\n",
      "           [5, 4, 9,  ..., 0, 7, 8],\n",
      "           [9, 4, 8,  ..., 6, 3, 3],\n",
      "           [1, 7, 1,  ..., 9, 5, 7]],\n",
      "\n",
      "          [[9, 2, 5,  ..., 8, 7, 0],\n",
      "           [6, 3, 6,  ..., 5, 3, 1],\n",
      "           [4, 9, 2,  ..., 9, 9, 0],\n",
      "           [2, 2, 2,  ..., 3, 2, 9],\n",
      "           [7, 6, 7,  ..., 3, 6, 0],\n",
      "           [7, 6, 2,  ..., 8, 1, 5]],\n",
      "\n",
      "          [[3, 6, 0,  ..., 4, 4, 9],\n",
      "           [0, 7, 0,  ..., 8, 5, 0],\n",
      "           [6, 0, 2,  ..., 4, 7, 6],\n",
      "           [3, 6, 0,  ..., 6, 3, 7],\n",
      "           [8, 3, 3,  ..., 1, 8, 9],\n",
      "           [0, 4, 1,  ..., 9, 3, 4]],\n",
      "\n",
      "          [[1, 6, 4,  ..., 9, 4, 7],\n",
      "           [5, 9, 7,  ..., 3, 2, 6],\n",
      "           [4, 7, 1,  ..., 5, 9, 1],\n",
      "           [7, 7, 1,  ..., 0, 7, 1],\n",
      "           [6, 5, 2,  ..., 8, 8, 1],\n",
      "           [6, 2, 3,  ..., 2, 9, 9]]],\n",
      "\n",
      "\n",
      "         [[[3, 9, 2,  ..., 9, 0, 6],\n",
      "           [1, 2, 7,  ..., 7, 3, 3],\n",
      "           [4, 2, 6,  ..., 9, 2, 5],\n",
      "           [3, 0, 8,  ..., 4, 0, 0],\n",
      "           [5, 0, 3,  ..., 9, 4, 7],\n",
      "           [4, 3, 8,  ..., 6, 7, 0]],\n",
      "\n",
      "          [[5, 1, 2,  ..., 3, 5, 5],\n",
      "           [3, 6, 6,  ..., 3, 3, 2],\n",
      "           [2, 9, 7,  ..., 9, 1, 2],\n",
      "           [4, 3, 0,  ..., 6, 4, 6],\n",
      "           [2, 9, 7,  ..., 6, 5, 3],\n",
      "           [0, 9, 4,  ..., 8, 5, 9]],\n",
      "\n",
      "          [[2, 4, 9,  ..., 9, 2, 4],\n",
      "           [6, 9, 8,  ..., 8, 3, 0],\n",
      "           [2, 2, 0,  ..., 1, 0, 0],\n",
      "           [6, 5, 4,  ..., 8, 0, 7],\n",
      "           [7, 5, 5,  ..., 6, 3, 3],\n",
      "           [9, 6, 8,  ..., 5, 5, 7]],\n",
      "\n",
      "          [[7, 5, 4,  ..., 5, 8, 0],\n",
      "           [6, 0, 9,  ..., 9, 7, 1],\n",
      "           [1, 2, 5,  ..., 4, 2, 7],\n",
      "           [5, 9, 1,  ..., 4, 0, 9],\n",
      "           [7, 7, 7,  ..., 0, 5, 6],\n",
      "           [9, 9, 5,  ..., 6, 1, 6]],\n",
      "\n",
      "          [[9, 1, 1,  ..., 1, 7, 7],\n",
      "           [8, 8, 4,  ..., 8, 0, 1],\n",
      "           [2, 7, 6,  ..., 2, 4, 0],\n",
      "           [4, 7, 6,  ..., 6, 9, 2],\n",
      "           [9, 7, 3,  ..., 1, 7, 2],\n",
      "           [5, 9, 8,  ..., 1, 6, 7]]],\n",
      "\n",
      "\n",
      "         [[[3, 6, 2,  ..., 3, 3, 9],\n",
      "           [0, 7, 9,  ..., 0, 2, 5],\n",
      "           [4, 9, 6,  ..., 9, 8, 7],\n",
      "           [0, 3, 9,  ..., 1, 7, 9],\n",
      "           [9, 9, 8,  ..., 8, 7, 5],\n",
      "           [3, 2, 5,  ..., 0, 9, 7]],\n",
      "\n",
      "          [[8, 0, 0,  ..., 9, 2, 7],\n",
      "           [8, 9, 6,  ..., 7, 7, 7],\n",
      "           [3, 2, 6,  ..., 5, 1, 7],\n",
      "           [0, 2, 7,  ..., 7, 6, 1],\n",
      "           [2, 5, 7,  ..., 0, 5, 5],\n",
      "           [5, 1, 9,  ..., 0, 7, 7]],\n",
      "\n",
      "          [[7, 8, 1,  ..., 2, 5, 5],\n",
      "           [0, 2, 1,  ..., 9, 5, 9],\n",
      "           [0, 9, 4,  ..., 5, 4, 1],\n",
      "           [6, 9, 7,  ..., 6, 4, 1],\n",
      "           [9, 6, 4,  ..., 0, 3, 2],\n",
      "           [7, 9, 6,  ..., 1, 0, 3]],\n",
      "\n",
      "          [[0, 8, 5,  ..., 4, 7, 5],\n",
      "           [0, 0, 2,  ..., 1, 1, 0],\n",
      "           [6, 5, 4,  ..., 7, 7, 0],\n",
      "           [4, 1, 3,  ..., 7, 4, 5],\n",
      "           [0, 6, 6,  ..., 6, 5, 0],\n",
      "           [5, 3, 6,  ..., 7, 4, 4]],\n",
      "\n",
      "          [[7, 4, 2,  ..., 9, 0, 7],\n",
      "           [3, 3, 2,  ..., 4, 2, 0],\n",
      "           [1, 3, 4,  ..., 0, 2, 2],\n",
      "           [7, 6, 2,  ..., 1, 3, 1],\n",
      "           [7, 4, 6,  ..., 9, 1, 4],\n",
      "           [2, 6, 4,  ..., 3, 0, 9]]]]])\n",
      "张量形状：torch.Size([3, 4, 5, 6, 7])\n",
      "张量形状：3\n",
      "张量形状：4\n",
      "张量形状：5\n",
      "张量形状：6\n",
      "张量形状：3\n",
      "张量形状：4\n",
      "张量形状：5\n",
      "张量形状：6\n",
      "张量修改形状(总数不变)：tensor([[[[[9, 7, 4,  ..., 7, 7, 9],\n",
      "           [1, 7, 1,  ..., 6, 2, 5],\n",
      "           [3, 4, 6,  ..., 1, 3, 4],\n",
      "           [5, 5, 3,  ..., 3, 6, 1],\n",
      "           [3, 0, 5,  ..., 6, 3, 0],\n",
      "           [6, 1, 8,  ..., 6, 9, 7]],\n",
      "\n",
      "          [[7, 1, 9,  ..., 9, 4, 3],\n",
      "           [6, 5, 9,  ..., 4, 6, 2],\n",
      "           [9, 9, 6,  ..., 4, 9, 2],\n",
      "           [3, 6, 4,  ..., 2, 4, 4],\n",
      "           [3, 0, 1,  ..., 2, 8, 6],\n",
      "           [5, 0, 4,  ..., 5, 0, 5]],\n",
      "\n",
      "          [[0, 6, 3,  ..., 8, 9, 7],\n",
      "           [5, 3, 7,  ..., 6, 8, 2],\n",
      "           [6, 7, 2,  ..., 0, 9, 1],\n",
      "           [2, 2, 9,  ..., 6, 7, 2],\n",
      "           [4, 7, 5,  ..., 0, 7, 0],\n",
      "           [0, 7, 1,  ..., 4, 0, 2]],\n",
      "\n",
      "          [[8, 0, 9,  ..., 4, 9, 6],\n",
      "           [9, 9, 5,  ..., 6, 6, 7],\n",
      "           [7, 3, 8,  ..., 8, 1, 5],\n",
      "           [7, 5, 0,  ..., 2, 9, 3],\n",
      "           [5, 8, 0,  ..., 1, 4, 8],\n",
      "           [4, 0, 6,  ..., 4, 8, 5]],\n",
      "\n",
      "          [[7, 4, 1,  ..., 3, 9, 5],\n",
      "           [8, 1, 7,  ..., 6, 4, 3],\n",
      "           [1, 2, 2,  ..., 5, 5, 2],\n",
      "           [5, 9, 8,  ..., 3, 3, 9],\n",
      "           [0, 0, 2,  ..., 5, 4, 7],\n",
      "           [8, 5, 9,  ..., 1, 5, 0]]],\n",
      "\n",
      "\n",
      "         [[[8, 2, 4,  ..., 2, 5, 6],\n",
      "           [3, 6, 1,  ..., 0, 7, 6],\n",
      "           [5, 8, 9,  ..., 6, 8, 3],\n",
      "           [4, 6, 6,  ..., 6, 1, 0],\n",
      "           [7, 8, 5,  ..., 7, 2, 2],\n",
      "           [3, 9, 7,  ..., 8, 7, 6]],\n",
      "\n",
      "          [[7, 0, 8,  ..., 0, 2, 4],\n",
      "           [9, 6, 0,  ..., 5, 3, 3],\n",
      "           [2, 1, 4,  ..., 8, 0, 4],\n",
      "           [3, 9, 7,  ..., 0, 5, 1],\n",
      "           [9, 0, 1,  ..., 4, 3, 6],\n",
      "           [5, 8, 6,  ..., 0, 4, 1]],\n",
      "\n",
      "          [[8, 7, 6,  ..., 7, 6, 1],\n",
      "           [8, 7, 9,  ..., 0, 6, 2],\n",
      "           [9, 7, 3,  ..., 9, 9, 5],\n",
      "           [0, 2, 3,  ..., 1, 9, 1],\n",
      "           [5, 8, 6,  ..., 5, 9, 3],\n",
      "           [2, 0, 1,  ..., 1, 3, 7]],\n",
      "\n",
      "          [[5, 4, 4,  ..., 8, 8, 2],\n",
      "           [6, 1, 3,  ..., 9, 0, 1],\n",
      "           [1, 1, 5,  ..., 5, 9, 9],\n",
      "           [9, 2, 7,  ..., 2, 7, 3],\n",
      "           [7, 4, 7,  ..., 6, 2, 0],\n",
      "           [9, 0, 2,  ..., 1, 4, 3]],\n",
      "\n",
      "          [[7, 3, 0,  ..., 5, 8, 3],\n",
      "           [6, 9, 3,  ..., 2, 6, 1],\n",
      "           [6, 3, 1,  ..., 2, 0, 6],\n",
      "           [7, 3, 6,  ..., 6, 7, 6],\n",
      "           [3, 2, 9,  ..., 6, 2, 7],\n",
      "           [1, 2, 9,  ..., 6, 3, 4]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[2, 5, 1,  ..., 6, 6, 2],\n",
      "           [8, 9, 1,  ..., 4, 4, 5],\n",
      "           [7, 9, 7,  ..., 9, 3, 3],\n",
      "           [7, 5, 2,  ..., 1, 0, 6],\n",
      "           [2, 0, 0,  ..., 8, 8, 5],\n",
      "           [6, 2, 2,  ..., 6, 5, 6]],\n",
      "\n",
      "          [[5, 8, 0,  ..., 6, 0, 9],\n",
      "           [1, 7, 3,  ..., 7, 9, 8],\n",
      "           [7, 5, 5,  ..., 0, 7, 5],\n",
      "           [3, 6, 3,  ..., 1, 5, 8],\n",
      "           [5, 2, 2,  ..., 1, 6, 3],\n",
      "           [9, 2, 0,  ..., 5, 2, 5]],\n",
      "\n",
      "          [[6, 6, 6,  ..., 0, 5, 3],\n",
      "           [3, 4, 7,  ..., 2, 9, 3],\n",
      "           [1, 2, 2,  ..., 0, 0, 9],\n",
      "           [3, 6, 4,  ..., 5, 5, 2],\n",
      "           [2, 4, 8,  ..., 6, 2, 0],\n",
      "           [0, 5, 7,  ..., 2, 9, 4]],\n",
      "\n",
      "          [[8, 6, 3,  ..., 3, 3, 1],\n",
      "           [3, 7, 4,  ..., 1, 6, 0],\n",
      "           [5, 3, 2,  ..., 4, 8, 4],\n",
      "           [1, 3, 6,  ..., 6, 7, 7],\n",
      "           [7, 5, 7,  ..., 0, 0, 7],\n",
      "           [9, 7, 0,  ..., 6, 4, 0]],\n",
      "\n",
      "          [[1, 2, 1,  ..., 7, 8, 0],\n",
      "           [4, 9, 2,  ..., 9, 2, 0],\n",
      "           [4, 5, 9,  ..., 3, 9, 6],\n",
      "           [1, 4, 5,  ..., 4, 2, 9],\n",
      "           [3, 2, 2,  ..., 0, 7, 8],\n",
      "           [5, 8, 2,  ..., 9, 9, 4]]],\n",
      "\n",
      "\n",
      "         [[[4, 8, 7,  ..., 8, 1, 8],\n",
      "           [6, 4, 5,  ..., 8, 1, 2],\n",
      "           [0, 2, 8,  ..., 4, 6, 3],\n",
      "           [4, 1, 6,  ..., 7, 9, 2],\n",
      "           [9, 4, 4,  ..., 7, 5, 4],\n",
      "           [6, 6, 8,  ..., 8, 0, 9]],\n",
      "\n",
      "          [[1, 7, 0,  ..., 6, 5, 2],\n",
      "           [6, 7, 0,  ..., 7, 1, 3],\n",
      "           [1, 8, 1,  ..., 9, 1, 9],\n",
      "           [8, 5, 2,  ..., 9, 5, 0],\n",
      "           [6, 1, 3,  ..., 2, 2, 2],\n",
      "           [3, 6, 2,  ..., 2, 2, 6]],\n",
      "\n",
      "          [[5, 1, 1,  ..., 3, 6, 2],\n",
      "           [4, 8, 1,  ..., 4, 3, 6],\n",
      "           [6, 2, 7,  ..., 9, 6, 0],\n",
      "           [9, 2, 4,  ..., 9, 8, 9],\n",
      "           [2, 1, 7,  ..., 5, 8, 2],\n",
      "           [7, 6, 8,  ..., 0, 8, 7]],\n",
      "\n",
      "          [[6, 4, 1,  ..., 8, 4, 4],\n",
      "           [2, 6, 9,  ..., 6, 8, 6],\n",
      "           [8, 0, 3,  ..., 1, 5, 0],\n",
      "           [4, 2, 9,  ..., 3, 1, 8],\n",
      "           [0, 5, 4,  ..., 2, 9, 2],\n",
      "           [0, 4, 1,  ..., 5, 2, 2]],\n",
      "\n",
      "          [[5, 9, 2,  ..., 3, 9, 2],\n",
      "           [9, 6, 2,  ..., 8, 4, 0],\n",
      "           [2, 8, 3,  ..., 3, 4, 1],\n",
      "           [9, 6, 0,  ..., 2, 4, 1],\n",
      "           [6, 4, 7,  ..., 5, 8, 2],\n",
      "           [7, 6, 7,  ..., 1, 2, 5]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0, 2, 4,  ..., 6, 5, 8],\n",
      "           [0, 1, 8,  ..., 4, 3, 5],\n",
      "           [5, 9, 0,  ..., 8, 0, 5],\n",
      "           [2, 2, 2,  ..., 6, 5, 7],\n",
      "           [8, 0, 2,  ..., 8, 7, 4],\n",
      "           [4, 8, 7,  ..., 5, 8, 7]],\n",
      "\n",
      "          [[2, 3, 5,  ..., 9, 8, 4],\n",
      "           [9, 8, 0,  ..., 2, 8, 1],\n",
      "           [4, 2, 4,  ..., 5, 7, 4],\n",
      "           [1, 9, 3,  ..., 0, 5, 3],\n",
      "           [1, 3, 4,  ..., 5, 6, 9],\n",
      "           [6, 6, 8,  ..., 0, 5, 6]],\n",
      "\n",
      "          [[2, 5, 2,  ..., 1, 2, 0],\n",
      "           [9, 9, 9,  ..., 1, 8, 7],\n",
      "           [7, 3, 7,  ..., 0, 1, 1],\n",
      "           [0, 1, 6,  ..., 1, 1, 9],\n",
      "           [5, 0, 6,  ..., 5, 4, 8],\n",
      "           [1, 9, 9,  ..., 7, 4, 6]],\n",
      "\n",
      "          [[8, 3, 5,  ..., 1, 8, 3],\n",
      "           [0, 3, 5,  ..., 0, 7, 8],\n",
      "           [9, 4, 8,  ..., 9, 5, 7],\n",
      "           [9, 2, 5,  ..., 5, 3, 1],\n",
      "           [4, 9, 2,  ..., 3, 2, 9],\n",
      "           [7, 6, 7,  ..., 8, 1, 5]],\n",
      "\n",
      "          [[3, 6, 0,  ..., 8, 5, 0],\n",
      "           [6, 0, 2,  ..., 6, 3, 7],\n",
      "           [8, 3, 3,  ..., 9, 3, 4],\n",
      "           [1, 6, 4,  ..., 3, 2, 6],\n",
      "           [4, 7, 1,  ..., 0, 7, 1],\n",
      "           [6, 5, 2,  ..., 2, 9, 9]]],\n",
      "\n",
      "\n",
      "         [[[3, 9, 2,  ..., 7, 3, 3],\n",
      "           [4, 2, 6,  ..., 4, 0, 0],\n",
      "           [5, 0, 3,  ..., 6, 7, 0],\n",
      "           [5, 1, 2,  ..., 3, 3, 2],\n",
      "           [2, 9, 7,  ..., 6, 4, 6],\n",
      "           [2, 9, 7,  ..., 8, 5, 9]],\n",
      "\n",
      "          [[2, 4, 9,  ..., 8, 3, 0],\n",
      "           [2, 2, 0,  ..., 8, 0, 7],\n",
      "           [7, 5, 5,  ..., 5, 5, 7],\n",
      "           [7, 5, 4,  ..., 9, 7, 1],\n",
      "           [1, 2, 5,  ..., 4, 0, 9],\n",
      "           [7, 7, 7,  ..., 6, 1, 6]],\n",
      "\n",
      "          [[9, 1, 1,  ..., 8, 0, 1],\n",
      "           [2, 7, 6,  ..., 6, 9, 2],\n",
      "           [9, 7, 3,  ..., 1, 6, 7],\n",
      "           [3, 6, 2,  ..., 0, 2, 5],\n",
      "           [4, 9, 6,  ..., 1, 7, 9],\n",
      "           [9, 9, 8,  ..., 0, 9, 7]],\n",
      "\n",
      "          [[8, 0, 0,  ..., 7, 7, 7],\n",
      "           [3, 2, 6,  ..., 7, 6, 1],\n",
      "           [2, 5, 7,  ..., 0, 7, 7],\n",
      "           [7, 8, 1,  ..., 9, 5, 9],\n",
      "           [0, 9, 4,  ..., 6, 4, 1],\n",
      "           [9, 6, 4,  ..., 1, 0, 3]],\n",
      "\n",
      "          [[0, 8, 5,  ..., 1, 1, 0],\n",
      "           [6, 5, 4,  ..., 7, 4, 5],\n",
      "           [0, 6, 6,  ..., 7, 4, 4],\n",
      "           [7, 4, 2,  ..., 4, 2, 0],\n",
      "           [1, 3, 4,  ..., 1, 3, 1],\n",
      "           [7, 4, 6,  ..., 3, 0, 9]]]]])\n",
      "torch.Size([3, 2, 5, 6, 14])\n",
      "torch.Size([2, 3]) 2 3\n",
      "torch.Size([2, 3]) 2 3\n",
      "torch.Size([1, 6])\n"
     ]
    }
   ],
   "execution_count": 104
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T10:38:20.927757Z",
     "start_time": "2025-03-23T10:38:20.917757Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "张量squeeze和unsqueeze\n",
    "- squeeze:删除指定位置形状为1的维度，不指定位置删除所有形状为1的维度（降维）\n",
    "- unsqueeze:在指定位置添加形状为1的维度（升维）\n",
    "'''\n",
    "\n",
    "\n",
    "def squeeze_or_unsqueeze():\n",
    "    squeeze_data = torch.tensor([1, 2, 3, 4, 5])\n",
    "    print(f'squeeze和unsqueeze案例 维度：{squeeze_data.shape}， 数据集:{squeeze_data}')\n",
    "\n",
    "    squeeze_data = squeeze_data.unsqueeze(dim=0)\n",
    "    print(f'在位置为0的位置添加形状为1的维度 维度：{squeeze_data.shape}， 数据集:{squeeze_data}')\n",
    "\n",
    "    squeeze_data = squeeze_data.unsqueeze(dim=1)\n",
    "    print(f'在1维上拓展维度 维度：{squeeze_data.shape}， 数据集:{squeeze_data}')\n",
    "\n",
    "    squeeze_data = squeeze_data.unsqueeze(dim=-1)\n",
    "    print(f'在-1维基础上拓展维度 维度：{squeeze_data.shape}， 数据集:{squeeze_data}')\n",
    "\n",
    "\n",
    "squeeze_or_unsqueeze()"
   ],
   "id": "319cfcf29aa145d3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "squeeze和unsqueeze案例 维度：torch.Size([5])， 数据集:tensor([1, 2, 3, 4, 5])\n",
      "在位置为0的位置添加形状为1的维度 维度：torch.Size([1, 5])， 数据集:tensor([[1, 2, 3, 4, 5]])\n",
      "在1维上拓展维度 维度：torch.Size([1, 1, 5])， 数据集:tensor([[[1, 2, 3, 4, 5]]])\n",
      "在-1维基础上拓展维度 维度：torch.Size([1, 1, 5, 1])， 数据集:tensor([[[[1],\n",
      "          [2],\n",
      "          [3],\n",
      "          [4],\n",
      "          [5]]]])\n"
     ]
    }
   ],
   "execution_count": 97
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T10:37:47.012563Z",
     "start_time": "2025-03-23T10:37:47.001711Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "transpose和permute\n",
    "transpose：实现交换正浪形状的指定维度，；例如一个形状为（2，3，4）把3和4进行交换，将张量变换为（2，4，3）\n",
    "permute：一次性交换更多的维度\n",
    "'''\n",
    "\n",
    "\n",
    "def transpose_or_permute():\n",
    "    # 创建一个三维的张量\n",
    "    # data = torch.tensor(np.random.randint(0, 10, [3, 4, 5]))\n",
    "    data = torch.randint(0, 10, [3, 4, 5])\n",
    "    print(f'data 维度：{data.shape}， 数据集:{data}')\n",
    "\n",
    "    exchange_transpose = torch.transpose(data, 1, 2)\n",
    "    print(f'交换1和2维度 形状：{exchange_transpose.shape}, 数据：{exchange_transpose}')\n",
    "\n",
    "    first_transpose = torch.transpose(data, 0, 1)\n",
    "    second_transpose = torch.transpose(first_transpose, 1, 2)\n",
    "    print(f'将形状修改为（4， 5， 3）形状：{second_transpose.shape}， 数据：{second_transpose}')\n",
    "\n",
    "    permute_data = torch.permute(data, [1, 2, 0])\n",
    "    print(f'使用permute函数将形状修改为（4， 5， 3）形状：{permute_data.shape}, 数据 ：{permute_data}')\n",
    "\n",
    "\n",
    "transpose_or_permute()"
   ],
   "id": "d43fd6448ed9d49a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data 维度：torch.Size([3, 4, 5])， 数据集:tensor([[[6, 6, 8, 3, 9],\n",
      "         [4, 9, 0, 1, 5],\n",
      "         [4, 3, 3, 8, 6],\n",
      "         [0, 1, 3, 4, 4]],\n",
      "\n",
      "        [[8, 3, 6, 9, 4],\n",
      "         [1, 2, 3, 2, 0],\n",
      "         [3, 0, 7, 0, 9],\n",
      "         [6, 7, 1, 4, 4]],\n",
      "\n",
      "        [[7, 0, 1, 2, 7],\n",
      "         [6, 4, 5, 5, 2],\n",
      "         [2, 2, 0, 1, 3],\n",
      "         [4, 7, 4, 0, 5]]])\n",
      "交换1和2维度 形状：torch.Size([3, 5, 4]), 数据：tensor([[[6, 4, 4, 0],\n",
      "         [6, 9, 3, 1],\n",
      "         [8, 0, 3, 3],\n",
      "         [3, 1, 8, 4],\n",
      "         [9, 5, 6, 4]],\n",
      "\n",
      "        [[8, 1, 3, 6],\n",
      "         [3, 2, 0, 7],\n",
      "         [6, 3, 7, 1],\n",
      "         [9, 2, 0, 4],\n",
      "         [4, 0, 9, 4]],\n",
      "\n",
      "        [[7, 6, 2, 4],\n",
      "         [0, 4, 2, 7],\n",
      "         [1, 5, 0, 4],\n",
      "         [2, 5, 1, 0],\n",
      "         [7, 2, 3, 5]]])\n",
      "将形状修改为（4， 5， 3）形状：torch.Size([4, 5, 3])， 数据：tensor([[[6, 8, 7],\n",
      "         [6, 3, 0],\n",
      "         [8, 6, 1],\n",
      "         [3, 9, 2],\n",
      "         [9, 4, 7]],\n",
      "\n",
      "        [[4, 1, 6],\n",
      "         [9, 2, 4],\n",
      "         [0, 3, 5],\n",
      "         [1, 2, 5],\n",
      "         [5, 0, 2]],\n",
      "\n",
      "        [[4, 3, 2],\n",
      "         [3, 0, 2],\n",
      "         [3, 7, 0],\n",
      "         [8, 0, 1],\n",
      "         [6, 9, 3]],\n",
      "\n",
      "        [[0, 6, 4],\n",
      "         [1, 7, 7],\n",
      "         [3, 1, 4],\n",
      "         [4, 4, 0],\n",
      "         [4, 4, 5]]])\n",
      "使用permute函数将形状修改为（4， 5， 3）形状：torch.Size([4, 5, 3]), 数据 ：tensor([[[6, 8, 7],\n",
      "         [6, 3, 0],\n",
      "         [8, 6, 1],\n",
      "         [3, 9, 2],\n",
      "         [9, 4, 7]],\n",
      "\n",
      "        [[4, 1, 6],\n",
      "         [9, 2, 4],\n",
      "         [0, 3, 5],\n",
      "         [1, 2, 5],\n",
      "         [5, 0, 2]],\n",
      "\n",
      "        [[4, 3, 2],\n",
      "         [3, 0, 2],\n",
      "         [3, 7, 0],\n",
      "         [8, 0, 1],\n",
      "         [6, 9, 3]],\n",
      "\n",
      "        [[0, 6, 4],\n",
      "         [1, 7, 7],\n",
      "         [3, 1, 4],\n",
      "         [4, 4, 0],\n",
      "         [4, 4, 5]]])\n"
     ]
    }
   ],
   "execution_count": 96
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T10:33:21.345790Z",
     "start_time": "2025-03-23T10:33:21.335393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "view和contiguous函数\n",
    "view：也可以用于修改张量形状，但只能用于连续张量，在PyTorch中有些张量的底层数据在内存中存储顺序与其在张量逻辑顺序不一致，view函数无反对这样的张量进行变形处理，eg：一个张量经过transpose或者permute函数的处理后，就无法使用view函数进行形状操作\n",
    "contiguous：将不连续张量转化为连续张量\n",
    "is_contiguous：判断张量是否连续，并返回True/False\n",
    "'''\n",
    "\n",
    "\n",
    "def view_or_contiguous_demo():\n",
    "    data = torch.tensor([[10, 20, 30], [40, 50, 60]])\n",
    "    print(f'shape：{data.shape}, data :{data}')\n",
    "\n",
    "    is_contiguous = data.is_contiguous()\n",
    "    print(f'张量是否连续：{is_contiguous}')\n",
    "\n",
    "    data = data.view(3, 2)\n",
    "    print(f'使用transpose改变张量形状 shape：{data.shape}, is_contiguous: {data.is_contiguous()} data:{data}')\n",
    "\n",
    "    data = torch.transpose(data, 0, 1)\n",
    "    print(f'使用transpose改变张量形状 shape：{data.shape}, is_contiguous: {data.is_contiguous()} data:{data}')\n",
    "\n",
    "    # 这里再使用view就会报错，因为当前张量不连续\n",
    "    #data = data.view(3, 2)\n",
    "    #print(f'使用view改变张量形状 shape：{data.shape}, is_contiguous: {data.is_contiguous()} data:{data}')\n",
    "\n",
    "    data = data.contiguous()\n",
    "    print(f'使用contiguous改为连续张量 shape：{data.shape}, is_contiguous: {data.is_contiguous()} data:{data}')\n",
    "\n",
    "    data = data.view(2, 3)\n",
    "    print(f'使用view改变张量形状 shape：{data.shape}, is_contiguous: {data.is_contiguous()} data:{data}')\n",
    "\n",
    "\n",
    "view_or_contiguous_demo()"
   ],
   "id": "bd259a277115ab02",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape：torch.Size([2, 3]), data :tensor([[10, 20, 30],\n",
      "        [40, 50, 60]])\n",
      "张量是否连续：True\n",
      "使用transpose改变张量形状 shape：torch.Size([3, 2]), is_contiguous: True data:tensor([[10, 20],\n",
      "        [30, 40],\n",
      "        [50, 60]])\n",
      "使用transpose改变张量形状 shape：torch.Size([2, 3]), is_contiguous: False data:tensor([[10, 30, 50],\n",
      "        [20, 40, 60]])\n",
      "使用contiguous改为连续张量 shape：torch.Size([2, 3]), is_contiguous: True data:tensor([[10, 30, 50],\n",
      "        [20, 40, 60]])\n",
      "使用view改变张量形状 shape：torch.Size([2, 3]), is_contiguous: True data:tensor([[10, 30, 50],\n",
      "        [20, 40, 60]])\n"
     ]
    }
   ],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T10:37:00.634315Z",
     "start_time": "2025-03-23T10:37:00.623572Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "Tensor拼接操作cat和concat\n",
    "cat:将多个张量按照指定维度拼接，要求张量在除拼接维度上其他维度保持一致\n",
    "concat:语法与cat保持一致，但更灵活，可以通过指定dim参数指定拼接维度\n",
    "stack：在一个新的维度上连接一系列张量，这回增加一个新维度，并且所有输入张量的形状必须完全相同\n",
    "备注：这里的dim可以理解为在第几层合并拼接，对应顺序位置shape增加\n",
    "'''\n",
    "\n",
    "\n",
    "def cat_demo():\n",
    "    data1 = torch.randint(0, 10, [1, 2, 3])\n",
    "    print(f'data1 shape：{data1.shape}, data :{data1}')\n",
    "    data2 = torch.randint(0, 10, [1, 2, 3])\n",
    "    print(f'data2 shape：{data2.shape}, data :{data2}')\n",
    "\n",
    "    data = torch.cat([data1, data2], dim=0)\n",
    "    print(f'data shape：{data.shape}, data :{data}')\n",
    "\n",
    "    data = torch.cat([data1, data2], dim=0)\n",
    "    print(f'data shape：{data.shape}, data :{data}')\n",
    "\n",
    "    data = torch.cat([data1, data2], dim=1)\n",
    "    print(f'data shape：{data.shape}, data :{data}')\n",
    "\n",
    "\n",
    "def stack_demo():\n",
    "    data1 = torch.randint(0, 10, [2, 3])\n",
    "    print(f'data1 shape：{data1.shape}, data :{data1}')\n",
    "    data2 = torch.randint(0, 10, [2, 3])\n",
    "    print(f'data2 shape：{data2.shape}, data :{data2}')\n",
    "\n",
    "    data = torch.stack([data1, data2], dim=0)\n",
    "    print(f'在0维上stack shape：{data.shape}, data :{data}')\n",
    "\n",
    "    data = torch.stack([data1, data2], dim=1)\n",
    "    print(f'在1维上stack shape：{data.shape}, data :{data}')\n",
    "\n",
    "    data = torch.stack([data1, data2], dim=2)\n",
    "    print(f'在2维上stack shape：{data.shape}, data :{data}')\n",
    "\n",
    "\n",
    "cat_demo()\n",
    "stack_demo()"
   ],
   "id": "f16537e1b12dfae4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data1 shape：torch.Size([1, 2, 3]), data :tensor([[[7, 1, 7],\n",
      "         [9, 2, 7]]])\n",
      "data2 shape：torch.Size([1, 2, 3]), data :tensor([[[4, 3, 5],\n",
      "         [9, 3, 4]]])\n",
      "data shape：torch.Size([2, 2, 3]), data :tensor([[[7, 1, 7],\n",
      "         [9, 2, 7]],\n",
      "\n",
      "        [[4, 3, 5],\n",
      "         [9, 3, 4]]])\n",
      "data shape：torch.Size([2, 2, 3]), data :tensor([[[7, 1, 7],\n",
      "         [9, 2, 7]],\n",
      "\n",
      "        [[4, 3, 5],\n",
      "         [9, 3, 4]]])\n",
      "data shape：torch.Size([1, 4, 3]), data :tensor([[[7, 1, 7],\n",
      "         [9, 2, 7],\n",
      "         [4, 3, 5],\n",
      "         [9, 3, 4]]])\n",
      "data1 shape：torch.Size([2, 3]), data :tensor([[7, 1, 9],\n",
      "        [8, 1, 1]])\n",
      "data2 shape：torch.Size([2, 3]), data :tensor([[6, 8, 3],\n",
      "        [7, 8, 2]])\n",
      "在0维上stack shape：torch.Size([2, 2, 3]), data :tensor([[[7, 1, 9],\n",
      "         [8, 1, 1]],\n",
      "\n",
      "        [[6, 8, 3],\n",
      "         [7, 8, 2]]])\n",
      "在1维上stack shape：torch.Size([2, 2, 3]), data :tensor([[[7, 1, 9],\n",
      "         [6, 8, 3]],\n",
      "\n",
      "        [[8, 1, 1],\n",
      "         [7, 8, 2]]])\n",
      "在2维上stack shape：torch.Size([2, 3, 2]), data :tensor([[[7, 6],\n",
      "         [1, 8],\n",
      "         [9, 3]],\n",
      "\n",
      "        [[8, 7],\n",
      "         [1, 8],\n",
      "         [1, 2]]])\n"
     ]
    }
   ],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T10:52:59.783360Z",
     "start_time": "2025-03-23T10:52:59.773694Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "自动微分模块：\n",
    "概念：自动微分就是自动计算梯度值,也就是计算导数\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "def scalar_gradient_calculation():\n",
    "    '''\n",
    "    标量张量梯度计算\n",
    "    :return: \n",
    "    '''\n",
    "\n",
    "    # 1、定义一个标量张量(点)\n",
    "    x = torch.tensor(10, requires_grad=True, dtype=torch.float32)\n",
    "    print(f'x shape：{x.shape}, data :{x}')\n",
    "\n",
    "    # 2、定义一个曲线\n",
    "    y = 2 * x ** 2\n",
    "\n",
    "    # 3、计算x点的梯度\n",
    "    # 此时y是一个标量,可以不用使用y.sum()转换成标量\n",
    "    # y'|(x=10) = (2*x**2)'|(x=10) = 4x|(x=10) = 40\n",
    "    # y.sum().backward()\n",
    "    y.backward()\n",
    "    print(f'x梯度：{x.grad}')\n",
    "\n",
    "\n",
    "def vector_gradient_calculation():\n",
    "    '''\n",
    "    向量张量梯度计算\n",
    "    :return: \n",
    "    '''\n",
    "    # 1、定义一个向量张量(点)\n",
    "    x = torch.tensor([10, 20], requires_grad=True, dtype=torch.float32)\n",
    "    print(f'x shape：{x.shape}, data :{x}')\n",
    "\n",
    "    # 2、定义一个曲线\n",
    "    y = 2 * x ** 2\n",
    "\n",
    "    # 计算梯度\n",
    "    # x和y都是向量张量,不能进行求导,需要将y转换成标量张量-->y.sum()\n",
    "    # y'|(x=10) = (2*x**2)'|(x=10) = 4x|(x=10) = 40\n",
    "    # y'|(x=20) = (2*x**2)'|(x=20) = 4x|(x=20) = 80\n",
    "    # 3、计算x点的梯度\n",
    "    # y.backward()\n",
    "    y.sum().backward()\n",
    "    print(f'x梯度：{x.grad}')\n",
    "\n",
    "\n",
    "scalar_gradient_calculation()\n",
    "vector_gradient_calculation()"
   ],
   "id": "1e6a24252a77660c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape：torch.Size([]), data :10.0\n",
      "x梯度：40.0\n",
      "x shape：torch.Size([2]), data :tensor([10., 20.], requires_grad=True)\n",
      "x梯度：tensor([40., 80.])\n"
     ]
    }
   ],
   "execution_count": 111
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T11:11:47.604225Z",
     "start_time": "2025-03-23T11:11:47.451797Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    " 求 y = x**2 + 20 的极小值点 并打印y是最小值时 w的值(梯度)\n",
    " 1 定义点 x=10 requires_grad=True  dtype=torch.float32\n",
    " 2 定义函数 y = x**2 + 20\n",
    " 3 利用梯度下降法 循环迭代1000 求最优解\n",
    " 3-1 正向计算(前向传播)\n",
    " 3-2 梯度清零 x.grad.zero_()\n",
    " 3-3 反向传播\n",
    " 3-4 梯度更新 x.data = x.data - 0.01 * x.grad\n",
    "'''\n",
    "\n",
    "\n",
    "def gradient_descent_calculation():\n",
    "    # 1 定义点x=10 requires_grad=True  dtype=torch.float32\n",
    "    x = torch.tensor(10, requires_grad=True, dtype=torch.float32)\n",
    "\n",
    "    # 2 定义函数 y = x ** 2 + 20\n",
    "    y = x ** 2 + 20\n",
    "    print('开始 权重x初始值:%.6f (0.01 * x.grad):无 y:%.6f' % (x, y))\n",
    "\n",
    "    # 3 利用梯度下降法 循环迭代1000 求最优解\n",
    "    for i in range(1, 1001):\n",
    "    \n",
    "        # 3-1 正向计算(前向传播)\n",
    "        y = x ** 2 + 20\n",
    "    \n",
    "        # 3-2 梯度清零 x.grad.zero_()\n",
    "        # 默认张量的 grad 属性会累加历史梯度值 需手工清零上一次的提取\n",
    "        # 一开始梯度不存在, 需要做判断\n",
    "        if x.grad is not None:\n",
    "            x.grad.zero_()\n",
    "    \n",
    "        # 3-3 反向传播\n",
    "        y.sum().backward()\n",
    "    \n",
    "        # 3-4 梯度更新 x.data = x.data - 0.01 * x.grad\n",
    "        # x.data是修改原始x内存中的数据,前后x的内存空间一样;如果使用x,此时修改前后x的内存空间不同\n",
    "        x.data = x.data - 0.01 * x.grad  # 注：不能 x = x - 0.01 * x.grad 这样写\n",
    "    \n",
    "        print('次数:%d 权重x: %.6f, (0.01 * x.grad):%.6f y:%.6f' % (i, x, 0.01 * x.grad, y))\n",
    "    print('x：', x, x.grad, 'y最小值', y)\n",
    "\n",
    "\n",
    "def gradient_descent_calculation_error():\n",
    "    '''\n",
    "    不能将自动微分的张量转换成numpy数组，会发生报错，可以通过detach()方法实现\n",
    "    :return: \n",
    "    '''\n",
    "    # 定义一个张量\n",
    "    x1 = torch.tensor([10, 20], requires_grad=True, dtype=torch.float64)\n",
    "\n",
    "    # 将x张量转换成numpy数组\n",
    "    # 发生报错,RuntimeError: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n",
    "    # 不能将自动微分的张量转换成numpy数组\n",
    "    # print(x1.numpy())\n",
    "\n",
    "    # 通过detach()方法产生一个新的张量,作为叶子结点\n",
    "    x2 = x1.detach()\n",
    "    # x1和x2张量共享数据,但是x2不会自动微分\n",
    "    print(x1.requires_grad)\n",
    "    print(x2.requires_grad)\n",
    "    # x1和x2张量的值一样,共用一份内存空间的数据\n",
    "    print(x1.data)\n",
    "    print(x2.data)\n",
    "    print(id(x1.data))\n",
    "    print(id(x2.data))\n",
    "\n",
    "    # 将x2张量转换成numpy数组\n",
    "    print(x2.detach())\n",
    "    # print(x2.numpy())\n",
    "\n",
    "gradient_descent_calculation()\n",
    "\n",
    "gradient_descent_calculation_error()\n"
   ],
   "id": "99dab4d56226efc5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始 权重x初始值:10.000000 (0.01 * x.grad):无 y:120.000000\n",
      "次数:1 权重x: 9.800000, (0.01 * x.grad):0.200000 y:120.000000\n",
      "次数:2 权重x: 9.604000, (0.01 * x.grad):0.196000 y:116.040001\n",
      "次数:3 权重x: 9.411921, (0.01 * x.grad):0.192080 y:112.236816\n",
      "次数:4 权重x: 9.223682, (0.01 * x.grad):0.188238 y:108.584251\n",
      "次数:5 权重x: 9.039208, (0.01 * x.grad):0.184474 y:105.076317\n",
      "次数:6 权重x: 8.858424, (0.01 * x.grad):0.180784 y:101.707291\n",
      "次数:7 权重x: 8.681255, (0.01 * x.grad):0.177168 y:98.471680\n",
      "次数:8 权重x: 8.507630, (0.01 * x.grad):0.173625 y:95.364197\n",
      "次数:9 权重x: 8.337478, (0.01 * x.grad):0.170153 y:92.379776\n",
      "次数:10 权重x: 8.170728, (0.01 * x.grad):0.166750 y:89.513535\n",
      "次数:11 权重x: 8.007313, (0.01 * x.grad):0.163415 y:86.760788\n",
      "次数:12 权重x: 7.847167, (0.01 * x.grad):0.160146 y:84.117058\n",
      "次数:13 权重x: 7.690223, (0.01 * x.grad):0.156943 y:81.578018\n",
      "次数:14 权重x: 7.536419, (0.01 * x.grad):0.153804 y:79.139534\n",
      "次数:15 权重x: 7.385691, (0.01 * x.grad):0.150728 y:76.797607\n",
      "次数:16 权重x: 7.237977, (0.01 * x.grad):0.147714 y:74.548431\n",
      "次数:17 权重x: 7.093217, (0.01 * x.grad):0.144760 y:72.388313\n",
      "次数:18 权重x: 6.951353, (0.01 * x.grad):0.141864 y:70.313736\n",
      "次数:19 权重x: 6.812326, (0.01 * x.grad):0.139027 y:68.321304\n",
      "次数:20 权重x: 6.676079, (0.01 * x.grad):0.136247 y:66.407784\n",
      "次数:21 权重x: 6.542558, (0.01 * x.grad):0.133522 y:64.570038\n",
      "次数:22 权重x: 6.411706, (0.01 * x.grad):0.130851 y:62.805061\n",
      "次数:23 权重x: 6.283473, (0.01 * x.grad):0.128234 y:61.109978\n",
      "次数:24 权重x: 6.157803, (0.01 * x.grad):0.125669 y:59.482029\n",
      "次数:25 权重x: 6.034647, (0.01 * x.grad):0.123156 y:57.918537\n",
      "次数:26 权重x: 5.913954, (0.01 * x.grad):0.120693 y:56.416965\n",
      "次数:27 权重x: 5.795675, (0.01 * x.grad):0.118279 y:54.974854\n",
      "次数:28 权重x: 5.679762, (0.01 * x.grad):0.115914 y:53.589851\n",
      "次数:29 权重x: 5.566167, (0.01 * x.grad):0.113595 y:52.259697\n",
      "次数:30 权重x: 5.454844, (0.01 * x.grad):0.111323 y:50.982216\n",
      "次数:31 权重x: 5.345747, (0.01 * x.grad):0.109097 y:49.755318\n",
      "次数:32 权重x: 5.238832, (0.01 * x.grad):0.106915 y:48.577003\n",
      "次数:33 权重x: 5.134055, (0.01 * x.grad):0.104777 y:47.445358\n",
      "次数:34 权重x: 5.031374, (0.01 * x.grad):0.102681 y:46.358517\n",
      "次数:35 权重x: 4.930746, (0.01 * x.grad):0.100627 y:45.314720\n",
      "次数:36 权重x: 4.832131, (0.01 * x.grad):0.098615 y:44.312256\n",
      "次数:37 权重x: 4.735489, (0.01 * x.grad):0.096643 y:43.349495\n",
      "次数:38 权重x: 4.640779, (0.01 * x.grad):0.094710 y:42.424854\n",
      "次数:39 权重x: 4.547964, (0.01 * x.grad):0.092816 y:41.536827\n",
      "次数:40 权重x: 4.457005, (0.01 * x.grad):0.090959 y:40.683975\n",
      "次数:41 权重x: 4.367865, (0.01 * x.grad):0.089140 y:39.864891\n",
      "次数:42 权重x: 4.280507, (0.01 * x.grad):0.087357 y:39.078239\n",
      "次数:43 权重x: 4.194897, (0.01 * x.grad):0.085610 y:38.322739\n",
      "次数:44 权重x: 4.110999, (0.01 * x.grad):0.083898 y:37.597160\n",
      "次数:45 权重x: 4.028779, (0.01 * x.grad):0.082220 y:36.900314\n",
      "次数:46 权重x: 3.948204, (0.01 * x.grad):0.080576 y:36.231060\n",
      "次数:47 权重x: 3.869240, (0.01 * x.grad):0.078964 y:35.588310\n",
      "次数:48 权重x: 3.791855, (0.01 * x.grad):0.077385 y:34.971016\n",
      "次数:49 权重x: 3.716018, (0.01 * x.grad):0.075837 y:34.378162\n",
      "次数:50 权重x: 3.641697, (0.01 * x.grad):0.074320 y:33.808788\n",
      "次数:51 权重x: 3.568863, (0.01 * x.grad):0.072834 y:33.261959\n",
      "次数:52 权重x: 3.497486, (0.01 * x.grad):0.071377 y:32.736786\n",
      "次数:53 权重x: 3.427536, (0.01 * x.grad):0.069950 y:32.232410\n",
      "次数:54 权重x: 3.358986, (0.01 * x.grad):0.068551 y:31.748007\n",
      "次数:55 权重x: 3.291806, (0.01 * x.grad):0.067180 y:31.282784\n",
      "次数:56 权重x: 3.225970, (0.01 * x.grad):0.065836 y:30.835987\n",
      "次数:57 权重x: 3.161450, (0.01 * x.grad):0.064519 y:30.406881\n",
      "次数:58 权重x: 3.098221, (0.01 * x.grad):0.063229 y:29.994768\n",
      "次数:59 权重x: 3.036257, (0.01 * x.grad):0.061964 y:29.598976\n",
      "次数:60 权重x: 2.975532, (0.01 * x.grad):0.060725 y:29.218855\n",
      "次数:61 权重x: 2.916021, (0.01 * x.grad):0.059511 y:28.853788\n",
      "次数:62 权重x: 2.857700, (0.01 * x.grad):0.058320 y:28.503178\n",
      "次数:63 权重x: 2.800546, (0.01 * x.grad):0.057154 y:28.166451\n",
      "次数:64 权重x: 2.744535, (0.01 * x.grad):0.056011 y:27.843060\n",
      "次数:65 权重x: 2.689645, (0.01 * x.grad):0.054891 y:27.532475\n",
      "次数:66 权重x: 2.635852, (0.01 * x.grad):0.053793 y:27.234188\n",
      "次数:67 权重x: 2.583135, (0.01 * x.grad):0.052717 y:26.947716\n",
      "次数:68 权重x: 2.531472, (0.01 * x.grad):0.051663 y:26.672586\n",
      "次数:69 权重x: 2.480843, (0.01 * x.grad):0.050629 y:26.408352\n",
      "次数:70 权重x: 2.431226, (0.01 * x.grad):0.049617 y:26.154581\n",
      "次数:71 权重x: 2.382601, (0.01 * x.grad):0.048625 y:25.910860\n",
      "次数:72 权重x: 2.334949, (0.01 * x.grad):0.047652 y:25.676790\n",
      "次数:73 权重x: 2.288250, (0.01 * x.grad):0.046699 y:25.451988\n",
      "次数:74 权重x: 2.242486, (0.01 * x.grad):0.045765 y:25.236090\n",
      "次数:75 权重x: 2.197636, (0.01 * x.grad):0.044850 y:25.028742\n",
      "次数:76 权重x: 2.153683, (0.01 * x.grad):0.043953 y:24.829603\n",
      "次数:77 权重x: 2.110610, (0.01 * x.grad):0.043074 y:24.638351\n",
      "次数:78 权重x: 2.068397, (0.01 * x.grad):0.042212 y:24.454674\n",
      "次数:79 权重x: 2.027029, (0.01 * x.grad):0.041368 y:24.278267\n",
      "次数:80 权重x: 1.986489, (0.01 * x.grad):0.040541 y:24.108849\n",
      "次数:81 权重x: 1.946759, (0.01 * x.grad):0.039730 y:23.946136\n",
      "次数:82 权重x: 1.907824, (0.01 * x.grad):0.038935 y:23.789871\n",
      "次数:83 权重x: 1.869667, (0.01 * x.grad):0.038156 y:23.639791\n",
      "次数:84 权重x: 1.832274, (0.01 * x.grad):0.037393 y:23.495655\n",
      "次数:85 权重x: 1.795628, (0.01 * x.grad):0.036645 y:23.357227\n",
      "次数:86 权重x: 1.759716, (0.01 * x.grad):0.035913 y:23.224281\n",
      "次数:87 权重x: 1.724522, (0.01 * x.grad):0.035194 y:23.096600\n",
      "次数:88 权重x: 1.690031, (0.01 * x.grad):0.034490 y:22.973974\n",
      "次数:89 权重x: 1.656231, (0.01 * x.grad):0.033801 y:22.856205\n",
      "次数:90 权重x: 1.623106, (0.01 * x.grad):0.033125 y:22.743099\n",
      "次数:91 权重x: 1.590644, (0.01 * x.grad):0.032462 y:22.634474\n",
      "次数:92 权重x: 1.558831, (0.01 * x.grad):0.031813 y:22.530148\n",
      "次数:93 权重x: 1.527654, (0.01 * x.grad):0.031177 y:22.429955\n",
      "次数:94 权重x: 1.497101, (0.01 * x.grad):0.030553 y:22.333729\n",
      "次数:95 权重x: 1.467159, (0.01 * x.grad):0.029942 y:22.241312\n",
      "次数:96 权重x: 1.437816, (0.01 * x.grad):0.029343 y:22.152557\n",
      "次数:97 权重x: 1.409060, (0.01 * x.grad):0.028756 y:22.067316\n",
      "次数:98 权重x: 1.380879, (0.01 * x.grad):0.028181 y:21.985449\n",
      "次数:99 权重x: 1.353261, (0.01 * x.grad):0.027618 y:21.906826\n",
      "次数:100 权重x: 1.326196, (0.01 * x.grad):0.027065 y:21.831316\n",
      "次数:101 权重x: 1.299672, (0.01 * x.grad):0.026524 y:21.758795\n",
      "次数:102 权重x: 1.273678, (0.01 * x.grad):0.025993 y:21.689146\n",
      "次数:103 权重x: 1.248205, (0.01 * x.grad):0.025474 y:21.622257\n",
      "次数:104 权重x: 1.223241, (0.01 * x.grad):0.024964 y:21.558016\n",
      "次数:105 权重x: 1.198776, (0.01 * x.grad):0.024465 y:21.496317\n",
      "次数:106 权重x: 1.174800, (0.01 * x.grad):0.023976 y:21.437063\n",
      "次数:107 权重x: 1.151304, (0.01 * x.grad):0.023496 y:21.380156\n",
      "次数:108 权重x: 1.128278, (0.01 * x.grad):0.023026 y:21.325500\n",
      "次数:109 权重x: 1.105713, (0.01 * x.grad):0.022566 y:21.273012\n",
      "次数:110 权重x: 1.083598, (0.01 * x.grad):0.022114 y:21.222601\n",
      "次数:111 权重x: 1.061926, (0.01 * x.grad):0.021672 y:21.174185\n",
      "次数:112 权重x: 1.040688, (0.01 * x.grad):0.021239 y:21.127687\n",
      "次数:113 权重x: 1.019874, (0.01 * x.grad):0.020814 y:21.083031\n",
      "次数:114 权重x: 0.999476, (0.01 * x.grad):0.020397 y:21.040142\n",
      "次数:115 权重x: 0.979487, (0.01 * x.grad):0.019990 y:20.998953\n",
      "次数:116 权重x: 0.959897, (0.01 * x.grad):0.019590 y:20.959394\n",
      "次数:117 权重x: 0.940699, (0.01 * x.grad):0.019198 y:20.921402\n",
      "次数:118 权重x: 0.921885, (0.01 * x.grad):0.018814 y:20.884914\n",
      "次数:119 权重x: 0.903448, (0.01 * x.grad):0.018438 y:20.849873\n",
      "次数:120 权重x: 0.885379, (0.01 * x.grad):0.018069 y:20.816217\n",
      "次数:121 权重x: 0.867671, (0.01 * x.grad):0.017708 y:20.783895\n",
      "次数:122 权重x: 0.850318, (0.01 * x.grad):0.017353 y:20.752853\n",
      "次数:123 权重x: 0.833311, (0.01 * x.grad):0.017006 y:20.723040\n",
      "次数:124 权重x: 0.816645, (0.01 * x.grad):0.016666 y:20.694408\n",
      "次数:125 权重x: 0.800312, (0.01 * x.grad):0.016333 y:20.666908\n",
      "次数:126 权重x: 0.784306, (0.01 * x.grad):0.016006 y:20.640499\n",
      "次数:127 权重x: 0.768620, (0.01 * x.grad):0.015686 y:20.615135\n",
      "次数:128 权重x: 0.753247, (0.01 * x.grad):0.015372 y:20.590776\n",
      "次数:129 权重x: 0.738182, (0.01 * x.grad):0.015065 y:20.567381\n",
      "次数:130 权重x: 0.723419, (0.01 * x.grad):0.014764 y:20.544914\n",
      "次数:131 权重x: 0.708950, (0.01 * x.grad):0.014468 y:20.523335\n",
      "次数:132 权重x: 0.694771, (0.01 * x.grad):0.014179 y:20.502611\n",
      "次数:133 权重x: 0.680876, (0.01 * x.grad):0.013895 y:20.482708\n",
      "次数:134 权重x: 0.667259, (0.01 * x.grad):0.013618 y:20.463593\n",
      "次数:135 权重x: 0.653913, (0.01 * x.grad):0.013345 y:20.445234\n",
      "次数:136 权重x: 0.640835, (0.01 * x.grad):0.013078 y:20.427603\n",
      "次数:137 权重x: 0.628018, (0.01 * x.grad):0.012817 y:20.410669\n",
      "次数:138 权重x: 0.615458, (0.01 * x.grad):0.012560 y:20.394407\n",
      "次数:139 权重x: 0.603149, (0.01 * x.grad):0.012309 y:20.378788\n",
      "次数:140 权重x: 0.591086, (0.01 * x.grad):0.012063 y:20.363789\n",
      "次数:141 权重x: 0.579264, (0.01 * x.grad):0.011822 y:20.349382\n",
      "次数:142 权重x: 0.567679, (0.01 * x.grad):0.011585 y:20.335546\n",
      "次数:143 权重x: 0.556325, (0.01 * x.grad):0.011354 y:20.322260\n",
      "次数:144 权重x: 0.545199, (0.01 * x.grad):0.011127 y:20.309498\n",
      "次数:145 权重x: 0.534295, (0.01 * x.grad):0.010904 y:20.297241\n",
      "次数:146 权重x: 0.523609, (0.01 * x.grad):0.010686 y:20.285471\n",
      "次数:147 权重x: 0.513137, (0.01 * x.grad):0.010472 y:20.274166\n",
      "次数:148 权重x: 0.502874, (0.01 * x.grad):0.010263 y:20.263309\n",
      "次数:149 权重x: 0.492817, (0.01 * x.grad):0.010057 y:20.252882\n",
      "次数:150 权重x: 0.482960, (0.01 * x.grad):0.009856 y:20.242868\n",
      "次数:151 权重x: 0.473301, (0.01 * x.grad):0.009659 y:20.233250\n",
      "次数:152 权重x: 0.463835, (0.01 * x.grad):0.009466 y:20.224014\n",
      "次数:153 权重x: 0.454558, (0.01 * x.grad):0.009277 y:20.215143\n",
      "次数:154 权重x: 0.445467, (0.01 * x.grad):0.009091 y:20.206623\n",
      "次数:155 权重x: 0.436558, (0.01 * x.grad):0.008909 y:20.198441\n",
      "次数:156 权重x: 0.427827, (0.01 * x.grad):0.008731 y:20.190582\n",
      "次数:157 权重x: 0.419270, (0.01 * x.grad):0.008557 y:20.183035\n",
      "次数:158 权重x: 0.410885, (0.01 * x.grad):0.008385 y:20.175787\n",
      "次数:159 权重x: 0.402667, (0.01 * x.grad):0.008218 y:20.168827\n",
      "次数:160 权重x: 0.394614, (0.01 * x.grad):0.008053 y:20.162140\n",
      "次数:161 权重x: 0.386721, (0.01 * x.grad):0.007892 y:20.155720\n",
      "次数:162 权重x: 0.378987, (0.01 * x.grad):0.007734 y:20.149553\n",
      "次数:163 权重x: 0.371407, (0.01 * x.grad):0.007580 y:20.143631\n",
      "次数:164 权重x: 0.363979, (0.01 * x.grad):0.007428 y:20.137943\n",
      "次数:165 权重x: 0.356699, (0.01 * x.grad):0.007280 y:20.132481\n",
      "次数:166 权重x: 0.349566, (0.01 * x.grad):0.007134 y:20.127235\n",
      "次数:167 权重x: 0.342574, (0.01 * x.grad):0.006991 y:20.122196\n",
      "次数:168 权重x: 0.335723, (0.01 * x.grad):0.006851 y:20.117357\n",
      "次数:169 权重x: 0.329008, (0.01 * x.grad):0.006714 y:20.112709\n",
      "次数:170 权重x: 0.322428, (0.01 * x.grad):0.006580 y:20.108246\n",
      "次数:171 权重x: 0.315980, (0.01 * x.grad):0.006449 y:20.103960\n",
      "次数:172 权重x: 0.309660, (0.01 * x.grad):0.006320 y:20.099844\n",
      "次数:173 权重x: 0.303467, (0.01 * x.grad):0.006193 y:20.095890\n",
      "次数:174 权重x: 0.297397, (0.01 * x.grad):0.006069 y:20.092093\n",
      "次数:175 权重x: 0.291449, (0.01 * x.grad):0.005948 y:20.088446\n",
      "次数:176 权重x: 0.285620, (0.01 * x.grad):0.005829 y:20.084942\n",
      "次数:177 权重x: 0.279908, (0.01 * x.grad):0.005712 y:20.081579\n",
      "次数:178 权重x: 0.274310, (0.01 * x.grad):0.005598 y:20.078348\n",
      "次数:179 权重x: 0.268824, (0.01 * x.grad):0.005486 y:20.075247\n",
      "次数:180 权重x: 0.263447, (0.01 * x.grad):0.005376 y:20.072266\n",
      "次数:181 权重x: 0.258178, (0.01 * x.grad):0.005269 y:20.069405\n",
      "次数:182 权重x: 0.253015, (0.01 * x.grad):0.005164 y:20.066656\n",
      "次数:183 权重x: 0.247954, (0.01 * x.grad):0.005060 y:20.064016\n",
      "次数:184 权重x: 0.242995, (0.01 * x.grad):0.004959 y:20.061481\n",
      "次数:185 权重x: 0.238135, (0.01 * x.grad):0.004860 y:20.059046\n",
      "次数:186 权重x: 0.233373, (0.01 * x.grad):0.004763 y:20.056709\n",
      "次数:187 权重x: 0.228705, (0.01 * x.grad):0.004667 y:20.054462\n",
      "次数:188 权重x: 0.224131, (0.01 * x.grad):0.004574 y:20.052305\n",
      "次数:189 权重x: 0.219649, (0.01 * x.grad):0.004483 y:20.050234\n",
      "次数:190 权重x: 0.215256, (0.01 * x.grad):0.004393 y:20.048246\n",
      "次数:191 权重x: 0.210950, (0.01 * x.grad):0.004305 y:20.046335\n",
      "次数:192 权重x: 0.206731, (0.01 * x.grad):0.004219 y:20.044500\n",
      "次数:193 权重x: 0.202597, (0.01 * x.grad):0.004135 y:20.042738\n",
      "次数:194 权重x: 0.198545, (0.01 * x.grad):0.004052 y:20.041046\n",
      "次数:195 权重x: 0.194574, (0.01 * x.grad):0.003971 y:20.039419\n",
      "次数:196 权重x: 0.190682, (0.01 * x.grad):0.003891 y:20.037859\n",
      "次数:197 权重x: 0.186869, (0.01 * x.grad):0.003814 y:20.036360\n",
      "次数:198 权重x: 0.183131, (0.01 * x.grad):0.003737 y:20.034920\n",
      "次数:199 权重x: 0.179469, (0.01 * x.grad):0.003663 y:20.033537\n",
      "次数:200 权重x: 0.175879, (0.01 * x.grad):0.003589 y:20.032209\n",
      "次数:201 权重x: 0.172362, (0.01 * x.grad):0.003518 y:20.030933\n",
      "次数:202 权重x: 0.168915, (0.01 * x.grad):0.003447 y:20.029709\n",
      "次数:203 权重x: 0.165536, (0.01 * x.grad):0.003378 y:20.028532\n",
      "次数:204 权重x: 0.162226, (0.01 * x.grad):0.003311 y:20.027403\n",
      "次数:205 权重x: 0.158981, (0.01 * x.grad):0.003245 y:20.026318\n",
      "次数:206 权重x: 0.155801, (0.01 * x.grad):0.003180 y:20.025274\n",
      "次数:207 权重x: 0.152685, (0.01 * x.grad):0.003116 y:20.024275\n",
      "次数:208 权重x: 0.149632, (0.01 * x.grad):0.003054 y:20.023314\n",
      "次数:209 权重x: 0.146639, (0.01 * x.grad):0.002993 y:20.022390\n",
      "次数:210 权重x: 0.143706, (0.01 * x.grad):0.002933 y:20.021503\n",
      "次数:211 权重x: 0.140832, (0.01 * x.grad):0.002874 y:20.020651\n",
      "次数:212 权重x: 0.138016, (0.01 * x.grad):0.002817 y:20.019835\n",
      "次数:213 权重x: 0.135255, (0.01 * x.grad):0.002760 y:20.019049\n",
      "次数:214 权重x: 0.132550, (0.01 * x.grad):0.002705 y:20.018293\n",
      "次数:215 权重x: 0.129899, (0.01 * x.grad):0.002651 y:20.017569\n",
      "次数:216 权重x: 0.127301, (0.01 * x.grad):0.002598 y:20.016874\n",
      "次数:217 权重x: 0.124755, (0.01 * x.grad):0.002546 y:20.016205\n",
      "次数:218 权重x: 0.122260, (0.01 * x.grad):0.002495 y:20.015564\n",
      "次数:219 权重x: 0.119815, (0.01 * x.grad):0.002445 y:20.014948\n",
      "次数:220 权重x: 0.117419, (0.01 * x.grad):0.002396 y:20.014355\n",
      "次数:221 权重x: 0.115070, (0.01 * x.grad):0.002348 y:20.013786\n",
      "次数:222 权重x: 0.112769, (0.01 * x.grad):0.002301 y:20.013241\n",
      "次数:223 权重x: 0.110513, (0.01 * x.grad):0.002255 y:20.012716\n",
      "次数:224 权重x: 0.108303, (0.01 * x.grad):0.002210 y:20.012213\n",
      "次数:225 权重x: 0.106137, (0.01 * x.grad):0.002166 y:20.011730\n",
      "次数:226 权重x: 0.104014, (0.01 * x.grad):0.002123 y:20.011265\n",
      "次数:227 权重x: 0.101934, (0.01 * x.grad):0.002080 y:20.010818\n",
      "次数:228 权重x: 0.099895, (0.01 * x.grad):0.002039 y:20.010391\n",
      "次数:229 权重x: 0.097897, (0.01 * x.grad):0.001998 y:20.009979\n",
      "次数:230 权重x: 0.095939, (0.01 * x.grad):0.001958 y:20.009584\n",
      "次数:231 权重x: 0.094021, (0.01 * x.grad):0.001919 y:20.009205\n",
      "次数:232 权重x: 0.092140, (0.01 * x.grad):0.001880 y:20.008841\n",
      "次数:233 权重x: 0.090297, (0.01 * x.grad):0.001843 y:20.008490\n",
      "次数:234 权重x: 0.088492, (0.01 * x.grad):0.001806 y:20.008154\n",
      "次数:235 权重x: 0.086722, (0.01 * x.grad):0.001770 y:20.007832\n",
      "次数:236 权重x: 0.084987, (0.01 * x.grad):0.001734 y:20.007521\n",
      "次数:237 权重x: 0.083288, (0.01 * x.grad):0.001700 y:20.007223\n",
      "次数:238 权重x: 0.081622, (0.01 * x.grad):0.001666 y:20.006937\n",
      "次数:239 权重x: 0.079989, (0.01 * x.grad):0.001632 y:20.006662\n",
      "次数:240 权重x: 0.078390, (0.01 * x.grad):0.001600 y:20.006399\n",
      "次数:241 权重x: 0.076822, (0.01 * x.grad):0.001568 y:20.006145\n",
      "次数:242 权重x: 0.075285, (0.01 * x.grad):0.001536 y:20.005901\n",
      "次数:243 权重x: 0.073780, (0.01 * x.grad):0.001506 y:20.005669\n",
      "次数:244 权重x: 0.072304, (0.01 * x.grad):0.001476 y:20.005444\n",
      "次数:245 权重x: 0.070858, (0.01 * x.grad):0.001446 y:20.005228\n",
      "次数:246 权重x: 0.069441, (0.01 * x.grad):0.001417 y:20.005020\n",
      "次数:247 权重x: 0.068052, (0.01 * x.grad):0.001389 y:20.004822\n",
      "次数:248 权重x: 0.066691, (0.01 * x.grad):0.001361 y:20.004631\n",
      "次数:249 权重x: 0.065357, (0.01 * x.grad):0.001334 y:20.004448\n",
      "次数:250 权重x: 0.064050, (0.01 * x.grad):0.001307 y:20.004272\n",
      "次数:251 权重x: 0.062769, (0.01 * x.grad):0.001281 y:20.004103\n",
      "次数:252 权重x: 0.061514, (0.01 * x.grad):0.001255 y:20.003941\n",
      "次数:253 权重x: 0.060283, (0.01 * x.grad):0.001230 y:20.003784\n",
      "次数:254 权重x: 0.059078, (0.01 * x.grad):0.001206 y:20.003633\n",
      "次数:255 权重x: 0.057896, (0.01 * x.grad):0.001182 y:20.003490\n",
      "次数:256 权重x: 0.056738, (0.01 * x.grad):0.001158 y:20.003351\n",
      "次数:257 权重x: 0.055603, (0.01 * x.grad):0.001135 y:20.003220\n",
      "次数:258 权重x: 0.054491, (0.01 * x.grad):0.001112 y:20.003092\n",
      "次数:259 权重x: 0.053402, (0.01 * x.grad):0.001090 y:20.002970\n",
      "次数:260 权重x: 0.052333, (0.01 * x.grad):0.001068 y:20.002851\n",
      "次数:261 权重x: 0.051287, (0.01 * x.grad):0.001047 y:20.002739\n",
      "次数:262 权重x: 0.050261, (0.01 * x.grad):0.001026 y:20.002630\n",
      "次数:263 权重x: 0.049256, (0.01 * x.grad):0.001005 y:20.002525\n",
      "次数:264 权重x: 0.048271, (0.01 * x.grad):0.000985 y:20.002426\n",
      "次数:265 权重x: 0.047305, (0.01 * x.grad):0.000965 y:20.002331\n",
      "次数:266 权重x: 0.046359, (0.01 * x.grad):0.000946 y:20.002237\n",
      "次数:267 权重x: 0.045432, (0.01 * x.grad):0.000927 y:20.002150\n",
      "次数:268 权重x: 0.044523, (0.01 * x.grad):0.000909 y:20.002064\n",
      "次数:269 权重x: 0.043633, (0.01 * x.grad):0.000890 y:20.001982\n",
      "次数:270 权重x: 0.042760, (0.01 * x.grad):0.000873 y:20.001904\n",
      "次数:271 权重x: 0.041905, (0.01 * x.grad):0.000855 y:20.001829\n",
      "次数:272 权重x: 0.041067, (0.01 * x.grad):0.000838 y:20.001757\n",
      "次数:273 权重x: 0.040246, (0.01 * x.grad):0.000821 y:20.001686\n",
      "次数:274 权重x: 0.039441, (0.01 * x.grad):0.000805 y:20.001619\n",
      "次数:275 权重x: 0.038652, (0.01 * x.grad):0.000789 y:20.001556\n",
      "次数:276 权重x: 0.037879, (0.01 * x.grad):0.000773 y:20.001493\n",
      "次数:277 权重x: 0.037121, (0.01 * x.grad):0.000758 y:20.001434\n",
      "次数:278 权重x: 0.036379, (0.01 * x.grad):0.000742 y:20.001377\n",
      "次数:279 权重x: 0.035651, (0.01 * x.grad):0.000728 y:20.001324\n",
      "次数:280 权重x: 0.034938, (0.01 * x.grad):0.000713 y:20.001270\n",
      "次数:281 权重x: 0.034239, (0.01 * x.grad):0.000699 y:20.001221\n",
      "次数:282 权重x: 0.033555, (0.01 * x.grad):0.000685 y:20.001173\n",
      "次数:283 权重x: 0.032884, (0.01 * x.grad):0.000671 y:20.001125\n",
      "次数:284 权重x: 0.032226, (0.01 * x.grad):0.000658 y:20.001081\n",
      "次数:285 权重x: 0.031581, (0.01 * x.grad):0.000645 y:20.001038\n",
      "次数:286 权重x: 0.030950, (0.01 * x.grad):0.000632 y:20.000998\n",
      "次数:287 权重x: 0.030331, (0.01 * x.grad):0.000619 y:20.000957\n",
      "次数:288 权重x: 0.029724, (0.01 * x.grad):0.000607 y:20.000919\n",
      "次数:289 权重x: 0.029130, (0.01 * x.grad):0.000594 y:20.000883\n",
      "次数:290 权重x: 0.028547, (0.01 * x.grad):0.000583 y:20.000849\n",
      "次数:291 权重x: 0.027976, (0.01 * x.grad):0.000571 y:20.000814\n",
      "次数:292 权重x: 0.027417, (0.01 * x.grad):0.000560 y:20.000782\n",
      "次数:293 权重x: 0.026868, (0.01 * x.grad):0.000548 y:20.000751\n",
      "次数:294 权重x: 0.026331, (0.01 * x.grad):0.000537 y:20.000721\n",
      "次数:295 权重x: 0.025804, (0.01 * x.grad):0.000527 y:20.000692\n",
      "次数:296 权重x: 0.025288, (0.01 * x.grad):0.000516 y:20.000666\n",
      "次数:297 权重x: 0.024782, (0.01 * x.grad):0.000506 y:20.000639\n",
      "次数:298 权重x: 0.024287, (0.01 * x.grad):0.000496 y:20.000614\n",
      "次数:299 权重x: 0.023801, (0.01 * x.grad):0.000486 y:20.000589\n",
      "次数:300 权重x: 0.023325, (0.01 * x.grad):0.000476 y:20.000566\n",
      "次数:301 权重x: 0.022859, (0.01 * x.grad):0.000467 y:20.000544\n",
      "次数:302 权重x: 0.022401, (0.01 * x.grad):0.000457 y:20.000523\n",
      "次数:303 权重x: 0.021953, (0.01 * x.grad):0.000448 y:20.000502\n",
      "次数:304 权重x: 0.021514, (0.01 * x.grad):0.000439 y:20.000483\n",
      "次数:305 权重x: 0.021084, (0.01 * x.grad):0.000430 y:20.000463\n",
      "次数:306 权重x: 0.020662, (0.01 * x.grad):0.000422 y:20.000444\n",
      "次数:307 权重x: 0.020249, (0.01 * x.grad):0.000413 y:20.000427\n",
      "次数:308 权重x: 0.019844, (0.01 * x.grad):0.000405 y:20.000410\n",
      "次数:309 权重x: 0.019447, (0.01 * x.grad):0.000397 y:20.000393\n",
      "次数:310 权重x: 0.019058, (0.01 * x.grad):0.000389 y:20.000378\n",
      "次数:311 权重x: 0.018677, (0.01 * x.grad):0.000381 y:20.000362\n",
      "次数:312 权重x: 0.018304, (0.01 * x.grad):0.000374 y:20.000349\n",
      "次数:313 权重x: 0.017937, (0.01 * x.grad):0.000366 y:20.000336\n",
      "次数:314 权重x: 0.017579, (0.01 * x.grad):0.000359 y:20.000322\n",
      "次数:315 权重x: 0.017227, (0.01 * x.grad):0.000352 y:20.000309\n",
      "次数:316 权重x: 0.016883, (0.01 * x.grad):0.000345 y:20.000298\n",
      "次数:317 权重x: 0.016545, (0.01 * x.grad):0.000338 y:20.000284\n",
      "次数:318 权重x: 0.016214, (0.01 * x.grad):0.000331 y:20.000275\n",
      "次数:319 权重x: 0.015890, (0.01 * x.grad):0.000324 y:20.000263\n",
      "次数:320 权重x: 0.015572, (0.01 * x.grad):0.000318 y:20.000252\n",
      "次数:321 权重x: 0.015261, (0.01 * x.grad):0.000311 y:20.000242\n",
      "次数:322 权重x: 0.014955, (0.01 * x.grad):0.000305 y:20.000233\n",
      "次数:323 权重x: 0.014656, (0.01 * x.grad):0.000299 y:20.000223\n",
      "次数:324 权重x: 0.014363, (0.01 * x.grad):0.000293 y:20.000216\n",
      "次数:325 权重x: 0.014076, (0.01 * x.grad):0.000287 y:20.000206\n",
      "次数:326 权重x: 0.013794, (0.01 * x.grad):0.000282 y:20.000198\n",
      "次数:327 权重x: 0.013518, (0.01 * x.grad):0.000276 y:20.000191\n",
      "次数:328 权重x: 0.013248, (0.01 * x.grad):0.000270 y:20.000183\n",
      "次数:329 权重x: 0.012983, (0.01 * x.grad):0.000265 y:20.000175\n",
      "次数:330 权重x: 0.012723, (0.01 * x.grad):0.000260 y:20.000168\n",
      "次数:331 权重x: 0.012469, (0.01 * x.grad):0.000254 y:20.000162\n",
      "次数:332 权重x: 0.012220, (0.01 * x.grad):0.000249 y:20.000156\n",
      "次数:333 权重x: 0.011975, (0.01 * x.grad):0.000244 y:20.000149\n",
      "次数:334 权重x: 0.011736, (0.01 * x.grad):0.000240 y:20.000143\n",
      "次数:335 权重x: 0.011501, (0.01 * x.grad):0.000235 y:20.000137\n",
      "次数:336 权重x: 0.011271, (0.01 * x.grad):0.000230 y:20.000132\n",
      "次数:337 权重x: 0.011046, (0.01 * x.grad):0.000225 y:20.000128\n",
      "次数:338 权重x: 0.010825, (0.01 * x.grad):0.000221 y:20.000122\n",
      "次数:339 权重x: 0.010608, (0.01 * x.grad):0.000216 y:20.000116\n",
      "次数:340 权重x: 0.010396, (0.01 * x.grad):0.000212 y:20.000113\n",
      "次数:341 权重x: 0.010188, (0.01 * x.grad):0.000208 y:20.000109\n",
      "次数:342 权重x: 0.009984, (0.01 * x.grad):0.000204 y:20.000103\n",
      "次数:343 权重x: 0.009785, (0.01 * x.grad):0.000200 y:20.000099\n",
      "次数:344 权重x: 0.009589, (0.01 * x.grad):0.000196 y:20.000095\n",
      "次数:345 权重x: 0.009397, (0.01 * x.grad):0.000192 y:20.000092\n",
      "次数:346 权重x: 0.009209, (0.01 * x.grad):0.000188 y:20.000088\n",
      "次数:347 权重x: 0.009025, (0.01 * x.grad):0.000184 y:20.000084\n",
      "次数:348 权重x: 0.008845, (0.01 * x.grad):0.000181 y:20.000082\n",
      "次数:349 权重x: 0.008668, (0.01 * x.grad):0.000177 y:20.000078\n",
      "次数:350 权重x: 0.008494, (0.01 * x.grad):0.000173 y:20.000074\n",
      "次数:351 权重x: 0.008324, (0.01 * x.grad):0.000170 y:20.000072\n",
      "次数:352 权重x: 0.008158, (0.01 * x.grad):0.000166 y:20.000069\n",
      "次数:353 权重x: 0.007995, (0.01 * x.grad):0.000163 y:20.000067\n",
      "次数:354 权重x: 0.007835, (0.01 * x.grad):0.000160 y:20.000065\n",
      "次数:355 权重x: 0.007678, (0.01 * x.grad):0.000157 y:20.000061\n",
      "次数:356 权重x: 0.007525, (0.01 * x.grad):0.000154 y:20.000059\n",
      "次数:357 权重x: 0.007374, (0.01 * x.grad):0.000150 y:20.000057\n",
      "次数:358 权重x: 0.007227, (0.01 * x.grad):0.000147 y:20.000055\n",
      "次数:359 权重x: 0.007082, (0.01 * x.grad):0.000145 y:20.000051\n",
      "次数:360 权重x: 0.006940, (0.01 * x.grad):0.000142 y:20.000050\n",
      "次数:361 权重x: 0.006802, (0.01 * x.grad):0.000139 y:20.000048\n",
      "次数:362 权重x: 0.006666, (0.01 * x.grad):0.000136 y:20.000046\n",
      "次数:363 权重x: 0.006532, (0.01 * x.grad):0.000133 y:20.000044\n",
      "次数:364 权重x: 0.006402, (0.01 * x.grad):0.000131 y:20.000042\n",
      "次数:365 权重x: 0.006274, (0.01 * x.grad):0.000128 y:20.000040\n",
      "次数:366 权重x: 0.006148, (0.01 * x.grad):0.000125 y:20.000040\n",
      "次数:367 权重x: 0.006025, (0.01 * x.grad):0.000123 y:20.000038\n",
      "次数:368 权重x: 0.005905, (0.01 * x.grad):0.000121 y:20.000036\n",
      "次数:369 权重x: 0.005787, (0.01 * x.grad):0.000118 y:20.000034\n",
      "次数:370 权重x: 0.005671, (0.01 * x.grad):0.000116 y:20.000034\n",
      "次数:371 权重x: 0.005557, (0.01 * x.grad):0.000113 y:20.000032\n",
      "次数:372 权重x: 0.005446, (0.01 * x.grad):0.000111 y:20.000031\n",
      "次数:373 权重x: 0.005337, (0.01 * x.grad):0.000109 y:20.000031\n",
      "次数:374 权重x: 0.005231, (0.01 * x.grad):0.000107 y:20.000029\n",
      "次数:375 权重x: 0.005126, (0.01 * x.grad):0.000105 y:20.000027\n",
      "次数:376 权重x: 0.005023, (0.01 * x.grad):0.000103 y:20.000027\n",
      "次数:377 权重x: 0.004923, (0.01 * x.grad):0.000100 y:20.000025\n",
      "次数:378 权重x: 0.004825, (0.01 * x.grad):0.000098 y:20.000025\n",
      "次数:379 权重x: 0.004728, (0.01 * x.grad):0.000096 y:20.000023\n",
      "次数:380 权重x: 0.004633, (0.01 * x.grad):0.000095 y:20.000023\n",
      "次数:381 权重x: 0.004541, (0.01 * x.grad):0.000093 y:20.000021\n",
      "次数:382 权重x: 0.004450, (0.01 * x.grad):0.000091 y:20.000021\n",
      "次数:383 权重x: 0.004361, (0.01 * x.grad):0.000089 y:20.000019\n",
      "次数:384 权重x: 0.004274, (0.01 * x.grad):0.000087 y:20.000019\n",
      "次数:385 权重x: 0.004188, (0.01 * x.grad):0.000085 y:20.000019\n",
      "次数:386 权重x: 0.004105, (0.01 * x.grad):0.000084 y:20.000017\n",
      "次数:387 权重x: 0.004022, (0.01 * x.grad):0.000082 y:20.000017\n",
      "次数:388 权重x: 0.003942, (0.01 * x.grad):0.000080 y:20.000015\n",
      "次数:389 权重x: 0.003863, (0.01 * x.grad):0.000079 y:20.000015\n",
      "次数:390 权重x: 0.003786, (0.01 * x.grad):0.000077 y:20.000015\n",
      "次数:391 权重x: 0.003710, (0.01 * x.grad):0.000076 y:20.000015\n",
      "次数:392 权重x: 0.003636, (0.01 * x.grad):0.000074 y:20.000013\n",
      "次数:393 权重x: 0.003563, (0.01 * x.grad):0.000073 y:20.000013\n",
      "次数:394 权重x: 0.003492, (0.01 * x.grad):0.000071 y:20.000013\n",
      "次数:395 权重x: 0.003422, (0.01 * x.grad):0.000070 y:20.000011\n",
      "次数:396 权重x: 0.003354, (0.01 * x.grad):0.000068 y:20.000011\n",
      "次数:397 权重x: 0.003287, (0.01 * x.grad):0.000067 y:20.000011\n",
      "次数:398 权重x: 0.003221, (0.01 * x.grad):0.000066 y:20.000011\n",
      "次数:399 权重x: 0.003156, (0.01 * x.grad):0.000064 y:20.000010\n",
      "次数:400 权重x: 0.003093, (0.01 * x.grad):0.000063 y:20.000010\n",
      "次数:401 权重x: 0.003031, (0.01 * x.grad):0.000062 y:20.000010\n",
      "次数:402 权重x: 0.002971, (0.01 * x.grad):0.000061 y:20.000010\n",
      "次数:403 权重x: 0.002911, (0.01 * x.grad):0.000059 y:20.000010\n",
      "次数:404 权重x: 0.002853, (0.01 * x.grad):0.000058 y:20.000008\n",
      "次数:405 权重x: 0.002796, (0.01 * x.grad):0.000057 y:20.000008\n",
      "次数:406 权重x: 0.002740, (0.01 * x.grad):0.000056 y:20.000008\n",
      "次数:407 权重x: 0.002685, (0.01 * x.grad):0.000055 y:20.000008\n",
      "次数:408 权重x: 0.002632, (0.01 * x.grad):0.000054 y:20.000008\n",
      "次数:409 权重x: 0.002579, (0.01 * x.grad):0.000053 y:20.000008\n",
      "次数:410 权重x: 0.002527, (0.01 * x.grad):0.000052 y:20.000006\n",
      "次数:411 权重x: 0.002477, (0.01 * x.grad):0.000051 y:20.000006\n",
      "次数:412 权重x: 0.002427, (0.01 * x.grad):0.000050 y:20.000006\n",
      "次数:413 权重x: 0.002379, (0.01 * x.grad):0.000049 y:20.000006\n",
      "次数:414 权重x: 0.002331, (0.01 * x.grad):0.000048 y:20.000006\n",
      "次数:415 权重x: 0.002285, (0.01 * x.grad):0.000047 y:20.000006\n",
      "次数:416 权重x: 0.002239, (0.01 * x.grad):0.000046 y:20.000006\n",
      "次数:417 权重x: 0.002194, (0.01 * x.grad):0.000045 y:20.000006\n",
      "次数:418 权重x: 0.002150, (0.01 * x.grad):0.000044 y:20.000006\n",
      "次数:419 权重x: 0.002107, (0.01 * x.grad):0.000043 y:20.000004\n",
      "次数:420 权重x: 0.002065, (0.01 * x.grad):0.000042 y:20.000004\n",
      "次数:421 权重x: 0.002024, (0.01 * x.grad):0.000041 y:20.000004\n",
      "次数:422 权重x: 0.001983, (0.01 * x.grad):0.000040 y:20.000004\n",
      "次数:423 权重x: 0.001944, (0.01 * x.grad):0.000040 y:20.000004\n",
      "次数:424 权重x: 0.001905, (0.01 * x.grad):0.000039 y:20.000004\n",
      "次数:425 权重x: 0.001867, (0.01 * x.grad):0.000038 y:20.000004\n",
      "次数:426 权重x: 0.001829, (0.01 * x.grad):0.000037 y:20.000004\n",
      "次数:427 权重x: 0.001793, (0.01 * x.grad):0.000037 y:20.000004\n",
      "次数:428 权重x: 0.001757, (0.01 * x.grad):0.000036 y:20.000004\n",
      "次数:429 权重x: 0.001722, (0.01 * x.grad):0.000035 y:20.000004\n",
      "次数:430 权重x: 0.001687, (0.01 * x.grad):0.000034 y:20.000004\n",
      "次数:431 权重x: 0.001654, (0.01 * x.grad):0.000034 y:20.000002\n",
      "次数:432 权重x: 0.001621, (0.01 * x.grad):0.000033 y:20.000002\n",
      "次数:433 权重x: 0.001588, (0.01 * x.grad):0.000032 y:20.000002\n",
      "次数:434 权重x: 0.001556, (0.01 * x.grad):0.000032 y:20.000002\n",
      "次数:435 权重x: 0.001525, (0.01 * x.grad):0.000031 y:20.000002\n",
      "次数:436 权重x: 0.001495, (0.01 * x.grad):0.000031 y:20.000002\n",
      "次数:437 权重x: 0.001465, (0.01 * x.grad):0.000030 y:20.000002\n",
      "次数:438 权重x: 0.001436, (0.01 * x.grad):0.000029 y:20.000002\n",
      "次数:439 权重x: 0.001407, (0.01 * x.grad):0.000029 y:20.000002\n",
      "次数:440 权重x: 0.001379, (0.01 * x.grad):0.000028 y:20.000002\n",
      "次数:441 权重x: 0.001351, (0.01 * x.grad):0.000028 y:20.000002\n",
      "次数:442 权重x: 0.001324, (0.01 * x.grad):0.000027 y:20.000002\n",
      "次数:443 权重x: 0.001298, (0.01 * x.grad):0.000026 y:20.000002\n",
      "次数:444 权重x: 0.001272, (0.01 * x.grad):0.000026 y:20.000002\n",
      "次数:445 权重x: 0.001246, (0.01 * x.grad):0.000025 y:20.000002\n",
      "次数:446 权重x: 0.001221, (0.01 * x.grad):0.000025 y:20.000002\n",
      "次数:447 权重x: 0.001197, (0.01 * x.grad):0.000024 y:20.000002\n",
      "次数:448 权重x: 0.001173, (0.01 * x.grad):0.000024 y:20.000002\n",
      "次数:449 权重x: 0.001149, (0.01 * x.grad):0.000023 y:20.000002\n",
      "次数:450 权重x: 0.001127, (0.01 * x.grad):0.000023 y:20.000002\n",
      "次数:451 权重x: 0.001104, (0.01 * x.grad):0.000023 y:20.000002\n",
      "次数:452 权重x: 0.001082, (0.01 * x.grad):0.000022 y:20.000002\n",
      "次数:453 权重x: 0.001060, (0.01 * x.grad):0.000022 y:20.000002\n",
      "次数:454 权重x: 0.001039, (0.01 * x.grad):0.000021 y:20.000002\n",
      "次数:455 权重x: 0.001018, (0.01 * x.grad):0.000021 y:20.000002\n",
      "次数:456 权重x: 0.000998, (0.01 * x.grad):0.000020 y:20.000002\n",
      "次数:457 权重x: 0.000978, (0.01 * x.grad):0.000020 y:20.000002\n",
      "次数:458 权重x: 0.000958, (0.01 * x.grad):0.000020 y:20.000002\n",
      "次数:459 权重x: 0.000939, (0.01 * x.grad):0.000019 y:20.000000\n",
      "次数:460 权重x: 0.000920, (0.01 * x.grad):0.000019 y:20.000000\n",
      "次数:461 权重x: 0.000902, (0.01 * x.grad):0.000018 y:20.000000\n",
      "次数:462 权重x: 0.000884, (0.01 * x.grad):0.000018 y:20.000000\n",
      "次数:463 权重x: 0.000866, (0.01 * x.grad):0.000018 y:20.000000\n",
      "次数:464 权重x: 0.000849, (0.01 * x.grad):0.000017 y:20.000000\n",
      "次数:465 权重x: 0.000832, (0.01 * x.grad):0.000017 y:20.000000\n",
      "次数:466 权重x: 0.000815, (0.01 * x.grad):0.000017 y:20.000000\n",
      "次数:467 权重x: 0.000799, (0.01 * x.grad):0.000016 y:20.000000\n",
      "次数:468 权重x: 0.000783, (0.01 * x.grad):0.000016 y:20.000000\n",
      "次数:469 权重x: 0.000767, (0.01 * x.grad):0.000016 y:20.000000\n",
      "次数:470 权重x: 0.000752, (0.01 * x.grad):0.000015 y:20.000000\n",
      "次数:471 权重x: 0.000737, (0.01 * x.grad):0.000015 y:20.000000\n",
      "次数:472 权重x: 0.000722, (0.01 * x.grad):0.000015 y:20.000000\n",
      "次数:473 权重x: 0.000708, (0.01 * x.grad):0.000014 y:20.000000\n",
      "次数:474 权重x: 0.000694, (0.01 * x.grad):0.000014 y:20.000000\n",
      "次数:475 权重x: 0.000680, (0.01 * x.grad):0.000014 y:20.000000\n",
      "次数:476 权重x: 0.000666, (0.01 * x.grad):0.000014 y:20.000000\n",
      "次数:477 权重x: 0.000653, (0.01 * x.grad):0.000013 y:20.000000\n",
      "次数:478 权重x: 0.000640, (0.01 * x.grad):0.000013 y:20.000000\n",
      "次数:479 权重x: 0.000627, (0.01 * x.grad):0.000013 y:20.000000\n",
      "次数:480 权重x: 0.000614, (0.01 * x.grad):0.000013 y:20.000000\n",
      "次数:481 权重x: 0.000602, (0.01 * x.grad):0.000012 y:20.000000\n",
      "次数:482 权重x: 0.000590, (0.01 * x.grad):0.000012 y:20.000000\n",
      "次数:483 权重x: 0.000578, (0.01 * x.grad):0.000012 y:20.000000\n",
      "次数:484 权重x: 0.000567, (0.01 * x.grad):0.000012 y:20.000000\n",
      "次数:485 权重x: 0.000555, (0.01 * x.grad):0.000011 y:20.000000\n",
      "次数:486 权重x: 0.000544, (0.01 * x.grad):0.000011 y:20.000000\n",
      "次数:487 权重x: 0.000533, (0.01 * x.grad):0.000011 y:20.000000\n",
      "次数:488 权重x: 0.000523, (0.01 * x.grad):0.000011 y:20.000000\n",
      "次数:489 权重x: 0.000512, (0.01 * x.grad):0.000010 y:20.000000\n",
      "次数:490 权重x: 0.000502, (0.01 * x.grad):0.000010 y:20.000000\n",
      "次数:491 权重x: 0.000492, (0.01 * x.grad):0.000010 y:20.000000\n",
      "次数:492 权重x: 0.000482, (0.01 * x.grad):0.000010 y:20.000000\n",
      "次数:493 权重x: 0.000473, (0.01 * x.grad):0.000010 y:20.000000\n",
      "次数:494 权重x: 0.000463, (0.01 * x.grad):0.000009 y:20.000000\n",
      "次数:495 权重x: 0.000454, (0.01 * x.grad):0.000009 y:20.000000\n",
      "次数:496 权重x: 0.000445, (0.01 * x.grad):0.000009 y:20.000000\n",
      "次数:497 权重x: 0.000436, (0.01 * x.grad):0.000009 y:20.000000\n",
      "次数:498 权重x: 0.000427, (0.01 * x.grad):0.000009 y:20.000000\n",
      "次数:499 权重x: 0.000419, (0.01 * x.grad):0.000009 y:20.000000\n",
      "次数:500 权重x: 0.000410, (0.01 * x.grad):0.000008 y:20.000000\n",
      "次数:501 权重x: 0.000402, (0.01 * x.grad):0.000008 y:20.000000\n",
      "次数:502 权重x: 0.000394, (0.01 * x.grad):0.000008 y:20.000000\n",
      "次数:503 权重x: 0.000386, (0.01 * x.grad):0.000008 y:20.000000\n",
      "次数:504 权重x: 0.000378, (0.01 * x.grad):0.000008 y:20.000000\n",
      "次数:505 权重x: 0.000371, (0.01 * x.grad):0.000008 y:20.000000\n",
      "次数:506 权重x: 0.000363, (0.01 * x.grad):0.000007 y:20.000000\n",
      "次数:507 权重x: 0.000356, (0.01 * x.grad):0.000007 y:20.000000\n",
      "次数:508 权重x: 0.000349, (0.01 * x.grad):0.000007 y:20.000000\n",
      "次数:509 权重x: 0.000342, (0.01 * x.grad):0.000007 y:20.000000\n",
      "次数:510 权重x: 0.000335, (0.01 * x.grad):0.000007 y:20.000000\n",
      "次数:511 权重x: 0.000328, (0.01 * x.grad):0.000007 y:20.000000\n",
      "次数:512 权重x: 0.000322, (0.01 * x.grad):0.000007 y:20.000000\n",
      "次数:513 权重x: 0.000315, (0.01 * x.grad):0.000006 y:20.000000\n",
      "次数:514 权重x: 0.000309, (0.01 * x.grad):0.000006 y:20.000000\n",
      "次数:515 权重x: 0.000303, (0.01 * x.grad):0.000006 y:20.000000\n",
      "次数:516 权重x: 0.000297, (0.01 * x.grad):0.000006 y:20.000000\n",
      "次数:517 权重x: 0.000291, (0.01 * x.grad):0.000006 y:20.000000\n",
      "次数:518 权重x: 0.000285, (0.01 * x.grad):0.000006 y:20.000000\n",
      "次数:519 权重x: 0.000279, (0.01 * x.grad):0.000006 y:20.000000\n",
      "次数:520 权重x: 0.000274, (0.01 * x.grad):0.000006 y:20.000000\n",
      "次数:521 权重x: 0.000268, (0.01 * x.grad):0.000005 y:20.000000\n",
      "次数:522 权重x: 0.000263, (0.01 * x.grad):0.000005 y:20.000000\n",
      "次数:523 权重x: 0.000258, (0.01 * x.grad):0.000005 y:20.000000\n",
      "次数:524 权重x: 0.000253, (0.01 * x.grad):0.000005 y:20.000000\n",
      "次数:525 权重x: 0.000248, (0.01 * x.grad):0.000005 y:20.000000\n",
      "次数:526 权重x: 0.000243, (0.01 * x.grad):0.000005 y:20.000000\n",
      "次数:527 权重x: 0.000238, (0.01 * x.grad):0.000005 y:20.000000\n",
      "次数:528 权重x: 0.000233, (0.01 * x.grad):0.000005 y:20.000000\n",
      "次数:529 权重x: 0.000228, (0.01 * x.grad):0.000005 y:20.000000\n",
      "次数:530 权重x: 0.000224, (0.01 * x.grad):0.000005 y:20.000000\n",
      "次数:531 权重x: 0.000219, (0.01 * x.grad):0.000004 y:20.000000\n",
      "次数:532 权重x: 0.000215, (0.01 * x.grad):0.000004 y:20.000000\n",
      "次数:533 权重x: 0.000211, (0.01 * x.grad):0.000004 y:20.000000\n",
      "次数:534 权重x: 0.000206, (0.01 * x.grad):0.000004 y:20.000000\n",
      "次数:535 权重x: 0.000202, (0.01 * x.grad):0.000004 y:20.000000\n",
      "次数:536 权重x: 0.000198, (0.01 * x.grad):0.000004 y:20.000000\n",
      "次数:537 权重x: 0.000194, (0.01 * x.grad):0.000004 y:20.000000\n",
      "次数:538 权重x: 0.000190, (0.01 * x.grad):0.000004 y:20.000000\n",
      "次数:539 权重x: 0.000187, (0.01 * x.grad):0.000004 y:20.000000\n",
      "次数:540 权重x: 0.000183, (0.01 * x.grad):0.000004 y:20.000000\n",
      "次数:541 权重x: 0.000179, (0.01 * x.grad):0.000004 y:20.000000\n",
      "次数:542 权重x: 0.000176, (0.01 * x.grad):0.000004 y:20.000000\n",
      "次数:543 权重x: 0.000172, (0.01 * x.grad):0.000004 y:20.000000\n",
      "次数:544 权重x: 0.000169, (0.01 * x.grad):0.000003 y:20.000000\n",
      "次数:545 权重x: 0.000165, (0.01 * x.grad):0.000003 y:20.000000\n",
      "次数:546 权重x: 0.000162, (0.01 * x.grad):0.000003 y:20.000000\n",
      "次数:547 权重x: 0.000159, (0.01 * x.grad):0.000003 y:20.000000\n",
      "次数:548 权重x: 0.000156, (0.01 * x.grad):0.000003 y:20.000000\n",
      "次数:549 权重x: 0.000152, (0.01 * x.grad):0.000003 y:20.000000\n",
      "次数:550 权重x: 0.000149, (0.01 * x.grad):0.000003 y:20.000000\n",
      "次数:551 权重x: 0.000146, (0.01 * x.grad):0.000003 y:20.000000\n",
      "次数:552 权重x: 0.000143, (0.01 * x.grad):0.000003 y:20.000000\n",
      "次数:553 权重x: 0.000141, (0.01 * x.grad):0.000003 y:20.000000\n",
      "次数:554 权重x: 0.000138, (0.01 * x.grad):0.000003 y:20.000000\n",
      "次数:555 权重x: 0.000135, (0.01 * x.grad):0.000003 y:20.000000\n",
      "次数:556 权重x: 0.000132, (0.01 * x.grad):0.000003 y:20.000000\n",
      "次数:557 权重x: 0.000130, (0.01 * x.grad):0.000003 y:20.000000\n",
      "次数:558 权重x: 0.000127, (0.01 * x.grad):0.000003 y:20.000000\n",
      "次数:559 权重x: 0.000125, (0.01 * x.grad):0.000003 y:20.000000\n",
      "次数:560 权重x: 0.000122, (0.01 * x.grad):0.000002 y:20.000000\n",
      "次数:561 权重x: 0.000120, (0.01 * x.grad):0.000002 y:20.000000\n",
      "次数:562 权重x: 0.000117, (0.01 * x.grad):0.000002 y:20.000000\n",
      "次数:563 权重x: 0.000115, (0.01 * x.grad):0.000002 y:20.000000\n",
      "次数:564 权重x: 0.000113, (0.01 * x.grad):0.000002 y:20.000000\n",
      "次数:565 权重x: 0.000110, (0.01 * x.grad):0.000002 y:20.000000\n",
      "次数:566 权重x: 0.000108, (0.01 * x.grad):0.000002 y:20.000000\n",
      "次数:567 权重x: 0.000106, (0.01 * x.grad):0.000002 y:20.000000\n",
      "次数:568 权重x: 0.000104, (0.01 * x.grad):0.000002 y:20.000000\n",
      "次数:569 权重x: 0.000102, (0.01 * x.grad):0.000002 y:20.000000\n",
      "次数:570 权重x: 0.000100, (0.01 * x.grad):0.000002 y:20.000000\n",
      "次数:571 权重x: 0.000098, (0.01 * x.grad):0.000002 y:20.000000\n",
      "次数:572 权重x: 0.000096, (0.01 * x.grad):0.000002 y:20.000000\n",
      "次数:573 权重x: 0.000094, (0.01 * x.grad):0.000002 y:20.000000\n",
      "次数:574 权重x: 0.000092, (0.01 * x.grad):0.000002 y:20.000000\n",
      "次数:575 权重x: 0.000090, (0.01 * x.grad):0.000002 y:20.000000\n",
      "次数:576 权重x: 0.000088, (0.01 * x.grad):0.000002 y:20.000000\n",
      "次数:577 权重x: 0.000087, (0.01 * x.grad):0.000002 y:20.000000\n",
      "次数:578 权重x: 0.000085, (0.01 * x.grad):0.000002 y:20.000000\n",
      "次数:579 权重x: 0.000083, (0.01 * x.grad):0.000002 y:20.000000\n",
      "次数:580 权重x: 0.000081, (0.01 * x.grad):0.000002 y:20.000000\n",
      "次数:581 权重x: 0.000080, (0.01 * x.grad):0.000002 y:20.000000\n",
      "次数:582 权重x: 0.000078, (0.01 * x.grad):0.000002 y:20.000000\n",
      "次数:583 权重x: 0.000077, (0.01 * x.grad):0.000002 y:20.000000\n",
      "次数:584 权重x: 0.000075, (0.01 * x.grad):0.000002 y:20.000000\n",
      "次数:585 权重x: 0.000074, (0.01 * x.grad):0.000002 y:20.000000\n",
      "次数:586 权重x: 0.000072, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:587 权重x: 0.000071, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:588 权重x: 0.000069, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:589 权重x: 0.000068, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:590 权重x: 0.000067, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:591 权重x: 0.000065, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:592 权重x: 0.000064, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:593 权重x: 0.000063, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:594 权重x: 0.000061, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:595 权重x: 0.000060, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:596 权重x: 0.000059, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:597 权重x: 0.000058, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:598 权重x: 0.000057, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:599 权重x: 0.000056, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:600 权重x: 0.000054, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:601 权重x: 0.000053, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:602 权重x: 0.000052, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:603 权重x: 0.000051, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:604 权重x: 0.000050, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:605 权重x: 0.000049, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:606 权重x: 0.000048, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:607 权重x: 0.000047, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:608 权重x: 0.000046, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:609 权重x: 0.000045, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:610 权重x: 0.000044, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:611 权重x: 0.000044, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:612 权重x: 0.000043, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:613 权重x: 0.000042, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:614 权重x: 0.000041, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:615 权重x: 0.000040, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:616 权重x: 0.000039, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:617 权重x: 0.000039, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:618 权重x: 0.000038, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:619 权重x: 0.000037, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:620 权重x: 0.000036, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:621 权重x: 0.000036, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:622 权重x: 0.000035, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:623 权重x: 0.000034, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:624 权重x: 0.000034, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:625 权重x: 0.000033, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:626 权重x: 0.000032, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:627 权重x: 0.000032, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:628 权重x: 0.000031, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:629 权重x: 0.000030, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:630 权重x: 0.000030, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:631 权重x: 0.000029, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:632 权重x: 0.000029, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:633 权重x: 0.000028, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:634 权重x: 0.000027, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:635 权重x: 0.000027, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:636 权重x: 0.000026, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:637 权重x: 0.000026, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:638 权重x: 0.000025, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:639 权重x: 0.000025, (0.01 * x.grad):0.000001 y:20.000000\n",
      "次数:640 权重x: 0.000024, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:641 权重x: 0.000024, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:642 权重x: 0.000023, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:643 权重x: 0.000023, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:644 权重x: 0.000022, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:645 权重x: 0.000022, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:646 权重x: 0.000021, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:647 权重x: 0.000021, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:648 权重x: 0.000021, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:649 权重x: 0.000020, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:650 权重x: 0.000020, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:651 权重x: 0.000019, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:652 权重x: 0.000019, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:653 权重x: 0.000019, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:654 权重x: 0.000018, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:655 权重x: 0.000018, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:656 权重x: 0.000018, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:657 权重x: 0.000017, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:658 权重x: 0.000017, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:659 权重x: 0.000017, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:660 权重x: 0.000016, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:661 权重x: 0.000016, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:662 权重x: 0.000016, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:663 权重x: 0.000015, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:664 权重x: 0.000015, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:665 权重x: 0.000015, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:666 权重x: 0.000014, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:667 权重x: 0.000014, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:668 权重x: 0.000014, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:669 权重x: 0.000013, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:670 权重x: 0.000013, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:671 权重x: 0.000013, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:672 权重x: 0.000013, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:673 权重x: 0.000012, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:674 权重x: 0.000012, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:675 权重x: 0.000012, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:676 权重x: 0.000012, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:677 权重x: 0.000011, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:678 权重x: 0.000011, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:679 权重x: 0.000011, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:680 权重x: 0.000011, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:681 权重x: 0.000011, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:682 权重x: 0.000010, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:683 权重x: 0.000010, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:684 权重x: 0.000010, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:685 权重x: 0.000010, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:686 权重x: 0.000010, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:687 权重x: 0.000009, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:688 权重x: 0.000009, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:689 权重x: 0.000009, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:690 权重x: 0.000009, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:691 权重x: 0.000009, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:692 权重x: 0.000008, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:693 权重x: 0.000008, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:694 权重x: 0.000008, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:695 权重x: 0.000008, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:696 权重x: 0.000008, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:697 权重x: 0.000008, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:698 权重x: 0.000008, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:699 权重x: 0.000007, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:700 权重x: 0.000007, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:701 权重x: 0.000007, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:702 权重x: 0.000007, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:703 权重x: 0.000007, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:704 权重x: 0.000007, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:705 权重x: 0.000007, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:706 权重x: 0.000006, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:707 权重x: 0.000006, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:708 权重x: 0.000006, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:709 权重x: 0.000006, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:710 权重x: 0.000006, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:711 权重x: 0.000006, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:712 权重x: 0.000006, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:713 权重x: 0.000006, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:714 权重x: 0.000005, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:715 权重x: 0.000005, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:716 权重x: 0.000005, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:717 权重x: 0.000005, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:718 权重x: 0.000005, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:719 权重x: 0.000005, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:720 权重x: 0.000005, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:721 权重x: 0.000005, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:722 权重x: 0.000005, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:723 权重x: 0.000005, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:724 权重x: 0.000004, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:725 权重x: 0.000004, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:726 权重x: 0.000004, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:727 权重x: 0.000004, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:728 权重x: 0.000004, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:729 权重x: 0.000004, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:730 权重x: 0.000004, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:731 权重x: 0.000004, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:732 权重x: 0.000004, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:733 权重x: 0.000004, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:734 权重x: 0.000004, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:735 权重x: 0.000004, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:736 权重x: 0.000003, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:737 权重x: 0.000003, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:738 权重x: 0.000003, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:739 权重x: 0.000003, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:740 权重x: 0.000003, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:741 权重x: 0.000003, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:742 权重x: 0.000003, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:743 权重x: 0.000003, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:744 权重x: 0.000003, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:745 权重x: 0.000003, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:746 权重x: 0.000003, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:747 权重x: 0.000003, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:748 权重x: 0.000003, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:749 权重x: 0.000003, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:750 权重x: 0.000003, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:751 权重x: 0.000003, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:752 权重x: 0.000003, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:753 权重x: 0.000002, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:754 权重x: 0.000002, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:755 权重x: 0.000002, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:756 权重x: 0.000002, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:757 权重x: 0.000002, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:758 权重x: 0.000002, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:759 权重x: 0.000002, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:760 权重x: 0.000002, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:761 权重x: 0.000002, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:762 权重x: 0.000002, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:763 权重x: 0.000002, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:764 权重x: 0.000002, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:765 权重x: 0.000002, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:766 权重x: 0.000002, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:767 权重x: 0.000002, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:768 权重x: 0.000002, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:769 权重x: 0.000002, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:770 权重x: 0.000002, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:771 权重x: 0.000002, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:772 权重x: 0.000002, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:773 权重x: 0.000002, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:774 权重x: 0.000002, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:775 权重x: 0.000002, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:776 权重x: 0.000002, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:777 权重x: 0.000002, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:778 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:779 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:780 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:781 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:782 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:783 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:784 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:785 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:786 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:787 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:788 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:789 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:790 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:791 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:792 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:793 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:794 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:795 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:796 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:797 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:798 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:799 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:800 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:801 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:802 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:803 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:804 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:805 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:806 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:807 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:808 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:809 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:810 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:811 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:812 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:813 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:814 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:815 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:816 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:817 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:818 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:819 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:820 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:821 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:822 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:823 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:824 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:825 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:826 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:827 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:828 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:829 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:830 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:831 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:832 权重x: 0.000001, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:833 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:834 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:835 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:836 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:837 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:838 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:839 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:840 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:841 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:842 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:843 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:844 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:845 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:846 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:847 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:848 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:849 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:850 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:851 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:852 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:853 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:854 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:855 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:856 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:857 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:858 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:859 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:860 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:861 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:862 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:863 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:864 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:865 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:866 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:867 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:868 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:869 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:870 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:871 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:872 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:873 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:874 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:875 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:876 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:877 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:878 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:879 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:880 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:881 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:882 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:883 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:884 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:885 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:886 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:887 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:888 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:889 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:890 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:891 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:892 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:893 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:894 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:895 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:896 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:897 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:898 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:899 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:900 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:901 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:902 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:903 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:904 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:905 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:906 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:907 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:908 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:909 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:910 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:911 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:912 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:913 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:914 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:915 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:916 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:917 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:918 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:919 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:920 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:921 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:922 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:923 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:924 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:925 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:926 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:927 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:928 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:929 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:930 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:931 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:932 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:933 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:934 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:935 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:936 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:937 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:938 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:939 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:940 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:941 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:942 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:943 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:944 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:945 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:946 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:947 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:948 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:949 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:950 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:951 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:952 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:953 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:954 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:955 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:956 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:957 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:958 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:959 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:960 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:961 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:962 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:963 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:964 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:965 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:966 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:967 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:968 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:969 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:970 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:971 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:972 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:973 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:974 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:975 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:976 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:977 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:978 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:979 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:980 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:981 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:982 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:983 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:984 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:985 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:986 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:987 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:988 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:989 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:990 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:991 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:992 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:993 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:994 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:995 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:996 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:997 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:998 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:999 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "次数:1000 权重x: 0.000000, (0.01 * x.grad):0.000000 y:20.000000\n",
      "x： tensor(1.6830e-08, requires_grad=True) tensor(3.4346e-08) y最小值 tensor(20., grad_fn=<AddBackward0>)\n",
      "True\n",
      "False\n",
      "tensor([10., 20.], dtype=torch.float64)\n",
      "tensor([10., 20.], dtype=torch.float64)\n",
      "140526910107792\n",
      "140526910107792\n",
      "tensor([10., 20.], dtype=torch.float64)\n"
     ]
    }
   ],
   "execution_count": 119
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T11:13:30.112455Z",
     "start_time": "2025-03-23T11:13:30.061218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "def automatic_differentiation():\n",
    "    '''\n",
    "    自动微分模块应用\n",
    "    :return: \n",
    "    '''\n",
    "\n",
    "    # 输入张量 2*5\n",
    "    x = torch.ones(2, 5)\n",
    "    # 目标值是 2*3    \n",
    "    y = torch.zeros(2, 3)\n",
    "    # 设置要更新的权重和偏置的初始值\n",
    "    w = torch.randn(5, 3, requires_grad=True)\n",
    "    b = torch.randn(3, requires_grad=True)\n",
    "    # 设置网络的输出值\n",
    "    z = torch.matmul(x, w) + b  # 矩阵乘法\n",
    "    # 设置损失函数，并进行损失的计算\n",
    "    loss = torch.nn.MSELoss()\n",
    "    loss = loss(z, y)\n",
    "    # 自动微分\n",
    "    loss.backward()\n",
    "    # 打印 w,b 变量的梯度\n",
    "    # backward 函数计算的梯度值会存储在张量的 grad 变量中\n",
    "    print(\"W的梯度:\", w.grad)\n",
    "    print(\"b的梯度\", b.grad)\n",
    "\n",
    "automatic_differentiation()"
   ],
   "id": "66fb6a3bec5f4bc9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W的梯度: tensor([[ 1.8780,  0.1972, -1.2748],\n",
      "        [ 1.8780,  0.1972, -1.2748],\n",
      "        [ 1.8780,  0.1972, -1.2748],\n",
      "        [ 1.8780,  0.1972, -1.2748],\n",
      "        [ 1.8780,  0.1972, -1.2748]])\n",
      "b的梯度 tensor([ 1.8780,  0.1972, -1.2748])\n"
     ]
    }
   ],
   "execution_count": 120
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T11:18:21.747201Z",
     "start_time": "2025-03-23T11:18:20.694625Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "我们使用 PyTorch 的各个组件来构建线性回归模型。在pytorch中进行模型构建的整个流程一般分为四个步骤：\n",
    "1、准备训练集数据\n",
    "2、构建要使用的模型\n",
    "3、设置损失函数和优化器\n",
    "4、模型训练\n",
    "\n",
    "要使用的API：\n",
    "    使用 PyTorch 的 nn.MSELoss() 代替平方损失函数\n",
    "    使用 PyTorch 的 data.DataLoader 代替数据加载器\n",
    "    使用 PyTorch 的 optim.SGD 代替优化器\n",
    "    使用 PyTorch 的 nn.Linear 代替假设函数\n",
    "\n",
    "'''\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset  # 构造数据集对象\n",
    "from torch.utils.data import DataLoader  # 数据加载器\n",
    "from torch import nn  # nn模块中有平方损失函数和假设函数\n",
    "from torch import optim  # optim模块中有优化器函数\n",
    "from sklearn.datasets import make_regression  # 创建线性回归模型数据集\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# 构造数据集\n",
    "def create_dataset():\n",
    "    x, y, coef = make_regression(n_samples=100,\n",
    "                                 n_features=1,\n",
    "                                 noise=10,\n",
    "                                 coef=True,\n",
    "                                 bias=14.5,\n",
    "                                 random_state=0)\n",
    "\n",
    "    # 将构建数据转换为张量类型\n",
    "    x = torch.tensor(x)\n",
    "    y = torch.tensor(y)\n",
    "\n",
    "    return x, y, coef\n",
    "\n",
    "# 训练模型\n",
    "def construct_liner_regression_model():\n",
    "    # 构造数据集\n",
    "    x, y, coef = create_dataset()\n",
    "\n",
    "    # 构造数据集对象\n",
    "    dataset = TensorDataset(x, y)\n",
    "\n",
    "    # 构造数据加载器\n",
    "    # dataset=:数据集对象\n",
    "    # batch_size=:批量训练样本数据\n",
    "    # shuffle=:样本数据是否进行乱序\n",
    "    dataloader = DataLoader(dataset=dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "    # 构造模型\n",
    "    # in_features指的是输入的二维张量的大小，即输入的[batch_size, size]中的size\n",
    "    # out_features指的是输出的二维张量的大小，即输出的[batch_size，size]中的size\n",
    "    model = nn.Linear(in_features=1, out_features=1)\n",
    "\n",
    "    # 构造平方损失函数\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # 构造优化函数\n",
    "    # params=model.parameters():训练的参数,w和b\n",
    "    # lr=1e-2:学习率, 1e-2为10的负二次方\n",
    "    print(\"w和b-->\", list(model.parameters()))\n",
    "    print(\"w-->\", model.weight)\n",
    "    print(\"b-->\", model.bias)\n",
    "    optimizer = optim.SGD(params=model.parameters(), lr=1e-2)\n",
    "\n",
    "    # 初始化训练次数\n",
    "    epochs = 100\n",
    "    # 损失的变化\n",
    "    epoch_loss = []\n",
    "    total_loss=0.0\n",
    "    train_sample=0.0\n",
    "    for _ in range(epochs):\n",
    "        for train_x, train_y in dataloader:\n",
    "            # 将一个batch的训练数据送入模型\n",
    "            y_pred = model(train_x.type(torch.float32))\n",
    "            # 计算损失值,均方误差,当前批次所有样本的平均误差 \n",
    "            loss = criterion(y_pred, train_y.reshape(-1, 1).type(torch.float32))\n",
    "            total_loss += loss.item()\n",
    "            # loss是平均误差,所以样本数+1\n",
    "            train_sample += 1\n",
    "            # 梯度清零\n",
    "            optimizer.zero_grad()\n",
    "            # 自动微分(反向传播)\n",
    "            loss.backward()\n",
    "            # 更新参数\n",
    "            optimizer.step()\n",
    "        # 计算所有batch的平均误差作为当前epoch的误差 \n",
    "        epoch_loss.append(total_loss/train_sample)\n",
    "\n",
    "    # 打印回归模型的w\n",
    "    print(model.weight)\n",
    "    # 打印回归模型的b\n",
    "    print(model.bias)\n",
    "\n",
    "    # 绘制损失变化曲线 \n",
    "    plt.plot(range(epochs), epoch_loss)\n",
    "    plt.title('损失变化曲线')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    # 绘制拟合直线\n",
    "    plt.scatter(x, y)\n",
    "    x = torch.linspace(x.min(), x.max(), 1000)\n",
    "    y1 = torch.tensor([v * model.weight + model.bias for v in x])\n",
    "    y2 = torch.tensor([v * coef + 14.5 for v in x])\n",
    "    plt.plot(x, y1, label='训练')\n",
    "    plt.plot(x, y2, label='真实')\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "construct_liner_regression_model()"
   ],
   "id": "6108a7b6bbbb583d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w和b--> [Parameter containing:\n",
      "tensor([[0.8250]], requires_grad=True), Parameter containing:\n",
      "tensor([0.5727], requires_grad=True)]\n",
      "w--> Parameter containing:\n",
      "tensor([[0.8250]], requires_grad=True)\n",
      "b--> Parameter containing:\n",
      "tensor([0.5727], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[42.7297]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([13.4735], requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[123], line 116\u001B[0m\n\u001B[1;32m    113\u001B[0m     plt\u001B[38;5;241m.\u001B[39mlegend()\n\u001B[1;32m    114\u001B[0m     plt\u001B[38;5;241m.\u001B[39mshow()\n\u001B[0;32m--> 116\u001B[0m \u001B[43mconstruct_liner_regression_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[123], line 106\u001B[0m, in \u001B[0;36mconstruct_liner_regression_model\u001B[0;34m()\u001B[0m\n\u001B[1;32m    103\u001B[0m plt\u001B[38;5;241m.\u001B[39mshow()\n\u001B[1;32m    105\u001B[0m \u001B[38;5;66;03m# 绘制拟合直线\u001B[39;00m\n\u001B[0;32m--> 106\u001B[0m \u001B[43mplt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscatter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    107\u001B[0m x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mlinspace(x\u001B[38;5;241m.\u001B[39mmin(), x\u001B[38;5;241m.\u001B[39mmax(), \u001B[38;5;241m1000\u001B[39m)\n\u001B[1;32m    108\u001B[0m y1 \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor([v \u001B[38;5;241m*\u001B[39m model\u001B[38;5;241m.\u001B[39mweight \u001B[38;5;241m+\u001B[39m model\u001B[38;5;241m.\u001B[39mbias \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m x])\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/matplotlib/pyplot.py:3903\u001B[0m, in \u001B[0;36mscatter\u001B[0;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, data, **kwargs)\u001B[0m\n\u001B[1;32m   3884\u001B[0m \u001B[38;5;129m@_copy_docstring_and_deprecators\u001B[39m(Axes\u001B[38;5;241m.\u001B[39mscatter)\n\u001B[1;32m   3885\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mscatter\u001B[39m(\n\u001B[1;32m   3886\u001B[0m     x: \u001B[38;5;28mfloat\u001B[39m \u001B[38;5;241m|\u001B[39m ArrayLike,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   3901\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   3902\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m PathCollection:\n\u001B[0;32m-> 3903\u001B[0m     __ret \u001B[38;5;241m=\u001B[39m \u001B[43mgca\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscatter\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   3904\u001B[0m \u001B[43m        \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3905\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3906\u001B[0m \u001B[43m        \u001B[49m\u001B[43ms\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43ms\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3907\u001B[0m \u001B[43m        \u001B[49m\u001B[43mc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3908\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmarker\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmarker\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3909\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcmap\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcmap\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3910\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnorm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnorm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3911\u001B[0m \u001B[43m        \u001B[49m\u001B[43mvmin\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvmin\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3912\u001B[0m \u001B[43m        \u001B[49m\u001B[43mvmax\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvmax\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3913\u001B[0m \u001B[43m        \u001B[49m\u001B[43malpha\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43malpha\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3914\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlinewidths\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlinewidths\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3915\u001B[0m \u001B[43m        \u001B[49m\u001B[43medgecolors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43medgecolors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3916\u001B[0m \u001B[43m        \u001B[49m\u001B[43mplotnonfinite\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mplotnonfinite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3917\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdata\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m}\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3918\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3919\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3920\u001B[0m     sci(__ret)\n\u001B[1;32m   3921\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m __ret\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/matplotlib/__init__.py:1473\u001B[0m, in \u001B[0;36m_preprocess_data.<locals>.inner\u001B[0;34m(ax, data, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1470\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m   1471\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minner\u001B[39m(ax, \u001B[38;5;241m*\u001B[39margs, data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m   1472\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1473\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1474\u001B[0m \u001B[43m            \u001B[49m\u001B[43max\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1475\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mmap\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msanitize_sequence\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1476\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m{\u001B[49m\u001B[43mk\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43msanitize_sequence\u001B[49m\u001B[43m(\u001B[49m\u001B[43mv\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitems\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1478\u001B[0m     bound \u001B[38;5;241m=\u001B[39m new_sig\u001B[38;5;241m.\u001B[39mbind(ax, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1479\u001B[0m     auto_label \u001B[38;5;241m=\u001B[39m (bound\u001B[38;5;241m.\u001B[39marguments\u001B[38;5;241m.\u001B[39mget(label_namer)\n\u001B[1;32m   1480\u001B[0m                   \u001B[38;5;129;01mor\u001B[39;00m bound\u001B[38;5;241m.\u001B[39mkwargs\u001B[38;5;241m.\u001B[39mget(label_namer))\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/matplotlib/axes/_axes.py:4781\u001B[0m, in \u001B[0;36mAxes.scatter\u001B[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, **kwargs)\u001B[0m\n\u001B[1;32m   4779\u001B[0m edgecolors \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124medgecolor\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m   4780\u001B[0m \u001B[38;5;66;03m# Process **kwargs to handle aliases, conflicts with explicit kwargs:\u001B[39;00m\n\u001B[0;32m-> 4781\u001B[0m x, y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_process_unit_info\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mx\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43my\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4782\u001B[0m \u001B[38;5;66;03m# np.ma.ravel yields an ndarray, not a masked array,\u001B[39;00m\n\u001B[1;32m   4783\u001B[0m \u001B[38;5;66;03m# unless its argument is a masked array.\u001B[39;00m\n\u001B[1;32m   4784\u001B[0m x \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mma\u001B[38;5;241m.\u001B[39mravel(x)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/matplotlib/axes/_base.py:2585\u001B[0m, in \u001B[0;36m_AxesBase._process_unit_info\u001B[0;34m(self, datasets, kwargs, convert)\u001B[0m\n\u001B[1;32m   2583\u001B[0m     \u001B[38;5;66;03m# Update from data if axis is already set but no unit is set yet.\u001B[39;00m\n\u001B[1;32m   2584\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m axis \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m axis\u001B[38;5;241m.\u001B[39mhave_units():\n\u001B[0;32m-> 2585\u001B[0m         \u001B[43maxis\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate_units\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2586\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m axis_name, axis \u001B[38;5;129;01min\u001B[39;00m axis_map\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m   2587\u001B[0m     \u001B[38;5;66;03m# Return if no axis is set.\u001B[39;00m\n\u001B[1;32m   2588\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m axis \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/matplotlib/axis.py:1750\u001B[0m, in \u001B[0;36mAxis.update_units\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mupdate_units\u001B[39m(\u001B[38;5;28mself\u001B[39m, data):\n\u001B[1;32m   1745\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1746\u001B[0m \u001B[38;5;124;03m    Introspect *data* for units converter and update the\u001B[39;00m\n\u001B[1;32m   1747\u001B[0m \u001B[38;5;124;03m    ``axis.converter`` instance if necessary. Return *True*\u001B[39;00m\n\u001B[1;32m   1748\u001B[0m \u001B[38;5;124;03m    if *data* is registered for unit conversion.\u001B[39;00m\n\u001B[1;32m   1749\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1750\u001B[0m     converter \u001B[38;5;241m=\u001B[39m \u001B[43mmunits\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mregistry\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_converter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1751\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m converter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1752\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/matplotlib/units.py:167\u001B[0m, in \u001B[0;36mRegistry.get_converter\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    165\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Get the converter interface instance for *x*, or None.\"\"\"\u001B[39;00m\n\u001B[1;32m    166\u001B[0m \u001B[38;5;66;03m# Unpack in case of e.g. Pandas or xarray object\u001B[39;00m\n\u001B[0;32m--> 167\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[43mcbook\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_unpack_to_numpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    169\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x, np\u001B[38;5;241m.\u001B[39mndarray):\n\u001B[1;32m    170\u001B[0m     \u001B[38;5;66;03m# In case x in a masked array, access the underlying data (only its\u001B[39;00m\n\u001B[1;32m    171\u001B[0m     \u001B[38;5;66;03m# type matters).  If x is a regular ndarray, getdata() just returns\u001B[39;00m\n\u001B[1;32m    172\u001B[0m     \u001B[38;5;66;03m# the array itself.\u001B[39;00m\n\u001B[1;32m    173\u001B[0m     x \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mma\u001B[38;5;241m.\u001B[39mgetdata(x)\u001B[38;5;241m.\u001B[39mravel()\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/matplotlib/cbook.py:2395\u001B[0m, in \u001B[0;36m_unpack_to_numpy\u001B[0;34m(x)\u001B[0m\n\u001B[1;32m   2393\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m xtmp\n\u001B[1;32m   2394\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _is_torch_array(x) \u001B[38;5;129;01mor\u001B[39;00m _is_jax_array(x):\n\u001B[0;32m-> 2395\u001B[0m     xtmp \u001B[38;5;241m=\u001B[39m \u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__array__\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2397\u001B[0m     \u001B[38;5;66;03m# In case __array__() method does not return a numpy array in future\u001B[39;00m\n\u001B[1;32m   2398\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(xtmp, np\u001B[38;5;241m.\u001B[39mndarray):\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/_tensor.py:1062\u001B[0m, in \u001B[0;36mTensor.__array__\u001B[0;34m(self, dtype)\u001B[0m\n\u001B[1;32m   1060\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(Tensor\u001B[38;5;241m.\u001B[39m__array__, (\u001B[38;5;28mself\u001B[39m,), \u001B[38;5;28mself\u001B[39m, dtype\u001B[38;5;241m=\u001B[39mdtype)\n\u001B[1;32m   1061\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1062\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnumpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1063\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1064\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnumpy()\u001B[38;5;241m.\u001B[39mastype(dtype, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Numpy is not available"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 123
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
