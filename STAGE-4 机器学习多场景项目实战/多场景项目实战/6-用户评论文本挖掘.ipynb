{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71f1396dc8d921e2",
   "metadata": {},
   "source": "# 用户评论文本挖掘学习目标\n- 知道评论文本挖掘的作用\n- 掌握使用NLTK和gensim来进行基本NLP处理\n\n---\n\n# 1、什么是文本挖掘？\n概念：文本挖掘是一种数据挖掘形式，专注一从文本数据中提取有价值的信息和知识\n目的：主要是实现自动化分析文本内容、发现模式、趋势关联、从而支持决策制定、趋势分析、客户洞察\n步骤：\n- 文本预处理：数据清洗、分词、去掉停用词、词干提取、词性标注\n- 特征提取：将文本装换为可以被机器学习算法处理的格式，如：词袋模型、TF-IDF、WordEmbeddings\n- 模式发现：应用机器学习算法来识别文本中的模式和关联，如分类、聚类、关联规则学习\n- 结果解释：解释挖掘结果，将其转化为可操作的洞察\n\n应用场景：\n- 市场分析：分析客户反馈和产品评论，以了解市场趋势和消费偏好\n- 情感分析：确定文本中表达的情绪倾向\n- 欺诈检测：识别欺诈性交易或可疑行为\n- 客户服务：自动化客户支持，通过聊天机器人提供快速响应\n- 法律分析：分析法律文档，以支持案件研究会和证据发现\n- 健康医疗：分析医疗记录，以支持争端和治疗决策\n\n\n# 2、什么是NLTK？\n概念：NLTK是一个自然语言处理平台，用于构建Python程序处理人类语言数据，它包含文本库（corpora），可以轻松访问词汇资源，如词性标注器、语法分析器、分类器、翻译器。并且同时也提供了文本处理所需要的数据集，如用于分类、标记、语法分析和语义推理的标注文本。其中包含以下特点：\n- 文本库处理：提供了一系列文本处理工具，如分词、标注、解析\n- 数据集：包含多重语言的文本数据集，方便进行语言学习、分析和研究\n- 算法：集成了多种自然语言处理算法（NLP）如分类、标记、聚类、解析\n- 可视化：提供了多种可视化工具，帮助用户理解语言数据和算法效果\n- 教育：NLTK是许多大学和在线课程教授NLP的首选工具，因为它易于使用切功能强大\n\n\n# 3、什么是Gensim？\n概念：Gensim是Python开源库，主要用于无监督自然语言建模，从原始的非结构化数字文本中提取语义主题。并且它包含一系列的算法Word2Vec、FastText、潜在语义分析（LSI），潜在狄利克雷分配（LDA），其主要功能包括：\n- 文档向量化：将文档转化为数值向量，以便于进行处理和分析\n- 模型训练：支持多重算法来训练文档和语义模型\n- 相似度检测：通过语义向量进行文档相似度查询\n- 内存独立性：不需要抗整个训练语料库一次性读入内存，适合处理大型数据集\n- 内存共享：训练好的模型可以减持久化到硬盘，并被多个进程共享\n- 兼容多重数据集结构：支持多重向量空间算法的高效实现\n\n# 4、什么是NLP？\n概念：NLP（Natural Language Processing）全称自然语言处理，它是人工智能和语言学领域的交叉学科，NLP致力于计算机能够理解、解释和生成人类语言内容：\n- 语音识别\n- 自然语言理解\n- 机器翻译\n- 情感分析\n- 文本摘要\n- 文本分类\n- 问答系统\n- 聊天机器人\n\n# 5、文本挖掘有哪些方法？\n文本挖掘是从文本数据中提取有用信息和知识的过程。它通常包括以下几个步骤：文本预处理、特征提取、模式发现和结果解释。以下是一些常见的文本挖掘方法：\n\n- **文本预处理**：\n   - **分词**：将文本分割成单词或短语。\n   - **去除停用词**：移除文本中的常见但无意义的词汇，如“的”、“是”等。\n   - **词干提取**（Stemming）和**词形还原**（Lemmatization）：将词汇还原到基本形式。\n   - **词性标注**：标记文本中单词的词性（名词、动词等）。\n   - **去除噪声**：删除文本中的无关信息，如HTML标签、特殊符号等。\n\n- **特征提取**：\n   - **词袋模型**（Bag of Words）：将文本转换为单词出现次数的向量。\n   - **TF-IDF**（Term Frequency-Inverse Document Frequency）：评估单词对于一个文本集合中的其中一份文档的重要程度。\n   - **词嵌入**（Word Embeddings）：使用预训练的模型（如Word2Vec、GloVe）将单词转换为稠密向量。\n   - **主题建模**：如LDA（Latent Dirichlet Allocation），用于发现文档集合中的隐藏主题。\n\n- **模式发现**：\n   - **分类**：将文本分配到预定义的类别。\n   - **聚类**：将文本分组到相似的类别中。\n   - **关联规则学习**：发现文本特征之间的有趣关系。\n   - **情感分析**：确定文本表达的情绪倾向（正面、负面或中性）。\n\n- **深度学习方法**：\n   - **卷积神经网络（CNN）**：用于文本分类和句子建模。\n   - **循环神经网络（RNN）**和**长短期记忆网络（LSTM）**：处理序列数据，如文本。\n   - **Transformers**：基于自注意力机制的模型，广泛应用于各种NLP任务。\n\n- **文本分析**：\n   - **摘要**：生成文本的简短版本，包括提取式摘要和生成式摘要。\n   - **关键词提取**：识别文本中的关键词汇或短语。\n   - **趋势分析**：分析文本数据随时间的变化趋势。\n\n- **信息检索**：\n   - **搜索引擎技术**：用于从大量文档中检索相关信息。\n   - **问答系统**：根据用户的问题提供准确的答案。\n\n- **自然语言理解**：\n   - **语义角色标注**：识别句子中各个成分的语义角色。\n   - **依存句法分析**：分析句子中单词之间的依存关系。\n\n- **文本可视化**：\n   - 使用图形和图表来表示文本数据，帮助用户理解文本内容和模式。\n\n这些方法可以单独使用，也可以组合使用，以解决特定的文本挖掘问题。随着机器学习和深度学习技术的发展，文本挖掘的方法也在不断进步和演变。\n\n\n"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "211ad85fd89f8dd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T06:35:15.785272Z",
     "start_time": "2024-09-25T06:35:15.733115Z"
    },
    "trusted": false
   },
   "source": "\n# 导入pandas模块（Pandas是基于Numpy，主要用于机器学习和数据分析领域，主要数据挖掘、数据分析、数据探索）\nimport pandas as pd\n\n# 加载数据\ndf_reviews = pd.read_csv('./file/reviews.csv')\n'''\n    数据条目：5077\n    字段个数及存在空字段：7 short_d、content、name\n    字段类型：数据类型\n    占用内存：277.8+ KB\n'''\ndf_reviews.info()\ndf_reviews.head()",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f691fa6dff2ca00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T06:35:31.028460Z",
     "start_time": "2024-09-25T06:35:31.022014Z"
    },
    "trusted": false
   },
   "source": "# 导入Datetime模块\nimport datetime\n\n# 数据处理函数定义\ndef get_stars(n):\n    '''\n    获取评论中星级数据\n    :param n: \n    :return: \n    '''\n    return float(n.replace(' out of 5 stars',''))\n\n \ndef stars_cat(n):\n    '''\n    根据评星数量获取评价属性， 好评（4分及以上）， 中评（3分）， 差评（2分及以下）\n    :param n: \n    :return: \n    '''\n    if n <= 2:\n        return '差评'\n    elif n == 3:\n        return '中评'\n    else:\n        return '好评'\n\n\ndef get_date(x):\n    '''\n        处理评论日期  Reviewed in the United States on June 24, 2020\n        先用 'on ' 去拆分, 把日期文本拆分成两部分\n        再用', '拆分, 把后面的部分拆分成 ['月 日','年']\n        最后把前面的'月 日' 用空格拆分成 月 日\n        获取评论中的日期信息，转换成日期时间格式\n    :param x: \n    :return: \n    '''\n    x = x.split('on ')[1] # 把数据拆分成两部分 ['Reviewed in the United States on ','June 24, 2020']\n    x = x.split(', ')\n    y= x[1]\n    x = x[0].split(' ')\n    m,d = x[0],x[1]\n    if m=='January' or m=='Jan':\n        on_date='01-'+d+'-'+y\n    elif m=='February' or m=='Feb':\n        on_date='02-'+d+'-'+y\n    elif m=='March' or m=='Mar':\n        on_date='03-'+d+'-'+y\n    elif  m=='April' or m=='Apr':\n        on_date='04-'+d+'-'+y\n    elif  m=='May':\n        on_date='05-'+d+'-'+y\n    elif  m=='June' or m=='Jun':\n        on_date='06-'+d+'-'+y\n    elif  m=='July' or m=='Jul':\n        on_date='07-'+d+'-'+y\n    elif m=='August' or m=='Aug':\n        on_date='08-'+d+'-'+y\n    elif m=='September' or m=='Sep':\n        on_date='09-'+d+'-'+y\n    elif m=='October' or m=='Oct':\n        on_date='10-'+d+'-'+y\n    elif m=='November' or m=='Nov':\n        on_date='11-'+d+'-'+y\n    elif m=='December' or m=='Dec':\n        on_date='12-'+d+'-'+y\n    on_date = datetime.datetime.strptime(on_date, '%m-%d-%Y').strftime('%Y-%m-%d')\n    return on_date",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1c9aca220628997",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T06:35:32.562234Z",
     "start_time": "2024-09-25T06:35:32.513002Z"
    },
    "trusted": false
   },
   "source": "# 字数统计\ndf_reviews['stars_num'] = df_reviews['stars'].apply(get_stars)\ndf_reviews['content_cat'] = df_reviews['stars_num'].apply(stars_cat)\ndf_reviews['date_d'] = df_reviews['date'].apply(get_date)",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bb5e22d5528fc88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T06:35:34.121888Z",
     "start_time": "2024-09-25T06:35:33.911457Z"
    },
    "trusted": false
   },
   "source": "# 导入seaborn绘图模块\nimport seaborn as sns\n\n# 查看不同商品的总数\nsns.set(font_scale = 1)\ndf_reviews['product_name'].value_counts().plot(kind='bar')",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "991ec2200567f249",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T06:35:36.439510Z",
     "start_time": "2024-09-25T06:35:36.423381Z"
    },
    "trusted": false
   },
   "source": "# 按时间顺序统计发文数量，分析是否有周期性规律\ndf_reviews['date_d'] = pd.to_datetime(df_reviews['date_d'])\ndf_reviews['y_m'] = df_reviews['date_d'].values.astype('datetime64[M]')#提取日期年月\ndf_reviews.head()",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "862cc8c827b3ea78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T06:35:39.455288Z",
     "start_time": "2024-09-25T06:35:38.405967Z"
    },
    "trusted": false
   },
   "source": "# 导入绘图模块\nimport matplotlib.pyplot as plt\n\n# 解决中文显示问题\nplt.rcParams['font.family'] = ['sans-serif']\nplt.rcParams['font.sans-serif'] = ['SimHei']\n\n'''\n    描述：包含多个子图的网格，每个子图中包含‘product_name’的分布情况\n    data：数据集\n    col：设置分组变量\n    col_wrap：显示子图数量\n    sharex/sharey：是否共享x/y轴刻度和标签\n    height：子图高度（英寸）\n    aspect：子图宽高比\n'''\n\ng = sns.FacetGrid(data = df_reviews, col = 'product_name',col_wrap = 2, sharex = False, sharey = False, height = 5, aspect= 1.2)\n\n# order_arr = ['positive','negative','neutral']\n# g.map(sns.countplot, 'content_cat', order = order_arr)",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6ddda02ee4d13e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T06:35:44.403412Z",
     "start_time": "2024-09-25T06:35:42.117884Z"
    },
    "trusted": false
   },
   "source": "# 每种产品的发文数量按月统计\ndf_content = df_reviews.groupby(['product_name','y_m'])['content'].count().reset_index()\n\n'''\n    描述：包含多个子图的网格，每个子图中包含‘product_name’的分布情况\n    data：数据集\n    col：设置分组变量\n    col_wrap：显示子图数量\n    sharex/sharey：是否共享x/y轴刻度和标签\n    height：子图高度（英寸）\n    aspect：子图宽高比\n'''\nfg = sns.FacetGrid(data = df_content, col = 'product_name', col_wrap = 2,sharey = False, sharex = False, height = 4,aspect = 2)\n# 第一个参数传入的是 要调用哪个API 绘图,  后面几个参数传的是 调用 (plt.plot 的时候需要用到哪些参数, 具体的数据传入列名就行了\n\n# marker='1' 折线图每一个点会一条短线来表示\nfg.map(plt.plot, \"y_m\", 'content', marker='1')",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1891100d4af8a8f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T06:35:49.555156Z",
     "start_time": "2024-09-25T06:35:46.534167Z"
    },
    "trusted": false
   },
   "source": "# target：好中差评随时间分布\n\n# 对数据按照产品名称、评论日期、内容分类分组并求和\ncomment_group_by_arr = ['product_name','y_m','content_cat']\ndf_content = df_reviews.groupby(comment_group_by_arr)['content'].count().reset_index()\nprint(df_content.head())\n'''\n    描述：包含多个子图的网格，每个子图中包含‘product_name’的分布情况\n    data：数据集\n    col：设置分组变量\n    col_wrap：显示子图数量\n    sharex/sharey：是否共享x/y轴刻度和标签\n    height：子图高度（英寸）\n    aspect：子图宽高比\n'''\nfg = sns.FacetGrid(data = df_content, col = 'product_name', hue = 'content_cat', col_wrap = 2, sharey = False, sharex = False, height = 4, aspect = 2)\n# 折线图每一个点会用一个点来表示\nfg.map(plt.plot, \"y_m\", 'content', marker = '.')\n# 添加图例\nfg.add_legend()",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ffe881dfeba85dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T06:35:55.759167Z",
     "start_time": "2024-09-25T06:35:52.519211Z"
    },
    "trusted": false
   },
   "source": "# target:同产品不同型号分布\n\n# 对数据按照产品、评论日期、类型排序\ntype_group_by_arr = ['product_name','y_m','type']\ndf_content = df_reviews.groupby(type_group_by_arr)['content'].count().reset_index()\nprint(df_content.head())\n\n'''\n    描述：包含多个子图的网格，每个子图中包含‘product_name’的分布情况\n    data：数据集\n    col：设置分组变量\n    col_wrap：显示子图数量\n    sharex/sharey：是否共享x/y轴刻度和标签\n    height：子图高度（英寸）\n    aspect：子图宽高比\n'''\nfg = sns.FacetGrid(data = df_content, col = 'product_name', hue = 'type', col_wrap = 2, sharey = False, sharex = False, height = 4, aspect = 2)\nfg.map(plt.plot, 'y_m', 'content', marker = '.')\nfg.add_legend()",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e2402e6391a201e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T06:35:57.563242Z",
     "start_time": "2024-09-25T06:35:57.553104Z"
    },
    "trusted": false
   },
   "source": "# target:数据去重\n\nsubset_dict = {\"product_name\", \"type\",\"date_d\", \"content_cat\", \"content\", \"stars_num\", \"name\"}\ndf_data = df_reviews.drop_duplicates(subset_dict)\ndf_text = df_data['content']\ndf_text[0]",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "902e4928e660a691",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T02:24:40.798843Z",
     "start_time": "2024-09-26T02:24:40.791574Z"
    },
    "trusted": false
   },
   "source": "# 判断某款产品是好评还是差评\n\npositive_condition = (df_data['product_name'] == 'everjoys-Soprano') & (df_data['content_cat'] == '好评')\nsample_positive = df_data[positive_condition]\n\nnegative_condition = (df_data['product_name'] == 'everjoys-Soprano') & (df_data['content_cat'] == '差评')\nsample_negative = df_data[negative_condition]\n\nprint('好评', len(sample_positive))\nprint('差评', len(sample_negative))",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ddfbfca110e576fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T08:06:30.823651Z",
     "start_time": "2024-09-26T08:06:30.817415Z"
    },
    "trusted": false
   },
   "source": "# 导入正则表达式\nimport re\n\ndef replace_abbreviations(text):\n    '''\n    在用语料分析的第一步，用正则表达式对文本进行处理，\n    :param text:\n    :return:\n\n    正则：由一系列普通与特殊字符组成的用于描述文本规则的表达式\n        - re的包，是一个有关正则匹配的\n        - re.sub(pattern,replacement,string) ##查找字符串中出现的所有模式，并做替换，输出替换后的结果字符串\n        - ? 前一个字符之多出现一次：<=1\n        - * 前一个字符至少不出现0次：>=0\n        - + 前一个字符至少出现一次：>=1\n        - ^ 标识字符串以后一个字符开始\n        - . 代表任意一个字符\n        - $ 标识字符串以前一个字符结束\n        - () 标识一个group,group(0)表示正则表达式的模式匹配结果，group(1)表示小括号内匹配的第一个群\n        - [] 中括号内的字符表示一个字符的取值范围\n        - {} 大括号内的数字表示前一个字符重复的次数\n        - \\ 反斜线表示去除通配符的特殊意义，仅作为普通字符使用\n        - | 或者\n    '''\n    new_text = text\n    #则表达式过滤特殊符号用空格符占位，双引号、单引号、句点、逗号\n    new_text = re.sub(r'[^a-zA-Z.,?! \\']+',' ', text).strip().lower()\n    # 还原常见缩写单词还原,i'm i'd he's\n    new_text = re.sub(r\"(it|he|she|that|this|there|here)(\\'s)\",r\"\\1 is\", new_text,re.I)\n    # (?<=pattern)xxx，就是捕获以pattern开头的内容xxx\n    new_text = re.sub(r\"(?<=[a-zA-Z])n\\'t\",\" not\", new_text) # not的缩写 aren't-- are not\n    new_text = re.sub(r\"(?<=[a-zA-Z])\\'d\",\" would\", new_text) # would的缩写i'd -->i would--> 'i' 'would'\n    new_text = re.sub(r\"(?<=[a-zA-Z])\\'ll\",\" will\", new_text) # will的缩写\n    new_text = re.sub(r\"(?<=[I|i])\\'m\",\" am\", new_text) # am的缩写\n    new_text = re.sub(r\"(?<=[a-zA-Z])\\'re\",\" are\", new_text) # are的缩写\n    new_text = re.sub(r\"(?<=[a-zA-Z])\\'ve\",\" have\", new_text) # have的缩写\n    new_text = new_text.replace('\\'', ' ').replace('.', '. ')\n\n    return new_text\n\nfrom nltk.corpus import wordnet as wn\ndef get_lemma(word):\n    '''\n    词性标注\n    :param word:\n    :return:\n    '''\n    lemma = wn.morphy(word)\n    if lemma is None:\n        return word\n    else:\n        return lemma\n\nimport nltk\n\n# 封装成pipeline\ndef prepare_text(n):\n    tx = replace_abbreviations(str(n)) # 缩写还原\n    # 分词处理  英文分词 实际上就是用空格去split\n\n    tokens = nltk.word_tokenize(tx)\n    # 词还原词形\n    tokens = [get_lemma(token) for token in tokens]\n    # 去停用词\n    tokens = [ i for i in tokens if i not in stop_words] # 遍历每一个单词 如果在停用词表中的就去掉 不在停用词表中的返回\n    return tokens",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44a3d4fa72e57d74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T02:34:37.763118Z",
     "start_time": "2024-09-27T02:34:37.757788Z"
    },
    "trusted": false
   },
   "source": "import nltk\n\npunctuation = [\",\", \":\", \";\", \".\", \"!\", \"'\", '\"', \"’\", \"?\", \"/\", \"-\", \"+\", \"&\", \"(\", \")\"]\n# nltk.download('stopwords')\nstop_words= nltk.corpus.stopwords.words('english') + punctuation\nstop_words",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "586e5694833cc969",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T02:34:47.368932Z",
     "start_time": "2024-09-27T02:34:46.684450Z"
    },
    "trusted": false
   },
   "source": "clean_txt_positive= [prepare_text(s) for s in sample_positive['content']]\nclean_txt_negative= [prepare_text(s) for s in sample_negative['content']]",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c316a0e38aa04c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T02:35:25.044920Z",
     "start_time": "2024-09-27T02:35:25.041642Z"
    },
    "trusted": false
   },
   "source": "print('原始文本：', sample_positive['content'][2])\nprint('处理后文本', clean_txt_positive[0])",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc76fa9973f7242d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T02:35:29.745899Z",
     "start_time": "2024-09-27T02:35:29.741957Z"
    },
    "trusted": false
   },
   "source": "from collections import Counter\n\nCounter(clean_txt_positive[0]).most_common(2)",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a6b62d7510147394",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T02:35:49.879360Z",
     "start_time": "2024-09-27T02:35:49.875515Z"
    },
    "trusted": false
   },
   "source": "# 创建词云图\ndef statistical_word_freq(target_word_coll):\n    word_arr = []\n\n    # 1、遍历分词后集合\n    for words in target_word_coll:\n        for word in words:\n            word_arr.append(word)\n\n    # 2、去重后转为集合\n    dupl_word_arr = set(word_arr)\n    total_words = list(dupl_word_arr)\n\n    # 3、统计次数\n    times = Counter(word_arr)\n    content_mean = len(word_arr) / len(target_word_coll)\n    words_cap =  len(total_words) / len(word_arr)\n    return times, word_arr, content_mean, total_words, words_cap",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73e70862feb45f08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T02:37:56.469276Z",
     "start_time": "2024-09-27T02:37:56.462873Z"
    },
    "trusted": false
   },
   "source": "p_times, p_word_arr, p_content_mean, p_total_words, p_words_cap = statistical_word_freq(clean_txt_positive)\nn_times, n_word_arr, n_content_mean, n_total_words, n_words_cap = statistical_word_freq(clean_txt_negative)",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9b05fabcb69bcd26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T02:37:58.683488Z",
     "start_time": "2024-09-27T02:37:58.679557Z"
    },
    "trusted": false
   },
   "source": "p_content_mean, p_words_cap",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "753f020206f31043",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T02:38:20.111363Z",
     "start_time": "2024-09-27T02:38:20.107611Z"
    },
    "trusted": false
   },
   "source": "n_content_mean, n_words_cap",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f642fc34b0fc4b3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T06:56:08.668570Z",
     "start_time": "2024-09-27T06:56:08.662671Z"
    },
    "trusted": false
   },
   "source": "# 取出前100个频率最高的单词\np_times.most_common(100)",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "53824ad2df1e160a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T06:56:10.531954Z",
     "start_time": "2024-09-27T06:56:10.526331Z"
    },
    "trusted": false
   },
   "source": "# 取出前100个频率最高的单词\nn_times.most_common(100)",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "10d817ebce9974b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T09:08:06.898891Z",
     "start_time": "2024-09-27T09:08:06.892473Z"
    },
    "trusted": false
   },
   "source": "import pyecharts.options as opts\nfrom pyecharts.charts import WordCloud\n\n#传入绘制词云图的数据,  word_size_range 字号大小取值范围\n\n# 设置标题字号\ntitle_opts = opts.TitleOpts(title=\"好评词云\", title_textstyle_opts = opts.TextStyleOpts(font_size=23))\n\nword_data = p_times.most_common(100)\n# 设置为True 鼠标滑过文字会弹出提示框\ntooltip_opts = opts.TooltipOpts(is_show = True)\n(WordCloud()\n     .add(series_name=\"好评词云\", data_pair = word_data,  word_size_range=[16, 80]) \n     .set_global_opts( title_opts= title_opts, tooltip_opts = tooltip_opts,)\n     #.render_notebook()\n     .render(\"./file/好评词云.html\")\n )",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "fad64e6a66991135",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T04:19:09.153806Z",
     "start_time": "2024-09-29T04:19:09.144629Z"
    },
    "trusted": false
   },
   "source": "import pyecharts.options as opts\nfrom pyecharts.charts import WordCloud\n\nimport matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight')\n\n# import warnings\n# # 忽略不必要的warnings\n# warnings.filterwarnings('ignore')\n# %matplotlib inline\n\n# 设置标题字号\ntitle_opts = opts.TitleOpts(title=\"差评词云\", title_textstyle_opts=opts.TextStyleOpts(font_size=23))\n\n# 设置为True 鼠标滑过文字会弹出提示框\ntooltip_opts = opts.TooltipOpts(is_show = True)\n\n(WordCloud()\n .add(series_name=\"差评词云\", data_pair= n_times.most_common(100), word_size_range=[16, 80])\n .set_global_opts(title_opts = title_opts, tooltip_opts = tooltip_opts)\n # .render_notebook()\n .render(\"./file/差评词云.html\")\n )",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31593934df638e5e",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "trusted": false
   },
   "source": "import pyecharts.options as opts\nfrom pyecharts.charts import WordCloud\n\ndata = [\n    (\"生活资源\", \"999\"),\n    (\"供热管理\", \"888\"),\n    (\"供气质量\", \"777\"),\n    (\"生活用水管理\", \"688\"),\n    (\"一次供水问题\", \"588\"),\n    (\"交通运输\", \"516\"),\n    (\"城市交通\", \"515\"),\n    (\"环境保护\", \"483\"),\n    (\"房地产管理\", \"462\"),\n    (\"城乡建设\", \"449\"),\n    (\"社会保障与福利\", \"429\"),\n    (\"社会保障\", \"407\"),\n    (\"文体与教育管理\", \"406\"),\n    (\"公共安全\", \"406\"),\n    (\"公交运输管理\", \"386\"),\n    (\"出租车运营管理\", \"385\"),\n    (\"供热管理\", \"375\"),\n    (\"市容环卫\", \"355\"),\n    (\"自然资源管理\", \"355\"),\n    (\"粉尘污染\", \"335\"),\n    (\"噪声污染\", \"324\"),\n    (\"土地资源管理\", \"304\"),\n    (\"物业服务与管理\", \"304\"),\n    (\"医疗卫生\", \"284\"),\n    (\"粉煤灰污染\", \"284\"),\n    (\"占道\", \"284\"),\n    (\"供热发展\", \"254\"),\n    (\"农村土地规划管理\", \"254\"),\n    (\"生活噪音\", \"253\"),\n    (\"供热单位影响\", \"253\"),\n    (\"城市供电\", \"223\"),\n    (\"房屋质量与安全\", \"223\"),\n    (\"大气污染\", \"223\"),\n    (\"房屋安全\", \"223\"),\n    (\"文化活动\", \"223\"),\n    (\"拆迁管理\", \"223\"),\n    (\"公共设施\", \"223\"),\n    (\"供气质量\", \"223\"),\n    (\"供电管理\", \"223\"),\n    (\"燃气管理\", \"152\"),\n    (\"教育管理\", \"152\"),\n    (\"医疗纠纷\", \"152\"),\n    (\"执法监督\", \"152\"),\n    (\"设备安全\", \"152\"),\n    (\"政务建设\", \"152\"),\n    (\"县区、开发区\", \"152\"),\n    (\"宏观经济\", \"152\"),\n    (\"教育管理\", \"112\"),\n    (\"社会保障\", \"112\"),\n    (\"生活用水管理\", \"112\"),\n    (\"物业服务与管理\", \"112\"),\n    (\"分类列表\", \"112\"),\n    (\"农业生产\", \"112\"),\n    (\"二次供水问题\", \"112\"),\n    (\"城市公共设施\", \"92\"),\n    (\"拆迁政策咨询\", \"92\"),\n    (\"物业服务\", \"92\"),\n    (\"物业管理\", \"92\"),\n    (\"社会保障保险管理\", \"92\"),\n    (\"低保管理\", \"92\"),\n    (\"文娱市场管理\", \"72\"),\n    (\"城市交通秩序管理\", \"72\"),\n    (\"执法争议\", \"72\"),\n    (\"商业烟尘污染\", \"72\"),\n    (\"占道堆放\", \"71\"),\n    (\"地上设施\", \"71\"),\n    (\"水质\", \"71\"),\n    (\"无水\", \"71\"),\n    (\"供热单位影响\", \"71\"),\n    (\"人行道管理\", \"71\"),\n    (\"主网原因\", \"71\"),\n    (\"集中供热\", \"71\"),\n    (\"客运管理\", \"71\"),\n    (\"国有公交（大巴）管理\", \"71\"),\n    (\"工业粉尘污染\", \"71\"),\n    (\"治安案件\", \"71\"),\n    (\"压力容器安全\", \"71\"),\n    (\"身份证管理\", \"71\"),\n    (\"群众健身\", \"41\"),\n    (\"工业排放污染\", \"41\"),\n    (\"破坏森林资源\", \"41\"),\n    (\"市场收费\", \"41\"),\n    (\"生产资金\", \"41\"),\n    (\"生产噪声\", \"41\"),\n    (\"农村低保\", \"41\"),\n    (\"劳动争议\", \"41\"),\n    (\"劳动合同争议\", \"41\"),\n    (\"劳动报酬与福利\", \"41\"),\n    (\"医疗事故\", \"21\"),\n    (\"停供\", \"21\"),\n    (\"基础教育\", \"21\"),\n    (\"职业教育\", \"21\"),\n    (\"物业资质管理\", \"21\"),\n    (\"拆迁补偿\", \"21\"),\n    (\"设施维护\", \"21\"),\n    (\"市场外溢\", \"11\"),\n    (\"占道经营\", \"11\"),\n    (\"树木管理\", \"11\"),\n    (\"农村基础设施\", \"11\"),\n    (\"无水\", \"11\"),\n    (\"供气质量\", \"11\"),\n    (\"停气\", \"11\"),\n    (\"市政府工作部门（含部门管理机构、直属单位）\", \"11\"),\n    (\"燃气管理\", \"11\"),\n    (\"市容环卫\", \"11\"),\n    (\"新闻传媒\", \"11\"),\n    (\"人才招聘\", \"11\"),\n    (\"市场环境\", \"11\"),\n    (\"行政事业收费\", \"11\"),\n    (\"食品安全与卫生\", \"11\"),\n    (\"城市交通\", \"11\"),\n    (\"房地产开发\", \"11\"),\n    (\"房屋配套问题\", \"11\"),\n    (\"物业服务\", \"11\"),\n    (\"物业管理\", \"11\"),\n    (\"占道\", \"11\"),\n    (\"园林绿化\", \"11\"),\n    (\"户籍管理及身份证\", \"11\"),\n    (\"公交运输管理\", \"11\"),\n    (\"公路（水路）交通\", \"11\"),\n    (\"房屋与图纸不符\", \"11\"),\n    (\"有线电视\", \"11\"),\n    (\"社会治安\", \"11\"),\n    (\"林业资源\", \"11\"),\n    (\"其他行政事业收费\", \"11\"),\n    (\"经营性收费\", \"11\"),\n    (\"食品安全与卫生\", \"11\"),\n    (\"体育活动\", \"11\"),\n    (\"有线电视安装及调试维护\", \"11\"),\n    (\"低保管理\", \"11\"),\n    (\"劳动争议\", \"11\"),\n    (\"社会福利及事务\", \"11\"),\n    (\"一次供水问题\", \"11\"),\n]\n\n# c = (\n(\n    WordCloud()\n    .add(\n        # 系列名称，用于 tooltip 的显示，legend 的图例筛选。\n        series_name=\"热点分析\",\n\n        # 系列数据项，[(word1, count1), (word2, count2)]\n        data_pair=data,\n\n        # 单词字体大小范围\n        word_size_range=[6, 66])\n\n    # 全局配置项\n    .set_global_opts(\n        # 标题设置\n        title_opts=opts.TitleOpts(\n            title=\"热点分析\", title_textstyle_opts=opts.TextStyleOpts(font_size=23)\n        ),\n        # 提示框设置\n        tooltip_opts=opts.TooltipOpts(is_show=True),\n    )\n    # .render_notebook()\n    .render(\"./file/Demo.html\")\n)",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28da9becfa98b31b",
   "metadata": {
    "trusted": false
   },
   "source": "",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
